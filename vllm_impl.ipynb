{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16422,"status":"ok","timestamp":1767102705334,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"pHyTEigks9zJ","outputId":"16383c98-67c1-4767-d421-92b00559683a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1767103874611,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"Cp_FSqxUtFfI","outputId":"72deea89-3973-4864-c950-2cb38be52b71"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["%cd '/content'\n","# this is saved in /content/drive/MyDrive/Colab Notebooks\n","# need to move it to Colab-Notebooks which is git checked in and make sure you\n","# are editing this copy\n"]},{"cell_type":"markdown","metadata":{"id":"nAqZ98nkC3Gn"},"source":["# VLLM **Impl**\n","\n","<ul>\n","\n","<ul>\n","<li>Implement a llm served by vllm </li>\n","<li>wont work. on google drive; FUSE timeout</li>\n","<li></li>\n","</ul>"]},{"cell_type":"code","source":["import os\n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Jx3_61UIisl3","executionInfo":{"status":"ok","timestamp":1767103882768,"user_tz":480,"elapsed":31,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"42d07ae1-47cc-49e2-b825-db3824dfdb27"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11299,"status":"ok","timestamp":1767103896255,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"mlwVTDiNe2O5","outputId":"606756e0-98e7-49bc-e2f3-c2021a503ad3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'vllm'...\n","remote: Enumerating objects: 130292, done.\u001b[K\n","remote: Total 130292 (delta 0), reused 0 (delta 0), pack-reused 130292 (from 1)\u001b[K\n","Receiving objects: 100% (130292/130292), 111.63 MiB | 25.25 MiB/s, done.\n","Resolving deltas: 100% (102366/102366), done.\n"]}],"source":["!git clone https://github.com/dougc333/vllm.git"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1625,"status":"ok","timestamp":1767103897882,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"NkziqCsQNVKR","outputId":"e8d55cf6-145b-4b70-8387-ecad2738ea62"},"outputs":[{"output_type":"stream","name":"stdout","text":["downloading uv 0.9.20 x86_64-unknown-linux-gnu\n","no checksums to verify\n","installing to /usr/local/bin\n","  uv\n","  uvx\n","everything's installed!\n"]}],"source":["!/usr/bin/curl -fsSL https://astral.sh/uv/install.sh | sh"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1767103898202,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"LyRJ54LaNmV1","outputId":"26b9210f-bdaa-441d-8cc9-a1db90bde25f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--system` flag has no effect, a system Python interpreter is always used in `uv venv`\u001b[0m\n","Using CPython 3.10.12 interpreter at: \u001b[36m/usr/bin/python3.10\u001b[39m\n","Creating virtual environment with seed packages at: \u001b[36m.venv\u001b[39m\n"," \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mwheel\u001b[0m\u001b[2m==0.45.1\u001b[0m\n","Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n"]}],"source":["!uv venv --python 3.10 --seed"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":144,"status":"ok","timestamp":1767103898351,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"r5cJeGP9NsEK"},"outputs":[],"source":["!source .venv/bin/activate"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2926,"status":"ok","timestamp":1767103901921,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"a1hUsv0TOVjB","outputId":"bd2ab24c-6f89-49be-8622-413248f048b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libnuma-dev is already the newest version (2.0.14-3ubuntu2).\n","gcc-12 is already the newest version (12.3.0-1ubuntu1~22.04.2).\n","python3-dev is already the newest version (3.10.6-1~22.04.1).\n","g++-12 is already the newest version (12.3.0-1ubuntu1~22.04.2).\n","0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"]}],"source":["!DEBIAN_FRONTEND=noninteractive \\\n","     apt-get -o Dpkg::Options::=--force-confnew \\\n","             -o Dpkg::Options::=--force-confdef \\\n","             install -y gcc-12 g++-12 libnuma-dev python3-dev"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":108,"status":"ok","timestamp":1767103902877,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"jPJ_GVBIOVlL"},"outputs":[],"source":["!update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12\n"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1767103905590,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"kLeSWstmOVnx","outputId":"9cd88410-8988-4750-89ec-0ce678a6ddbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/vllm\n"]}],"source":["%cd vllm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpPTL3ChSKhr"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":206,"status":"ok","timestamp":1767103908536,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"ui-25EouO7gh","outputId":"1c57d7c6-37d8-49e5-e67f-b0e77cc15dd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2mAudited \u001b[1m10 packages\u001b[0m \u001b[2min 95ms\u001b[0m\u001b[0m\n"]}],"source":["#had to add --python 3.10 else it goes to 3.12\n","#cant run from cell, run from terminal\n","!uv pip install  -r requirements/build.txt --index-strategy unsafe-best-match"]},{"cell_type":"code","source":["!apt-get install -y ccache\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXkS9JXtb1A2","executionInfo":{"status":"ok","timestamp":1767103914928,"user_tz":480,"elapsed":3101,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"ce3a4321-01bb-4d4e-89bf-e040c688b432"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ccache is already the newest version (4.5.1-1).\n","0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"MAX_JOBS\"] = \"4\""],"metadata":{"id":"KLt_ZNNgcUCB","executionInfo":{"status":"ok","timestamp":1767103918136,"user_tz":480,"elapsed":2,"user":{"displayName":"doug chang","userId":"06495228775351504429"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AO1yBhfTXf2j"},"source":["Remove xformers{platform_machine == 'x86_64' and sys_platform\n","      == 'linux'}==0.0.33+5d4b92a5.\n","      \n","      \n","      d20251029\n","from requirements/cuda.txt\n"]},{"cell_type":"code","source":["!uv pip install --python 3.10 -r  requirements/build.txt --index-strategy unsafe-best-match"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNSuYCAtkhEg","executionInfo":{"status":"ok","timestamp":1767103922161,"user_tz":480,"elapsed":112,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"787410e2-7bd2-495e-f350-6fafd44973c4"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2mUsing Python 3.10.12 environment at: /usr\u001b[0m\n","\u001b[2mAudited \u001b[1m10 packages\u001b[0m \u001b[2min 86ms\u001b[0m\u001b[0m\n"]}]},{"cell_type":"markdown","source":["edit reqirements/cuda.txt comment out xformers{platform_machine == 'x86_64' and sys_platform == 'linux'}==0.0.33+5d4b92a5."],"metadata":{"id":"qQYs3nE3miRz"}},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1767104030906,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"Ea90_r-aPkdG","outputId":"b4f4e1f5-4401-490e-e368-905e3a8d719c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2mUsing Python 3.10.12 environment at: /usr\u001b[0m\n","\u001b[2mAudited \u001b[1m57 packages\u001b[0m \u001b[2min 97ms\u001b[0m\u001b[0m\n"]}],"source":["#cant run from cell, run from terminal window.\n","#eliminate xformers line\n","#had to add --python 3.10 else it goes to 3.12\n","#!grep -n \"xformers\" requirements/cuda.txt\n","#comment out: xformers from cuda.txt\n","!uv pip install --python 3.10 -r  requirements/cuda.txt --index-strategy unsafe-best-match"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3629542,"status":"ok","timestamp":1767107668069,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"TqdDnmljPN7r","outputId":"dacc57a3-2ad1-4d41-87c4-632db37ce876"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/quark/schemes\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/quark/schemes\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/quark/schemes/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/quark/schemes\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/quark/schemes/quark_ocp_mx.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/quark/schemes\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/quark/schemes\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/models/transformers\n","\u001b[31m      \u001b[0mcopying vllm/model_executor/models/transformers/multimodal.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/models/transformers\n","\u001b[31m      \u001b[0mcopying vllm/model_executor/models/transformers/causal.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/models/transformers\n","\u001b[31m      \u001b[0mcopying vllm/model_executor/models/transformers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/models/transformers\n","\u001b[31m      \u001b[0mcopying vllm/model_executor/models/transformers/legacy.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/models/transformers\n","\u001b[31m      \u001b[0mcopying vllm/model_executor/models/transformers/pooling.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/models/transformers\n","\u001b[31m      \u001b[0mcopying vllm/model_executor/models/transformers/base.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/models/transformers\n","\u001b[31m      \u001b[0mcopying vllm/model_executor/models/transformers/moe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/models/transformers\n","\u001b[31m      \u001b[0mcopying vllm/model_executor/models/transformers/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/models/transformers\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/chat_templates\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/chat_templates/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/chat_templates\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/chat_templates/registry.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/chat_templates\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/tokenizers\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/tokenizers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/tokenizers\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/tokenizers/mistral.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/tokenizers\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/processors\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/processors/ovis2_5.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/processors\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/processors/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/processors\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/processors/ovis.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/processors\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/processors/deepseek_ocr.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/processors\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/processors/deepseek_vl2.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/processors\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/kimi_vl.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/jais.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/kimi_linear.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/midashenglm.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/nemotron.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/dotsocr.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/eagle.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/step3_vl.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/ultravox.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/chatglm.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/falcon.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/mistral.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/qwen3_next.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/moonvit.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/ovis.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/radio.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/nemotron_h.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/mlp_speculator.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/olmo3.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/flex_olmo.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/medusa.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/lfm2_moe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/deepseek_vl2.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/arctic.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs/speculators\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/speculators/algos.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs/speculators\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/speculators/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs/speculators\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/configs/speculators/base.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/configs/speculators\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/core\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/kv_cache_coordinator.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/single_type_kv_cache_manager.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/kv_cache_manager.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/kv_cache_utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/block_pool.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/encoder_cache_manager.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/structured_output\n","\u001b[31m      \u001b[0mcopying vllm/v1/structured_output/backend_outlines.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/structured_output\n","\u001b[31m      \u001b[0mcopying vllm/v1/structured_output/backend_lm_format_enforcer.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/structured_output\n","\u001b[31m      \u001b[0mcopying vllm/v1/structured_output/backend_guidance.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/structured_output\n","\u001b[31m      \u001b[0mcopying vllm/v1/structured_output/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/structured_output\n","\u001b[31m      \u001b[0mcopying vllm/v1/structured_output/backend_xgrammar.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/structured_output\n","\u001b[31m      \u001b[0mcopying vllm/v1/structured_output/backend_types.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/structured_output\n","\u001b[31m      \u001b[0mcopying vllm/v1/structured_output/request.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/structured_output\n","\u001b[31m      \u001b[0mcopying vllm/v1/structured_output/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/structured_output\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/spec_decode\n","\u001b[31m      \u001b[0mcopying vllm/v1/spec_decode/eagle.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/spec_decode\n","\u001b[31m      \u001b[0mcopying vllm/v1/spec_decode/metadata.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/spec_decode\n","\u001b[31m      \u001b[0mcopying vllm/v1/spec_decode/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/spec_decode\n","\u001b[31m      \u001b[0mcopying vllm/v1/spec_decode/ngram_proposer.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/spec_decode\n","\u001b[31m      \u001b[0mcopying vllm/v1/spec_decode/suffix_decoding.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/spec_decode\n","\u001b[31m      \u001b[0mcopying vllm/v1/spec_decode/medusa.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/spec_decode\n","\u001b[31m      \u001b[0mcopying vllm/v1/spec_decode/metrics.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/spec_decode\n","\u001b[31m      \u001b[0mcopying vllm/v1/spec_decode/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/spec_decode\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/sample\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/sampler.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/metadata.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/rejection_sampler.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/executor\n","\u001b[31m      \u001b[0mcopying vllm/v1/executor/ray_executor.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/executor\n","\u001b[31m      \u001b[0mcopying vllm/v1/executor/multiproc_executor.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/executor\n","\u001b[31m      \u001b[0mcopying vllm/v1/executor/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/executor\n","\u001b[31m      \u001b[0mcopying vllm/v1/executor/ray_distributed_executor.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/executor\n","\u001b[31m      \u001b[0mcopying vllm/v1/executor/ray_utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/executor\n","\u001b[31m      \u001b[0mcopying vllm/v1/executor/uniproc_executor.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/executor\n","\u001b[31m      \u001b[0mcopying vllm/v1/executor/abstract.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/executor\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/pool\n","\u001b[31m      \u001b[0mcopying vllm/v1/pool/metadata.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/pool\n","\u001b[31m      \u001b[0mcopying vllm/v1/pool/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/pool\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/arc_manager.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/backend.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/cpu.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/mediums.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/factory.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/lru_manager.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/spec.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/abstract.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/metrics\n","\u001b[31m      \u001b[0mcopying vllm/v1/metrics/prometheus.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/metrics\n","\u001b[31m      \u001b[0mcopying vllm/v1/metrics/ray_wrappers.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/metrics\n","\u001b[31m      \u001b[0mcopying vllm/v1/metrics/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/metrics\n","\u001b[31m      \u001b[0mcopying vllm/v1/metrics/loggers.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/metrics\n","\u001b[31m      \u001b[0mcopying vllm/v1/metrics/stats.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/metrics\n","\u001b[31m      \u001b[0mcopying vllm/v1/metrics/reader.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/metrics\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/detokenizer.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/exceptions.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/llm_engine.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/processor.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/parallel_sampling.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/coordinator.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/logprobs.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/async_llm.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/core.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/output_processor.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcopying vllm/v1/engine/core_client.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/engine\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/gpu_ubatch_wrapper.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/gpu_model_runner.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/dp_utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/lora_model_runner_mixin.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/gpu_worker.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/tpu_model_runner.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/ec_connector_model_runner_mixin.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/gpu_input_batch.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/xpu_model_runner.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/ubatching.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/kv_connector_model_runner_mixin.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/ubatch_utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/tpu_input_batch.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/block_table.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/worker_base.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/cpu_model_runner.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/cpu_worker.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/tpu_worker.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/worker/xpu_worker.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/worker\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/attention\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/core/sched\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/sched/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core/sched\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/sched/scheduler.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core/sched\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/sched/request_queue.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core/sched\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/sched/output.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core/sched\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/sched/async_scheduler.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core/sched\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/sched/interface.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core/sched\n","\u001b[31m      \u001b[0mcopying vllm/v1/core/sched/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/core/sched\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/sample/ops\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/ops/penalties.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/ops\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/ops/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/ops\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/ops/topk_topp_sampler.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/ops\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/ops/logprobs.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/ops\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/ops/bad_words.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/ops\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/sample/tpu\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/tpu/sampler.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/tpu\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/tpu/metadata.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/tpu\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/tpu/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/tpu\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/logits_processor\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/logits_processor/builtin.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/logits_processor\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/logits_processor/state.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/logits_processor\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/logits_processor/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/logits_processor\n","\u001b[31m      \u001b[0mcopying vllm/v1/sample/logits_processor/interface.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/sample/logits_processor\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/backends/cpu.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/backends/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload/backends\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/worker/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/worker/cpu_gpu.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload/worker\n","\u001b[31m      \u001b[0mcopying vllm/v1/kv_offload/worker/worker.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/kv_offload/worker\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/flashinfer.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/rocm_aiter_fa.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/tree_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mamba1_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/flash_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/rocm_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/flex_attention.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/short_conv_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/rocm_aiter_unified_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/gdn_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/triton_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/linear_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mamba2_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/cpu_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/pallas.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mamba_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/xformers.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mla/cutlass_mla.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mla/common.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mla/flashmla.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mla/indexer.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mla/triton_mla.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mla/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mla/flashinfer_mla.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mla/flashmla_sparse.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mla/rocm_aiter_mla.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcopying vllm/v1/attention/backends/mla/flashattn_mla.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/v1/attention/backends/mla\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/distributed/eplb\n","\u001b[31m      \u001b[0mcopying vllm/distributed/eplb/rebalance_execute.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/eplb\n","\u001b[31m      \u001b[0mcopying vllm/distributed/eplb/eplb_state.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/eplb\n","\u001b[31m      \u001b[0mcopying vllm/distributed/eplb/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/eplb\n","\u001b[31m      \u001b[0mcopying vllm/distributed/eplb/rebalance_algo.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/eplb\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/distributed/ec_transfer\n","\u001b[31m      \u001b[0mcopying vllm/distributed/ec_transfer/ec_transfer_state.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/ec_transfer\n","\u001b[31m      \u001b[0mcopying vllm/distributed/ec_transfer/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/ec_transfer\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_transfer_state.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/device_communicators/base_device_communicator.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/all2all.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/custom_all_reduce.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/pynccl_allocator.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/all_reduce_utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/cpu_communicator.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/quick_all_reduce.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/tpu_communicator.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/mnnvl_compat.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/symm_mem.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/xpu_communicator.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/cuda_wrapper.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/shm_broadcast.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/shm_object_storage.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/pynccl_wrapper.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/ray_communicator.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/pynccl.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcopying vllm/distributed/device_communicators/cuda_communicator.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/device_communicators\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/ec_transfer/ec_connector\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/ec_transfer/ec_connector/shared_storage_connector.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/ec_transfer/ec_connector\n","\u001b[31m      \u001b[0mcopying vllm/distributed/ec_transfer/ec_connector/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/ec_transfer/ec_connector\n","\u001b[31m      \u001b[0mcopying vllm/distributed/ec_transfer/ec_connector/factory.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/ec_transfer/ec_connector\n","\u001b[31m      \u001b[0mcopying vllm/distributed/ec_transfer/ec_connector/base.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/ec_transfer/ec_connector\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_lookup_buffer\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_lookup_buffer\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_lookup_buffer\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_lookup_buffer/base.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_lookup_buffer\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_lookup_buffer\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_pipe\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_pipe\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_pipe\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_pipe/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_pipe\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_pipe/base.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_pipe\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_connector/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_connector/factory.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_connector/base.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_connector/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/offloading_connector.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_connector/v1/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/decode_bench_connector.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_connector/v1/base.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/lmcache_mp_connector.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_connector/v1/metrics.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/multi_process_adapter.py\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/__init__.py\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/vllm_v1_adapter.py\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/utils.py\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/benchmarks/sweep\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/sweep/serve.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/sweep\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/sweep/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/sweep\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/sweep/param_sweep.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/sweep\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/sweep/server.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/sweep\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/sweep/sla_sweep.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/sweep\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/sweep/plot.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/sweep\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/sweep/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/sweep\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/sweep/serve_sla.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/sweep\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/sweep/cli.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/sweep\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/benchmarks/lib\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/lib/endpoint_request_func.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/lib\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/lib/ready_checker.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/lib\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/lib/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/lib\n","\u001b[31m      \u001b[0mcopying vllm/benchmarks/lib/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/benchmarks/lib\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/lora/punica_wrapper\n","\u001b[31m      \u001b[0mcopying vllm/lora/punica_wrapper/punica_selector.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/punica_wrapper\n","\u001b[31m      \u001b[0mcopying vllm/lora/punica_wrapper/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/punica_wrapper\n","\u001b[31m      \u001b[0mcopying vllm/lora/punica_wrapper/punica_xpu.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/punica_wrapper\n","\u001b[31m      \u001b[0mcopying vllm/lora/punica_wrapper/punica_cpu.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/punica_wrapper\n","\u001b[31m      \u001b[0mcopying vllm/lora/punica_wrapper/punica_tpu.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/punica_wrapper\n","\u001b[31m      \u001b[0mcopying vllm/lora/punica_wrapper/punica_base.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/punica_wrapper\n","\u001b[31m      \u001b[0mcopying vllm/lora/punica_wrapper/punica_gpu.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/punica_wrapper\n","\u001b[31m      \u001b[0mcopying vllm/lora/punica_wrapper/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/punica_wrapper\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcopying vllm/lora/layers/base_linear.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcopying vllm/lora/layers/column_parallel_linear.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcopying vllm/lora/layers/replicated_linear.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcopying vllm/lora/layers/logits_processor.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcopying vllm/lora/layers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcopying vllm/lora/layers/fused_moe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcopying vllm/lora/layers/vocal_parallel_embedding.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcopying vllm/lora/layers/base.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcopying vllm/lora/layers/row_parallel_linear.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcopying vllm/lora/layers/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/layers\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/lora/ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/lora/ops/triton_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/triton_ops/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/triton_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/triton_ops/lora_kernel_metadata.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/triton_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/triton_ops/kernel_utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/triton_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/triton_ops/lora_expand_op.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/triton_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/triton_ops/lora_shrink_op.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/triton_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/triton_ops/fused_moe_lora_op.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/triton_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/triton_ops/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/triton_ops\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/lora/ops/ipex_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/ipex_ops/lora_ops.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/ipex_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/ipex_ops/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/ipex_ops\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/lora/ops/xla_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/xla_ops/lora_ops.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/xla_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/xla_ops/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/xla_ops\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/lora/ops/torch_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/torch_ops/lora_ops.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/torch_ops\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/torch_ops/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/torch_ops\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/plugins/lora_resolvers\n","\u001b[31m      \u001b[0mcopying vllm/plugins/lora_resolvers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/plugins/lora_resolvers\n","\u001b[31m      \u001b[0mcopying vllm/plugins/lora_resolvers/filesystem_resolver.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/plugins/lora_resolvers\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/plugins/io_processors\n","\u001b[31m      \u001b[0mcopying vllm/plugins/io_processors/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/plugins/io_processors\n","\u001b[31m      \u001b[0mcopying vllm/plugins/io_processors/interface.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/plugins/io_processors\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/attention/layers\n","\u001b[31m      \u001b[0mcopying vllm/attention/layers/encoder_only_attention.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/layers\n","\u001b[31m      \u001b[0mcopying vllm/attention/layers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/layers\n","\u001b[31m      \u001b[0mcopying vllm/attention/layers/chunked_local_attention.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/layers\n","\u001b[31m      \u001b[0mcopying vllm/attention/layers/cross_attention.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/layers\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/attention/utils\n","\u001b[31m      \u001b[0mcopying vllm/attention/utils/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/utils\n","\u001b[31m      \u001b[0mcopying vllm/attention/utils/kv_transfer_utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/utils\n","\u001b[31m      \u001b[0mcopying vllm/attention/utils/fa_utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/utils\n","\u001b[31m      \u001b[0mcopying vllm/attention/utils/kv_sharing_utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/utils\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/rocm_aiter_paged_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/common.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/flashmla.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/merge_attn_states.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/chunked_prefill_paged_decode.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/paged_attn.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/prefix_prefill.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/triton_merge_attn_states.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/pallas_kv_cache_update.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/triton_decode_attention.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/triton_reshape_and_cache_flash.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/triton_unified_attention.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcopying vllm/attention/ops/vit_attn_wrappers.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/ops\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/attention/backends/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/attention/backends/registry.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/attention/backends/abstract.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/backends\n","\u001b[31m      \u001b[0mcopying vllm/attention/backends/utils.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/attention/backends\n","\u001b[31m      \u001b[0mrunning egg_info\n","\u001b[31m      \u001b[0mcreating vllm.egg-info\n","\u001b[31m      \u001b[0mwriting vllm.egg-info/PKG-INFO\n","\u001b[31m      \u001b[0mwriting dependency_links to vllm.egg-info/dependency_links.txt\n","\u001b[31m      \u001b[0mwriting entry points to vllm.egg-info/entry_points.txt\n","\u001b[31m      \u001b[0mwriting requirements to vllm.egg-info/requires.txt\n","\u001b[31m      \u001b[0mwriting top-level names to vllm.egg-info/top_level.txt\n","\u001b[31m      \u001b[0mwriting manifest file 'vllm.egg-info/SOURCES.txt'\n","\u001b[31m      \u001b[0mreading manifest template 'MANIFEST.in'\n","\u001b[31m      \u001b[0madding license file 'LICENSE'\n","\u001b[31m      \u001b[0mwriting manifest file 'vllm.egg-info/SOURCES.txt'\n","\u001b[31m      \u001b[0mcopying vllm/py.typed -> build/lib.linux-x86_64-cpython-310/vllm\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=928,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=40,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=704,device_name=NVIDIA_B200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=32,N=1408,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=704,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=640,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=AMD_Instinct_MI350_OAM,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=352,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=64,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=384,device_name=AMD_Instinct_MI355_OAM,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=384,N=128,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=320,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1856,device_name=NVIDIA_L40S.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=40,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=40,N=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=928,device_name=NVIDIA_L40S.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1856,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=64,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=384,device_name=AMD_Instinct_MI350_OAM,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=NVIDIA_H100,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=64,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=72,N=192,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=bf16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=384,N=128,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=32,N=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=bf16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=640,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI308X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=2048,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H100_PCIe,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=32,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=40,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1408,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=64,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=384,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=384,N=256,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=640,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=62,N=128,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=384,N=128,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcreating\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=12288,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2112,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=12288,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2112,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-310/vllm/vllm_flash_attn\n","\u001b[31m      \u001b[0mcopying vllm/vllm_flash_attn/.gitkeep ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/vllm_flash_attn\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=NVIDIA_H100,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1856,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=1856,device_name=NVIDIA_L40S.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=352,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=704,device_name=NVIDIA_B200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=704,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI308X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=bf16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=928,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=928,device_name=NVIDIA_L40S.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=2048,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=AMD_Instinct_MI350_OAM,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=320,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=384,device_name=AMD_Instinct_MI350_OAM,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=384,device_name=AMD_Instinct_MI355_OAM,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=640,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=640,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=160,N=640,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=32,N=1408,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=32,N=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=32,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=384,N=128,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=384,N=128,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=384,N=128,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=384,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=384,N=256,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=40,N=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=40,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=40,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=40,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=64,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=64,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=64,device_name=NVIDIA_H20-3e.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=512,N=64,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=62,N=128,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1408,device_name=NVIDIA_B200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H100_PCIe,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_H20.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=bf16.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=64,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=72,N=192,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying vllm/model_executor/layers/fused_moe/configs/README ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/fused_moe/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=12288,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=12288,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2112,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2112,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4096,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json\n","\u001b[31m      \u001b[0m->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/model_executor/layers/quantization/utils/configs/README.md ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/model_executor/layers/quantization/utils/configs\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/chat_templates/template_basic.jinja ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/chat_templates\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/chat_templates/template_blip2.jinja ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/chat_templates\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/chat_templates/template_chatml.jinja ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/chat_templates\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/transformers_utils/chat_templates/template_deepseek_ocr.jinja ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/chat_templates\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/transformers_utils/chat_templates/template_deepseek_vl2.jinja ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/chat_templates\n","\u001b[31m      \u001b[0mcopying vllm/transformers_utils/chat_templates/template_fuyu.jinja ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/chat_templates\n","\u001b[31m      \u001b[0mcopying\n","\u001b[31m      \u001b[0mvllm/transformers_utils/chat_templates/template_minicpmv45.jinja ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/transformers_utils/chat_templates\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/README.md ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer\n","\u001b[31m      \u001b[0mcopying vllm/distributed/kv_transfer/disagg_prefill_workflow.jpg ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/distributed/kv_transfer\n","\u001b[31m      \u001b[0mcopying vllm/lora/ops/triton_ops/README_TUNING.md ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/lora/ops/triton_ops\n","\u001b[31m      \u001b[0mcopying vllm/plugins/lora_resolvers/README.md ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-310/vllm/plugins/lora_resolvers\n","\u001b[31m      \u001b[0mrunning build_ext\n","\u001b[31m      \u001b[0mUsing MAX_JOBS=4 as the number of jobs.\n","\u001b[31m      \u001b[0m-- The CXX compiler identification is GNU 12.3.0\n","\u001b[31m      \u001b[0m-- Detecting CXX compiler ABI info\n","\u001b[31m      \u001b[0m-- Detecting CXX compiler ABI info - done\n","\u001b[31m      \u001b[0m-- Check for working CXX compiler: /usr/bin/c++ - skipped\n","\u001b[31m      \u001b[0m-- Detecting CXX compile features\n","\u001b[31m      \u001b[0m-- Detecting CXX compile features - done\n","\u001b[31m      \u001b[0m-- Build type: RelWithDebInfo\n","\u001b[31m      \u001b[0m-- Target device: cuda\n","\u001b[31m      \u001b[0m-- Found Python: /usr/bin/python3.10 (found version \"3.10.12\") found\n","\u001b[31m      \u001b[0mcomponents: Interpreter Development.Module Development.SABIModule\n","\u001b[31m      \u001b[0m-- Found python matching: /usr/bin/python3.10.\n","\u001b[31m      \u001b[0m-- Found CUDA: /usr/local/cuda (found version \"12.5\")\n","\u001b[31m      \u001b[0m-- The CUDA compiler identification is NVIDIA 12.5.82 with host compiler\n","\u001b[31m      \u001b[0mGNU 12.3.0\n","\u001b[31m      \u001b[0m-- Detecting CUDA compiler ABI info\n","\u001b[31m      \u001b[0m-- Detecting CUDA compiler ABI info - done\n","\u001b[31m      \u001b[0m-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n","\u001b[31m      \u001b[0m-- Detecting CUDA compile features\n","\u001b[31m      \u001b[0m-- Detecting CUDA compile features - done\n","\u001b[31m      \u001b[0m-- Found CUDAToolkit: /usr/local/cuda/include (found version \"12.5.82\")\n","\u001b[31m      \u001b[0m-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n","\u001b[31m      \u001b[0m-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n","\u001b[31m      \u001b[0m-- Found Threads: TRUE\n","\u001b[31m      \u001b[0m-- PyTorch: CUDA detected: 12.5\n","\u001b[31m      \u001b[0m-- PyTorch: CUDA nvcc is: /usr/local/cuda/bin/nvcc\n","\u001b[31m      \u001b[0m-- PyTorch: CUDA toolkit directory: /usr/local/cuda\n","\u001b[31m      \u001b[0m-- PyTorch: Header version is: 12.5\n","\u001b[31m      \u001b[0m-- Found Python: /usr/bin/python3.10 (found version \"3.10.12\") found\n","\u001b[31m      \u001b[0mcomponents: Interpreter\n","\u001b[31m      \u001b[0m-- USE_CUDNN is set to 0. Compiling without cuDNN support\n","\u001b[31m      \u001b[0m-- USE_CUSPARSELT is set to 0. Compiling without cuSPARSELt support\n","\u001b[31m      \u001b[0m-- USE_CUDSS is set to 0. Compiling without cuDSS support\n","\u001b[31m      \u001b[0m-- USE_CUFILE is set to 0. Compiling without cuFile support\n","\u001b[31m      \u001b[0m-- Autodetected CUDA architecture(s):  7.5\n","\u001b[31m      \u001b[0m-- Added CUDA NVCC flags for: -gencode;arch=compute_75,code=sm_75\n","\u001b[31m      \u001b[0m-- Found Torch:\n","\u001b[31m      \u001b[0m/usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so\n","\u001b[31m      \u001b[0m-- CUDA target architectures: 7.5\n","\u001b[31m      \u001b[0m-- CUDA supported target architectures: 7.5\n","\u001b[31m      \u001b[0m-- FetchContent base directory: /content/vllm/.deps\n","\u001b[31m      \u001b[0m-- Enabling cumem allocator extension.\n","\u001b[31m      \u001b[0m-- CMake Version: 4.2.1\n","\u001b[31m      \u001b[0m-- CUTLASS 4.2.1\n","\u001b[31m      \u001b[0m-- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include\n","\u001b[31m      \u001b[0m(found version \"12.5.82\")\n","\u001b[31m      \u001b[0m-- CUDART: /usr/local/cuda/lib64/libcudart.so\n","\u001b[31m      \u001b[0m-- CUDA Driver: /usr/local/cuda/lib64/stubs/libcuda.so\n","\u001b[31m      \u001b[0m-- NVRTC: /usr/local/cuda/lib64/libnvrtc.so\n","\u001b[31m      \u001b[0m-- Default Install Location: install\n","\u001b[31m      \u001b[0m-- Found Python3: /usr/bin/python3.12 (found suitable version \"3.12.12\",\n","\u001b[31m      \u001b[0mminimum required is \"3.5\") found components: Interpreter\n","\u001b[31m      \u001b[0m-- CUDA Compilation Architectures: 70;72;75;80;86;87;89;90;90a\n","\u001b[31m      \u001b[0m-- Enable caching of reference results in conv unit tests\n","\u001b[31m      \u001b[0m-- Enable rigorous conv problem sizes in conv unit tests\n","\u001b[31m      \u001b[0m-- Grid Dependency Control (GDC) is enabled for SM100 kernels (required\n","\u001b[31m      \u001b[0mfor programmatic dependent launches).\n","\u001b[31m      \u001b[0m-- Using the following NVCC flags:\n","\u001b[31m      \u001b[0m  --expt-relaxed-constexpr\n","\u001b[31m      \u001b[0m  -ftemplate-backtrace-limit=0\n","\u001b[31m      \u001b[0m  -DCUTLASS_TEST_LEVEL=0\n","\u001b[31m      \u001b[0m  -DCUTLASS_TEST_ENABLE_CACHED_RESULTS=1\n","\u001b[31m      \u001b[0m  -DCUTLASS_CONV_UNIT_TEST_RIGOROUS_SIZE_ENABLED=1\n","\u001b[31m      \u001b[0m  -DCUTLASS_DEBUG_TRACE_LEVEL=0\n","\u001b[31m      \u001b[0m  -Xcompiler=-Wconversion\n","\u001b[31m      \u001b[0m  -Xcompiler=-fno-strict-aliasing\n","\u001b[31m      \u001b[0m  -lineinfo\n","\u001b[31m      \u001b[0m-- Configuring cublas ...\n","\u001b[31m      \u001b[0m-- cuBLAS Disabled.\n","\u001b[31m      \u001b[0m-- Configuring cuBLAS ... done.\n","\u001b[31m      \u001b[0m-- Not building Marlin kernels as no compatible archs found in CUDA\n","\u001b[31m      \u001b[0mtarget architectures\n","\u001b[31m      \u001b[0m-- Not building AllSpark kernels as no compatible archs found in CUDA\n","\u001b[31m      \u001b[0mtarget architectures\n","\u001b[31m      \u001b[0m-- Not building scaled_mm_c3x_sm90 as no compatible archs found in CUDA\n","\u001b[31m      \u001b[0mtarget architectures\n","\u001b[31m      \u001b[0m-- Not building scaled_mm_c3x_120 as no compatible archs found in CUDA\n","\u001b[31m      \u001b[0mtarget architectures\n","\u001b[31m      \u001b[0m-- Not building scaled_mm_c3x_100 as no compatible archs found in CUDA\n","\u001b[31m      \u001b[0mtarget architectures\n","\u001b[31m      \u001b[0m-- Building scaled_mm_c2x for archs: 7.5\n","\u001b[31m      \u001b[0m-- Not building sparse_scaled_mm_c3x as no compatible archs found in\n","\u001b[31m      \u001b[0mCUDA target architectures\n","\u001b[31m      \u001b[0m-- Not building NVFP4 as no compatible archs were found.\n","\u001b[31m      \u001b[0m-- Not building NVFP4 as no compatible archs were found.\n","\u001b[31m      \u001b[0m-- Not building CUTLASS MLA as no compatible archs were found.\n","\u001b[31m      \u001b[0m-- Not building grouped_mm_c3x as no compatible archs found in CUDA\n","\u001b[31m      \u001b[0mtarget architectures.\n","\u001b[31m      \u001b[0m-- Not building grouped_mm_c3x as no compatible archs found in CUDA\n","\u001b[31m      \u001b[0mtarget architectures.\n","\u001b[31m      \u001b[0m-- Not building moe_data as no compatible archs found in CUDA target\n","\u001b[31m      \u001b[0marchitectures.\n","\u001b[31m      \u001b[0m-- Not building blockwise_scaled_group_mm_sm100 as no compatible archs\n","\u001b[31m      \u001b[0mfound in CUDA target architectures\n","\u001b[31m      \u001b[0m-- Not building Machete kernels as no compatible archs found in CUDA\n","\u001b[31m      \u001b[0mtarget architectures\n","\u001b[31m      \u001b[0m-- Not building W4A8 kernels as no compatible archs found in CUDA target\n","\u001b[31m      \u001b[0marchitectures\n","\u001b[31m      \u001b[0m-- Enabling C extension.\n","\u001b[31m      \u001b[0m-- Not building Marlin MOE kernels as no compatible archs found in CUDA\n","\u001b[31m      \u001b[0mtarget architectures\n","\u001b[31m      \u001b[0m-- Enabling moe extension.\n","\u001b[31m      \u001b[0m-- FlashMLA is available at /content/vllm/.deps/flashmla-src\n","\u001b[31m      \u001b[0m-- [QUTLASS] QuTLASS is available at /content/vllm/.deps/qutlass-src\n","\u001b[31m      \u001b[0m-- [QUTLASS] Skipping build: CUDA 12.8 or newer is required (found\n","\u001b[31m      \u001b[0m12.5.82).\n","\u001b[31m      \u001b[0m-- Build type: RelWithDebInfo\n","\u001b[31m      \u001b[0m-- Target device: cuda\n","\u001b[31m      \u001b[0m-- Found Python: /usr/bin/python3.10 (found version \"3.10.12\") found\n","\u001b[31m      \u001b[0mcomponents: Interpreter Development.Module Development.SABIModule\n","\u001b[31m      \u001b[0m-- CUDA target architectures: 7.5\n","\u001b[31m      \u001b[0m-- CUDA supported target architectures:\n","\u001b[31m      \u001b[0m-- FA2_ARCHS:\n","\u001b[31m      \u001b[0m-- FA3_ARCHS:\n","\u001b[31m      \u001b[0m-- vllm-flash-attn is available at\n","\u001b[31m      \u001b[0m/content/vllm/.deps/vllm-flash-attn-src\n","\u001b[31m      \u001b[0m-- Configuring done (64.5s)\n","\u001b[31m      \u001b[0m-- Generating done (0.1s)\n","\u001b[31m      \u001b[0m-- Build files have been written to:\n","\u001b[31m      \u001b[0m/content/vllm/build/temp.linux-x86_64-cpython-310\n","\u001b[31m      \u001b[0mUsing MAX_JOBS=4 as the number of jobs.\n","\u001b[31m      \u001b[0m[1/443] Building CXX object\n","\u001b[31m      \u001b[0mCMakeFiles/cumem_allocator.dir/csrc/cumem_allocator.cpp.o\n","\u001b[31m      \u001b[0m[2/443] Building CUDA object CMakeFiles/_C.dir/csrc/cache_kernels.cu.o\n","\u001b[31m      \u001b[0m[3/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/mamba/mamba_ssm/selective_scan_fwd.cu.o\n","\u001b[31m      \u001b[0m[4/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/attention/merge_attn_states.cu.o\n","\u001b[31m      \u001b[0m[5/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/attention/vertical_slash_index.cu.o\n","\u001b[31m      \u001b[0m[6/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/pos_encoding_kernels.cu.o\n","\u001b[31m      \u001b[0m[7/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/activation_kernels.cu.o\n","\u001b[31m      \u001b[0m[8/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/layernorm_kernels.cu.o\n","\u001b[31m      \u001b[0m[9/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/fused_qknorm_rope_kernel.cu.o\n","\u001b[31m      \u001b[0m[10/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/layernorm_quant_kernels.cu.o\n","\u001b[31m      \u001b[0m[11/443] Building CUDA object CMakeFiles/_C.dir/csrc/sampler.cu.o\n","\u001b[31m      \u001b[0m[12/443] Building CUDA object CMakeFiles/_C.dir/csrc/cuda_view.cu.o\n","\u001b[31m      \u001b[0m[13/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/attention/paged_attention_v1.cu.o\n","\u001b[31m      \u001b[0m[14/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/attention/paged_attention_v2.cu.o\n","\u001b[31m      \u001b[0m[15/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/gptq/q_gemm.cu.o\n","\u001b[31m      \u001b[0m[16/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/w8a8/int8/scaled_quant.cu.o\n","\u001b[31m      \u001b[0m[17/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/w8a8/fp8/common.cu.o\n","\u001b[31m      \u001b[0m[18/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/cuda_utils_kernels.cu.o\n","\u001b[31m      \u001b[0m[19/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/fused_kernels/fused_layernorm_dynamic_per_token_quant.cu.o\n","\u001b[31m      \u001b[0m[20/443] Building CXX object CMakeFiles/_C.dir/csrc/torch_bindings.cpp.o\n","\u001b[31m      \u001b[0m[21/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/activation_kernels.cu.o\n","\u001b[31m      \u001b[0m/content/vllm/csrc/quantization/activation_kernels.cu(196): warning\n","\u001b[31m      \u001b[0m#940-D: missing return statement at end of non-void function\n","\u001b[31m      \u001b[0m\"vllm::clip\"\n","\u001b[31m      \u001b[0m  }\n","\u001b[31m      \u001b[0m  ^\n","\n","\u001b[31m      \u001b[0mRemark: The warnings can be suppressed with \"-diag-suppress\n","\u001b[31m      \u001b[0m<warning-number>\"\n","\n","\u001b[31m      \u001b[0m[22/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/custom_all_reduce.cu.o\n","\u001b[31m      \u001b[0m[23/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/gguf/gguf_kernel.cu.o\n","\u001b[31m      \u001b[0m[24/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/awq/gemm_kernels.cu.o\n","\u001b[31m      \u001b[0m[25/443] Building CUDA object CMakeFiles/_C.dir/csrc/permute_cols.cu.o\n","\u001b[31m      \u001b[0m[26/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/w8a8/cutlass/scaled_mm_entry.cu.o\n","\u001b[31m      \u001b[0m[27/443] Building CXX object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/cutlass_extensions/common.cpp.o\n","\u001b[31m      \u001b[0m[28/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/fp4/nvfp4_quant_entry.cu.o\n","\u001b[31m      \u001b[0m[29/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/fp4/nvfp4_scaled_mm_entry.cu.o\n","\u001b[31m      \u001b[0m[30/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/sparse/cutlass/sparse_scaled_mm_entry.cu.o\n","\u001b[31m      \u001b[0m[31/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/w8a8/int8/per_token_group_quant.cu.o\n","\u001b[31m      \u001b[0m[32/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/w8a8/fp8/per_token_group_quant.cu.o\n","\u001b[31m      \u001b[0m[33/443] Building CXX object\n","\u001b[31m      \u001b[0mCMakeFiles/_moe_C.dir/csrc/moe/torch_bindings.cpp.o\n","\u001b[31m      \u001b[0m[34/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/w8a8/cutlass/scaled_mm_c2x.cu.o\n","\u001b[31m      \u001b[0mFAILED: [code=137]\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/w8a8/cutlass/scaled_mm_c2x.cu.o\n","\u001b[31m      \u001b[0mccache /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler\n","\u001b[31m      \u001b[0m-DCUTLASS_ENABLE_DIRECT_CUDA_DRIVER_CALL=1 -DPy_LIMITED_API=3\n","\u001b[31m      \u001b[0m-DTORCH_EXTENSION_NAME=_C -DUSE_C10D_GLOO -DUSE_C10D_NCCL\n","\u001b[31m      \u001b[0m-DUSE_DISTRIBUTED -DUSE_NVSHMEM -DUSE_RPC -DUSE_TENSORPIPE -D_C_EXPORTS\n","\u001b[31m      \u001b[0m-I/content/vllm/csrc -I/content/vllm/.deps/cutlass-src/include\n","\u001b[31m      \u001b[0m-I/content/vllm/.deps/cutlass-src/tools/util/include\n","\u001b[31m      \u001b[0m-isystem /usr/include/python3.10 -isystem\n","\u001b[31m      \u001b[0m/usr/local/lib/python3.10/dist-packages/torch/include -isystem\n","\u001b[31m      \u001b[0m/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include\n","\u001b[31m      \u001b[0m-isystem /usr/local/cuda/include -DONNX_NAMESPACE=onnx_c2 -Xcudafe\n","\u001b[31m      \u001b[0m--diag_suppress=cc_clobber_ignored,--diag_suppress=field_without_dll_interface,--diag_suppress=base_class_has_different_dll_interface,--diag_suppress=dll_interface_conflict_none_assumed,--diag_suppress=dll_interface_conflict_dllexport_assumed,--diag_suppress=bad_friend_decl\n","\u001b[31m      \u001b[0m--expt-relaxed-constexpr --expt-extended-lambda -O2 -g\n","\u001b[31m      \u001b[0m-DNDEBUG -std=c++17 -Xcompiler=-fPIC --expt-relaxed-constexpr\n","\u001b[31m      \u001b[0m-DENABLE_FP8 --threads=1 -DENABLE_SCALED_MM_C2X=1\n","\u001b[31m      \u001b[0m-gencode arch=compute_75,code=sm_75 -MD -MT\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/w8a8/cutlass/scaled_mm_c2x.cu.o -MF\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/w8a8/cutlass/scaled_mm_c2x.cu.o.d -x\n","\u001b[31m      \u001b[0mcu -c /content/vllm/csrc/quantization/w8a8/cutlass/scaled_mm_c2x.cu -o\n","\u001b[31m      \u001b[0mCMakeFiles/_C.dir/csrc/quantization/w8a8/cutlass/scaled_mm_c2x.cu.o\n","\u001b[31m      \u001b[0mKilled\n","\u001b[31m      \u001b[0m[35/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_moe_C.dir/csrc/moe/moe_lora_align_sum_kernels.cu.o\n","\u001b[31m      \u001b[0m[36/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_moe_C.dir/csrc/moe/moe_align_sum_kernels.cu.o\n","\u001b[31m      \u001b[0m[37/443] Building CUDA object\n","\u001b[31m      \u001b[0mCMakeFiles/_moe_C.dir/csrc/moe/topk_softmax_kernels.cu.o\n","\u001b[31m      \u001b[0mninja: build stopped: subcommand failed.\n","\n","\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n","\u001b[31m      \u001b[0m/usr/local/lib/python3.10/dist-packages/setuptools_scm/_integration/version_inference.py:51:\n","\u001b[31m      \u001b[0mUserWarning: version of None already set\n","\u001b[31m      \u001b[0m  warnings.warn(self.message)\n","\u001b[31m      \u001b[0mCMake Warning at\n","\u001b[31m      \u001b[0m/usr/local/lib/python3.10/dist-packages/torch/share/cmake/Caffe2/public/cuda.cmake:140\n","\u001b[31m      \u001b[0m(message):\n","\u001b[31m      \u001b[0m  Failed to compute shorthash for libnvrtc.so\n","\u001b[31m      \u001b[0mCall Stack (most recent call first):\n","\u001b[31m      \u001b[0m  /usr/local/lib/python3.10/dist-packages/torch/share/cmake/Caffe2/Caffe2Config.cmake:86\n","\u001b[31m      \u001b[0m(include)\n","\u001b[31m      \u001b[0m  /usr/local/lib/python3.10/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:68\n","\u001b[31m      \u001b[0m(find_package)\n","\u001b[31m      \u001b[0m  CMakeLists.txt:91 (find_package)\n","\n","\n","\u001b[31m      \u001b[0mCMake Warning at\n","\u001b[31m      \u001b[0m/usr/local/lib/python3.10/dist-packages/torch/share/cmake/Caffe2/public/cuda.cmake:323\n","\u001b[31m      \u001b[0m(message):\n","\u001b[31m      \u001b[0m  pytorch is not compatible with `CMAKE_CUDA_ARCHITECTURES` and will\n","\u001b[31m      \u001b[0mignore\n","\u001b[31m      \u001b[0m  its value.  Please configure `TORCH_CUDA_ARCH_LIST` instead.\n","\u001b[31m      \u001b[0mCall Stack (most recent call first):\n","\u001b[31m      \u001b[0m  /usr/local/lib/python3.10/dist-packages/torch/share/cmake/Caffe2/Caffe2Config.cmake:86\n","\u001b[31m      \u001b[0m(include)\n","\u001b[31m      \u001b[0m  /usr/local/lib/python3.10/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:68\n","\u001b[31m      \u001b[0m(find_package)\n","\u001b[31m      \u001b[0m  CMakeLists.txt:91 (find_package)\n","\n","\n","\u001b[31m      \u001b[0mCMake Warning at\n","\u001b[31m      \u001b[0m/usr/local/lib/python3.10/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:22\n","\u001b[31m      \u001b[0m(message):\n","\u001b[31m      \u001b[0m  static library kineto_LIBRARY-NOTFOUND not found.\n","\u001b[31m      \u001b[0mCall Stack (most recent call first):\n","\u001b[31m      \u001b[0m  /usr/local/lib/python3.10/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:125\n","\u001b[31m      \u001b[0m(append_torchlib_if_found)\n","\u001b[31m      \u001b[0m  CMakeLists.txt:91 (find_package)\n","\n","\n","\u001b[31m      \u001b[0mCMake Warning (dev) at\n","\u001b[31m      \u001b[0m/usr/local/lib/python3.10/dist-packages/cmake/data/share/cmake-4.2/Modules/FetchContent.cmake:1963\n","\u001b[31m      \u001b[0m(message):\n","\u001b[31m      \u001b[0m  Calling FetchContent_Populate(qutlass) is deprecated, call\n","\u001b[31m      \u001b[0m  FetchContent_MakeAvailable(qutlass) instead.  Policy CMP0169 can be\n","\u001b[31m      \u001b[0mset to\n","\u001b[31m      \u001b[0m  OLD to allow FetchContent_Populate(qutlass) to be called directly\n","\u001b[31m      \u001b[0mfor now,\n","\u001b[31m      \u001b[0m  but the ability to call it with declared details will be removed\n","\u001b[31m      \u001b[0mcompletely\n","\u001b[31m      \u001b[0m  in a future version.\n","\u001b[31m      \u001b[0mCall Stack (most recent call first):\n","\u001b[31m      \u001b[0m  cmake/external_projects/qutlass.cmake:27 (FetchContent_Populate)\n","\u001b[31m      \u001b[0m  CMakeLists.txt:1036 (include)\n","\u001b[31m      \u001b[0mThis warning is for project developers.  Use -Wno-dev to suppress it.\n","\n","\u001b[31m      \u001b[0mCMake Warning at .deps/vllm-flash-attn-src/CMakeLists.txt:77 (message):\n","\u001b[31m      \u001b[0m  Pytorch version 2.4.0 expected for CUDA build, saw 2.9.0 instead.\n","\n","\n","\u001b[31m      \u001b[0mTraceback (most recent call last):\n","\u001b[31m      \u001b[0m  File \"<string>\", line 11, in <module>\n","\u001b[31m      \u001b[0m  File \"/usr/local/lib/python3.10/dist-packages/setuptools/build_meta.py\",\n","\u001b[31m      \u001b[0mline 435, in build_wheel\n","\u001b[31m      \u001b[0m    return _build(['bdist_wheel', '--dist-info-dir',\n","\u001b[31m      \u001b[0mstr(metadata_directory)])\n","\u001b[31m      \u001b[0m  File \"/usr/local/lib/python3.10/dist-packages/setuptools/build_meta.py\",\n","\u001b[31m      \u001b[0mline 423, in _build\n","\u001b[31m      \u001b[0m    return self._build_with_temp_dir(\n","\u001b[31m      \u001b[0m  File \"/usr/local/lib/python3.10/dist-packages/setuptools/build_meta.py\",\n","\u001b[31m      \u001b[0mline 404, in _build_with_temp_dir\n","\u001b[31m      \u001b[0m    self.run_setup()\n","\u001b[31m      \u001b[0m  File \"/usr/local/lib/python3.10/dist-packages/setuptools/build_meta.py\",\n","\u001b[31m      \u001b[0mline 317, in run_setup\n","\u001b[31m      \u001b[0m    exec(code, locals())\n","\u001b[31m      \u001b[0m  File \"<string>\", line 708, in <module>\n","\u001b[31m      \u001b[0m  File \"/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py\",\n","\u001b[31m      \u001b[0mline 115, in setup\n","\u001b[31m      \u001b[0m    return distutils.core.setup(**attrs)\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\",\n","\u001b[31m      \u001b[0mline 186, in setup\n","\u001b[31m      \u001b[0m    return run_commands(dist)\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\",\n","\u001b[31m      \u001b[0mline 202, in run_commands\n","\u001b[31m      \u001b[0m    dist.run_commands()\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\",\n","\u001b[31m      \u001b[0mline 1002, in run_commands\n","\u001b[31m      \u001b[0m    self.run_command(cmd)\n","\u001b[31m      \u001b[0m  File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\",\n","\u001b[31m      \u001b[0mline 1102, in run_command\n","\u001b[31m      \u001b[0m    super().run_command(command)\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\",\n","\u001b[31m      \u001b[0mline 1021, in run_command\n","\u001b[31m      \u001b[0m    cmd_obj.run()\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/command/bdist_wheel.py\",\n","\u001b[31m      \u001b[0mline 370, in run\n","\u001b[31m      \u001b[0m    self.run_command(\"build\")\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py\",\n","\u001b[31m      \u001b[0mline 357, in run_command\n","\u001b[31m      \u001b[0m    self.distribution.run_command(command)\n","\u001b[31m      \u001b[0m  File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\",\n","\u001b[31m      \u001b[0mline 1102, in run_command\n","\u001b[31m      \u001b[0m    super().run_command(command)\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\",\n","\u001b[31m      \u001b[0mline 1021, in run_command\n","\u001b[31m      \u001b[0m    cmd_obj.run()\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build.py\",\n","\u001b[31m      \u001b[0mline 135, in run\n","\u001b[31m      \u001b[0m    self.run_command(cmd_name)\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py\",\n","\u001b[31m      \u001b[0mline 357, in run_command\n","\u001b[31m      \u001b[0m    self.distribution.run_command(command)\n","\u001b[31m      \u001b[0m  File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\",\n","\u001b[31m      \u001b[0mline 1102, in run_command\n","\u001b[31m      \u001b[0m    super().run_command(command)\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\",\n","\u001b[31m      \u001b[0mline 1021, in run_command\n","\u001b[31m      \u001b[0m    cmd_obj.run()\n","\u001b[31m      \u001b[0m  File \"<string>\", line 284, in run\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/command/build_ext.py\",\n","\u001b[31m      \u001b[0mline 96, in run\n","\u001b[31m      \u001b[0m    _build_ext.run(self)\n","\u001b[31m      \u001b[0m  File\n","\u001b[31m      \u001b[0m\"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\",\n","\u001b[31m      \u001b[0mline 368, in run\n","\u001b[31m      \u001b[0m    self.build_extensions()\n","\u001b[31m      \u001b[0m  File \"<string>\", line 253, in build_extensions\n","\u001b[31m      \u001b[0m  File \"/usr/lib/python3.10/subprocess.py\", line 369, in check_call\n","\u001b[31m      \u001b[0m    raise CalledProcessError(retcode, cmd)\n","\u001b[31m      \u001b[0msubprocess.CalledProcessError: Command '['cmake', '--build',\n","\u001b[31m      \u001b[0m'.', '-j=4', '--target=_moe_C', '--target=cumem_allocator',\n","\u001b[31m      \u001b[0m'--target=_vllm_fa2_C', '--target=_vllm_fa3_C', '--target=_flashmla_C',\n","\u001b[31m      \u001b[0m'--target=_flashmla_extension_C', '--target=_C']' returned non-zero exit\n","\u001b[31m      \u001b[0mstatus 137.\n","\n","\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This usually indicates a problem with the package or the build\n","\u001b[31m      \u001b[0menvironment.\n","\u001b[34mDEBUG\u001b[39m Released lock at `/tmp/uv-5117a8cdc2a02a18.lock`\n","\u001b[34mDEBUG\u001b[39m Released lock at `/root/.cache/uv/.lock`\n"]}],"source":["# can leave off the --python 3.10, should work on 3.12\n","!VLLM_TARGET_DEVICE=cuda uv pip install --python 3.10 . -v --no-build-isolation -v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PykHn5jEPbXl"},"outputs":[],"source":["import vllm\n","vllm.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cD2G-uJjTpf6"},"outputs":[],"source":["from vllm import LLM\n","llm = LLM(\"gpt2\")\n","\n","engine = llm.llm_engine\n","print(engine.model_executor.driver_worker.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["46fe76bd8d7040b5a25476843ef4de42","21471a7f56a247ab877262d81be19f52","5bab41a75dd94a25acf9eb1f5fb37c19","2c56ad7431e945dca7c8866c3243101d","e7aefaf8127b438aa54671eed68a8ded","84311cf3d05149129608f87b65e54368","d2ddd61263bb44f2a0a5bd4a192b0055","3d30b4c8d53b4f94aac194815e5b37f1","8c611d818f104db0bb59591ad93735e3","eae068103346425c8be3518d7a55ccaa","3f6635d2cd624c96aea8427644475183","7429e6efd6c24c56bde773e90a9b4596","e238ac5e2c5a4045a9bf9693e6bd3503","52fa7880598a4028a0b6cd80ef9adbb3","cdc385cb69f546ee9e00f0975169c261","86665449e97747af95b25eb2a7449801","21f9a82b630d4746a2dd5e1be8b0d48a","3008197fae974e41ac0d4c70ab84f95f","b49ff3104fce40d99f5f0aeab5cd16f4","918b00ebf25344e79e5a6e48a164a1aa","c5884b09520840858c458500df3435a7","f6220a02b3cd4a0a951b1507fd7670b2","3bb54182021e4eba9b309b87de58abcb","a5762dcb4ce64419a8744a69805d27dd","3101b484a78c4b3d9d28788e96534ff5","513c072c084a460e88824e6284dc7a3f","ecaa7e71967e4616be09071c68bbdc02","da72cbbc603044fdb6a28c42b6b449e9","60ef08481eeb4c6486cc8c35b90d77d6","947d93a8a6ad46c89ab56d551da738c3","804d3e730988497f8c4e2165b2ca68da","440b77549572402284a31356ee717870","8149d962342c46daa5e030151b902bbe","baed747e0a2a4e2092ed9dfdfbedd14a","2b2a4cc3bc31477b852a32cd8121c990","96e6a57de1004d8388b053edf4e88e79","9459fc8d95a54619871679b6c7dbe9db","86de03adccdc481cb1ca578059e06702","11eac913eabc4694baf70f858e1d23ba","5e13a0fe01314588a0e256e83e63eaba","78707284241a439a965417eadc21e4e1","2adcfdf8db024b66b5573499221f4a08","c8d037babeac4c8ba4fe577cc37a0d8d","dc24f059fab94ff5a0a611b3b0559a0b","d6c8f2fd80b34b64ba6da8f285b8c795","866019f8091341d180d2d2551e0520a8","fc2ffebc17c94e8daf87c0471d8ce117","c269fa3e7e1b4d67bae323c672923baf","2531f8d1511d4c15a0c0e6412f08d480","117aeb5d6841451394ca485f33ba2d9a","d80a000ce7a0444fba9df88739bc7d1c","af9ed07f41cd43e4b38af457dd634c00","bf070d07f4e8491a9e2f92143b3e0667","cb9b188c958c4b74ab2de1777a3625b5","99c92cd4aa13485ebdd9858a8a89cb9f","ca37bad47f7f42be84dfd13f72a5a989","ee0c40dadd434180bdc248753cfb3136","0165189d47894b23b07c64cfa824546d","3817cb1b27004650b331336897c98cdd","bd1d5cda8c824c19be315594e92508aa","a086340ff7b343a0bba2eb5cc2d62c27","46e9a26adade4a8986731f61274a54b3","639701726b664ccca0966cea2678ba51","351f4330e8624ee2b10d8755be06dbc4","d03959dde4a04ab788922ccbe7e76099","0e682191fc0a4e0c9c3d3134c4115dcf","f511eb5abe4e4d12811e67c91264642b","275a41b39b374d349a1dc7d90d41be51","bbdcb080e62e43d78d99fa2d6229386e","6a9966fb9f0c461f9d9c00cadfa9a1d6","77f95bb65efe4fef868b745e249f71c6","0aa836e2827444bb8cb4929c045191a5","8e0693e2a0734d6ca5f20da4be958474","f9934be8e092499c8b53abf47f461c25","d5bd003854c7448bb781475fbe708032","dc684a44bccb4da2bb2d7ab4c87594de","58a5a5ef93254a66bcafb96852199069","ff38a1a388784c90aadfd1b4e2e73da6","2bfb60b0107c4f6ebfe69d45856e7cd4","0d0239e5c4244d70bd0bc30420acebe9","dc1201e0b1854142ba525fb3b79141da","b6172b3042bf42f4ab1aca94e78e00b4","962e8c170def419cb205cc756ee10c56","87636f0c72c246acb4722743ea70d315","377f69d9aa474004abf9d7337950cc4c","f28532d8ab50429a98f9de52cf635633","c2aa85673942457c9263940b6456ada2","e42b97798dc9426a9c2e40f32caba75a","5eda3f3072ce4128910a6e18caa9db32","7090e887268843dcb2f36046b59cd5e8","212d58f1ce5c49d5bfac0e5db83d6ea8","6dd9c73dcbbf4c16a3003f79a0e5f68b","e7c4e9421801424a8f1e2a31aa578f96","391ff001bdad4bf7acb5ca25926f4277","ce32b1a7d633474d941839704230ce69","2decf45365ca4e0c8779ec1d093a848d","55674e2fce3e47a08d51777749e51dd8","c83d6b6a0152482ca604340bc5bdf499","2d613ef8370d40949c8bd3e94af59ea5","8ddff6ac16f04e078f6534604325ac8d","18d5473a4b6340dc97c0561739614229","d56c1a0557d745908edf897af8de60a4","8424915efc404a5893987b0da06a986a","1087d1b2b0d74725b000bc9e07fba9c3","1d5c51917b4044bfa43ba4a5232f9397","8bb22c223e4049f381525d10c99b9dd1","b07550e4af784fab9aa5c5d404decf25","f2dc3ff0a2cd40428306cbe6c70dcf37","056709ca73eb44d990b9990d9fdbe206","2e6f11c2950541b3bd03f556d7a3860e","a4afd685b6b24871920d7b2ef1d0482f","2a38717f8cc746b88b6fea1d9891fee7","2f73f92bd88b4e2484c96180b90df78c","b89c86e5863843b6be5d0896c82c00af","9f33629411fc4e7aac4a70a7bf84d867","c278e9e826ae43beb2d4ac81fafe956a","f62aae1c59394eb58fb9df01a3628764","1b4dacaa78d84b5982d01ece05d45be3","2ff8fba4592d42f099dd1bbc67aec8e8","ad952cc41b5f45858d0b211ab5055397","6509aa8d44914af99d534f4ba5c8af56","dba0ba4f3d494d10aa1c8965f463af5a","c8c1fb2221694d8298d2994d5453dbc1","f09cc00186214845afa3770b92269e89","eabbf4ff588e4f9e891d6217c1303e9f","93123f4763b948c2b42a5e2f8210bc35","00bea1d79b5a4b3e911070c9c03fccf1","513071b094ab4d19825029c3542ae61b","fbf7161ef02a4c8db1bb73aab1fa03fc","cdb1ffc07da84dd68f697c1be60b7638","d691981d65a0493eb9f194a91d200560","914278c3cae54264acb653a33f11c81f","673892063e354f66945d1280ac178a9b","0ff0a7e275e84b84972aa9ad7e638e3d","605d7827e679422ab8feb0719e5a2d96","2f2574f5a565412aba5ffa859dc324da","08420f74b6c344dca941855325e3e3b6","6ff10dc18f0948cc934fda373b307ca6","6b4e2e5b4b2e40188562e00fafe1d322","9b31e6ae61254202b670c2d4bec50ee6","a5c7b1ca05a74b6399be504d0f91820a","8c2bb819e460425ca6e43e259068e7c6","0beffe9ebba64cad9f1bcca42a862e32","40b9d0c6a39a4630bb59cac6e556c811","7f4a6c096b984feb876b10c44c0aa396","517c5619c91047b99115ccfbc2bc084d","e9f94e49e88c4b069f776138652a1f3b","932bafc45b72459b9ab4173f1950e9b1","a014743e6d4b4c9a9bea7da1287c900c","4fd2e3ebc30b43d69fd05b167a0cee7d","29aa0a8aeef64b85b99667715a8e6b26","6c95bed5026242d588ed06f64af74689","6fb373c8a0cb49beade6d71dec0fdf98","1b25b411f2424456950ca33b87b932dc","006ecbdf34b943dd937ffd2b6c566026","8529e2577f7c43aeb639378bbedc2b8f","f37253c8d7c84e82b85c7ed98ba0a829","df59ed47ba9045af934227128095542d","ab40cddd63c1433c954402a29292a9b7","ff21f42febc340589b0dc73fdda83b26","1ba7974ddb3b4e4cbb54e1bc29b8edf4","257388c3bf1246f88fa57b947c5ba291","83cb4f1edfa442acaeb54e92a00dc55f","1e4d76c4ef234d1792839e692e1139ce","37b87ed888604d219f85f76f18fef166"]},"executionInfo":{"elapsed":224388,"status":"ok","timestamp":1767007602137,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"bMc0sL8PwT2e","outputId":"45d1ad08-b7c0-4d97-b556-42fd5e4e576a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46fe76bd8d7040b5a25476843ef4de42","version_major":2,"version_minor":0},"text/plain":["README.md: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7429e6efd6c24c56bde773e90a9b4596","version_major":2,"version_minor":0},"text/plain":["wikitext-2-raw-v1/test-00000-of-00001.pa():   0%|          | 0.00/733k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bb54182021e4eba9b309b87de58abcb","version_major":2,"version_minor":0},"text/plain":["wikitext-2-raw-v1/train-00000-of-00001.p():   0%|          | 0.00/6.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"baed747e0a2a4e2092ed9dfdfbedd14a","version_major":2,"version_minor":0},"text/plain":["wikitext-2-raw-v1/validation-00000-of-00():   0%|          | 0.00/657k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6c8f2fd80b34b64ba6da8f285b8c795","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca37bad47f7f42be84dfd13f72a5a989","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f511eb5abe4e4d12811e67c91264642b","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff38a1a388784c90aadfd1b4e2e73da6","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5eda3f3072ce4128910a6e18caa9db32","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ddff6ac16f04e078f6534604325ac8d","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4afd685b6b24871920d7b2ef1d0482f","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dba0ba4f3d494d10aa1c8965f463af5a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Vocab size: 50257\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"673892063e354f66945d1280ac178a9b","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/4358 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40b9d0c6a39a4630bb59cac6e556c811","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/36718 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"006ecbdf34b943dd937ffd2b6c566026","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/3760 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Train blocks: torch.Size([18686, 127]) Val blocks: torch.Size([1931, 127])\n","Number of parameters: 28.923648 M\n","Step 100/2000 | train loss: 6.9055 | val loss: 6.9795\n","Step 200/2000 | train loss: 6.6285 | val loss: 6.5550\n","Step 300/2000 | train loss: 6.4293 | val loss: 6.3343\n","Step 400/2000 | train loss: 6.0299 | val loss: 6.1891\n","Step 500/2000 | train loss: 6.2031 | val loss: 6.0776\n","Step 600/2000 | train loss: 5.9669 | val loss: 5.9886\n","Step 700/2000 | train loss: 5.7596 | val loss: 5.9239\n","Step 800/2000 | train loss: 5.5217 | val loss: 5.8452\n","Step 900/2000 | train loss: 5.6529 | val loss: 5.7835\n","Step 1000/2000 | train loss: 5.5582 | val loss: 5.7263\n","Step 1100/2000 | train loss: 5.4097 | val loss: 5.6738\n","Step 1200/2000 | train loss: 5.1860 | val loss: 5.6362\n","Step 1300/2000 | train loss: 5.1045 | val loss: 5.6093\n","Step 1400/2000 | train loss: 5.1163 | val loss: 5.5651\n","Step 1500/2000 | train loss: 5.0822 | val loss: 5.5286\n","Step 1600/2000 | train loss: 5.1152 | val loss: 5.4892\n","Step 1700/2000 | train loss: 5.0553 | val loss: 5.4503\n","Step 1800/2000 | train loss: 4.7914 | val loss: 5.4392\n","Step 1900/2000 | train loss: 4.8730 | val loss: 5.4192\n","Step 2000/2000 | train loss: 4.8764 | val loss: 5.3988\n","Training finished.\n","=== SAMPLE ===\n","Wikipedia is a long @-@ age ( 2 @.@ 2 @.@ 2 to 7 million in ) . In the first round of the second season , the fourth season included most of the Grand Slam Cup , and the first time record , though their\n"]}],"source":["# ============================================================\n","# TinyLLM on WikiText-2 (decoder-only Transformer, from scratch)\n","# Colab-ready, pure PyTorch + HuggingFace Datasets/Tokenizer\n","# ============================================================\n","\n","!pip install -q datasets transformers\n","\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from datasets import load_dataset\n","from transformers import AutoTokenizer\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using device:\", device)\n","\n","# -----------------------------\n","# 1. Hyperparameters\n","# -----------------------------\n","block_size   = 128      # max sequence length\n","batch_size   = 32\n","n_layers     = 4\n","n_heads      = 4\n","d_model      = 256\n","d_ff         = 4 * d_model\n","dropout      = 0.1\n","learning_rate = 3e-4\n","max_steps    = 2000      # small for demo; bump up to really train\n","print_every  = 100\n","\n","\n","# -----------------------------\n","# 2. Load WikiText-2 and tokenizer\n","# -----------------------------\n","dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","# ensure we have a pad token\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","vocab_size = tokenizer.vocab_size\n","print(\"Vocab size:\", vocab_size)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"])\n","\n","tokenized = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n","\n","# -----------------------------\n","# 3. Turn token stream into fixed-length blocks\n","# -----------------------------\n","def make_block_dataset(split):\n","    ids = tokenized[split][\"input_ids\"]\n","    # flatten all sequences into one long list\n","    all_ids = [tok for seq in ids for tok in seq]\n","    # trim so it divides evenly into block_size\n","    n = (len(all_ids) // block_size) * block_size\n","    all_ids = all_ids[:n]\n","    # shape: (num_blocks, block_size)\n","    data = torch.tensor(all_ids, dtype=torch.long).view(-1, block_size)\n","    # inputs: everything except last token; targets: everything except first token\n","    x = data[:, :-1]\n","    y = data[:, 1:]\n","    return x, y\n","\n","train_x, train_y = make_block_dataset(\"train\")\n","val_x,   val_y   = make_block_dataset(\"validation\")\n","\n","print(\"Train blocks:\", train_x.shape, \"Val blocks:\", val_x.shape)\n","\n","class BlockDataset(Dataset):\n","    def __init__(self, x, y):\n","        self.x = x\n","        self.y = y\n","    def __len__(self):\n","        return self.x.size(0)\n","    def __getitem__(self, idx):\n","        return self.x[idx], self.y[idx]\n","\n","train_ds = BlockDataset(train_x, train_y)\n","val_ds   = BlockDataset(val_x,   val_y)\n","\n","train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n","val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=True)\n","\n","\n","# -----------------------------\n","# 4. TinyLLM model (GPT-style)\n","# -----------------------------\n","class CausalSelfAttention(nn.Module):\n","    def __init__(self, d_model, n_heads, block_size, dropout=0.1):\n","        super().__init__()\n","        assert d_model % n_heads == 0\n","        self.n_heads   = n_heads\n","        self.head_dim  = d_model // n_heads\n","        self.block_size = block_size\n","\n","        self.qkv = nn.Linear(d_model, 3 * d_model)\n","        self.proj = nn.Linear(d_model, d_model)\n","        self.attn_drop = nn.Dropout(dropout)\n","        self.resid_drop = nn.Dropout(dropout)\n","\n","        # causal mask: (1, 1, T, T)\n","        mask = torch.tril(torch.ones(block_size, block_size)).view(1, 1, block_size, block_size)\n","        self.register_buffer(\"mask\", mask)\n","\n","    def forward(self, x):\n","        B, T, C = x.shape\n","        qkv = self.qkv(x)  # (B, T, 3*C)\n","        q, k, v = qkv.chunk(3, dim=-1)\n","\n","        # shape (B, n_heads, T, head_dim)\n","        q = q.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n","        k = k.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n","        v = v.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n","\n","        att = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim)  # (B, h, T, T)\n","        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float(\"-inf\"))\n","        att = F.softmax(att, dim=-1)\n","        att = self.attn_drop(att)\n","\n","        y = att @ v  # (B, h, T, head_dim)\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)\n","        y = self.resid_drop(self.proj(y))\n","        return y\n","\n","\n","class Block(nn.Module):\n","    def __init__(self, d_model, n_heads, d_ff, block_size, dropout=0.1):\n","        super().__init__()\n","        self.ln1 = nn.LayerNorm(d_model)\n","        self.ln2 = nn.LayerNorm(d_model)\n","        self.attn = CausalSelfAttention(d_model, n_heads, block_size, dropout)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(d_model, d_ff),\n","            nn.GELU(),\n","            nn.Linear(d_ff, d_model),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        x = x + self.attn(self.ln1(x))\n","        x = x + self.mlp(self.ln2(x))\n","        return x\n","\n","\n","class TinyLLM(nn.Module):\n","    def __init__(self, vocab_size, d_model, n_layers, n_heads, d_ff, block_size, dropout=0.1):\n","        super().__init__()\n","        self.block_size = block_size\n","        self.tok_emb = nn.Embedding(vocab_size, d_model)\n","        self.pos_emb = nn.Embedding(block_size,  d_model)\n","        self.drop = nn.Dropout(dropout)\n","        self.blocks = nn.ModuleList([\n","            Block(d_model, n_heads, d_ff, block_size, dropout) for _ in range(n_layers)\n","        ])\n","        self.ln_f = nn.LayerNorm(d_model)\n","        self.head = nn.Linear(d_model, vocab_size, bias=False)\n","\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, (nn.Linear, nn.Embedding)):\n","            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","        if isinstance(module, nn.Linear) and module.bias is not None:\n","            nn.init.zeros_(module.bias)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","        assert T <= self.block_size, \"Sequence too long\"\n","\n","        pos = torch.arange(0, T, device=idx.device).unsqueeze(0)  # (1, T)\n","        x = self.tok_emb(idx) + self.pos_emb(pos)  # (B, T, C)\n","        x = self.drop(x)\n","\n","        for block in self.blocks:\n","            x = block(x)\n","        x = self.ln_f(x)\n","        logits = self.head(x)  # (B, T, vocab_size)\n","\n","        loss = None\n","        if targets is not None:\n","            loss = F.cross_entropy(\n","                logits.view(-1, logits.size(-1)),\n","                targets.view(-1),\n","                ignore_index=-100\n","            )\n","        return logits, loss\n","\n","    @torch.no_grad()\n","    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n","        # simple autoregressive sampling\n","        for _ in range(max_new_tokens):\n","            idx_cond = idx[:, -self.block_size:]\n","            logits, _ = self(idx_cond)\n","            logits = logits[:, -1, :] / temperature\n","\n","            if top_k is not None:\n","                v, _ = torch.topk(logits, top_k)\n","                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n","\n","            probs = F.softmax(logits, dim=-1)\n","            next_token = torch.multinomial(probs, num_samples=1)\n","            idx = torch.cat([idx, next_token], dim=1)\n","        return idx\n","\n","model = TinyLLM(\n","    vocab_size=vocab_size,\n","    d_model=d_model,\n","    n_layers=n_layers,\n","    n_heads=n_heads,\n","    d_ff=d_ff,\n","    block_size=block_size-1,  # because we use T-1 inputs\n","    dropout=dropout,\n",").to(device)\n","\n","print(\"Number of parameters:\", sum(p.numel() for p in model.parameters()) / 1e6, \"M\")\n","\n","\n","# -----------------------------\n","# 5. Training loop\n","# -----------------------------\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","def evaluate(loader, max_batches=50):\n","    model.eval()\n","    losses = []\n","    with torch.no_grad():\n","        for i, (x, y) in enumerate(loader):\n","            if i >= max_batches:\n","                break\n","            x = x.to(device)\n","            y = y.to(device)\n","            _, loss = model(x, y)\n","            losses.append(loss.item())\n","    model.train()\n","    return sum(losses) / len(losses) if losses else None\n","\n","step = 0\n","while step < max_steps:\n","    for x, y in train_loader:\n","        step += 1\n","        x = x.to(device)\n","        y = y.to(device)\n","\n","        _, loss = model(x, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        if step % print_every == 0:\n","            val_loss = evaluate(val_loader)\n","            print(f\"Step {step}/{max_steps} | train loss: {loss.item():.4f} | val loss: {val_loss:.4f}\")\n","\n","        if step >= max_steps:\n","            break\n","\n","print(\"Training finished.\")\n","\n","\n","# -----------------------------\n","# 6. Quick generation demo\n","# -----------------------------\n","model.eval()\n","prompt = \"Wikipedia is\"\n","input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n","out = model.generate(input_ids, max_new_tokens=50, temperature=0.8, top_k=50)\n","print(\"=== SAMPLE ===\")\n","print(tokenizer.decode(out[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1767007824839,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"DzLlMkhgwT45","outputId":"df8458bd-dfd9-4a86-c3f3-bd2128ebe2e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved TinyLLM + tokenizer to: tinyllm_wikitext2\n"]}],"source":["import os\n","save_dir = \"tinyllm_wikitext2\"\n","\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# 1) Save model weights\n","torch.save(model.state_dict(), os.path.join(save_dir, \"pytorch_model.bin\"))\n","\n","# 2) Save tokenizer\n","tokenizer.save_pretrained(save_dir)\n","\n","# 3) Save config / hyperparams\n","import json\n","\n","config = {\n","    \"vocab_size\": vocab_size,\n","    \"d_model\": d_model,\n","    \"n_layers\": n_layers,\n","    \"n_heads\": n_heads,\n","    \"d_ff\": d_ff,\n","    \"block_size\": block_size - 1,\n","    \"dropout\": dropout,\n","}\n","with open(os.path.join(save_dir, \"tinyllm_config.json\"), \"w\") as f:\n","    json.dump(config, f, indent=2)\n","\n","print(f\"Saved TinyLLM + tokenizer to: {save_dir}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":904,"status":"ok","timestamp":1767009207809,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"NU2Eh2BiCTuS","outputId":"0e354284-2fd5-43ad-f31d-36b692f55baa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wikipedia is the first season of the season . The first half @-@ month player , including the final game , one two games , respectively . \n"," = = = = = Production = = = \n"," = = = Track listing = = = = \n"]}],"source":["import json\n","import torch\n","#\n","with open(\"tinyllm_wikitext2/tinyllm_config.json\") as f:\n","    cfg = json.load(f)\n","\n","reloaded_model = TinyLLM(\n","    vocab_size=cfg[\"vocab_size\"],\n","    d_model=cfg[\"d_model\"],\n","    n_layers=cfg[\"n_layers\"],\n","    n_heads=cfg[\"n_heads\"],\n","    d_ff=cfg[\"d_ff\"],\n","    block_size=cfg[\"block_size\"],\n","    dropout=cfg[\"dropout\"],\n",").to(device)\n","\n","state = torch.load(\"tinyllm_wikitext2/pytorch_model.bin\", map_location=device)\n","reloaded_model.load_state_dict(state)\n","reloaded_model.eval()\n","\n","tok = AutoTokenizer.from_pretrained(\"tinyllm_wikitext2\")\n","prompt = \"Wikipedia is\"\n","inp = tok.encode(prompt, return_tensors=\"pt\").to(device)\n","out = reloaded_model.generate(inp, max_new_tokens=50, temperature=0.8, top_k=50)\n","print(tok.decode(out[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KLfw5OKhCTwy"},"outputs":[],"source":["# GPT-2 supported by vllm."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1767010871214,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"d75zg7nhCTzW","outputId":"6f6da7bb-5590-4670-9ea2-ed8334c8768e"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"TinyLLMForCausalLM\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 128,\n","  \"n_embd\": 256,\n","  \"n_head\": 4,\n","  \"n_inner\": null,\n","  \"n_layer\": 4,\n","  \"n_positions\": 128,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.57.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"]}],"source":["from transformers import AutoConfig\n","cfg = AutoConfig.from_pretrained(\"/content/tinyllm_wikitext2\")\n","print(cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1767009471393,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"U5C2JA1eCT1b","outputId":"794a237f-bed3-45ce-c105-7518ba89cfc8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wrote new config.json\n"]}],"source":["import os, json\n","from transformers import GPT2Config\n","\n","save_dir = \"/content/tinyllm_wikitext2\"\n","\n","# Your current tiny config:\n","raw = {\n","  \"vocab_size\": 50257,\n","  \"d_model\": 256,\n","  \"n_layers\": 4,\n","  \"n_heads\": 4,\n","  \"d_ff\": 1024,\n","  \"block_size\": 127,\n","  \"dropout\": 0.1,\n","}\n","\n","config = GPT2Config(\n","    vocab_size     = raw[\"vocab_size\"],\n","    n_positions    = raw[\"block_size\"] + 1,  # because your model uses T-1 inputs\n","    n_ctx          = raw[\"block_size\"] + 1,\n","    n_embd         = raw[\"d_model\"],\n","    n_layer        = raw[\"n_layers\"],\n","    n_head         = raw[\"n_heads\"],\n","    activation_function = \"gelu_new\",\n","    resid_pdrop    = raw[\"dropout\"],\n","    embd_pdrop     = raw[\"dropout\"],\n","    attn_pdrop     = raw[\"dropout\"],\n",")\n","\n","cfg = config.to_dict()\n","cfg[\"_name_or_path\"] = \"tinyllm-wikitext2\"\n","cfg[\"architectures\"] = [\"TinyLLMForCausalLM\"]  # <- vLLM will look for this backend\n","\n","with open(os.path.join(save_dir, \"config.json\"), \"w\") as f:\n","    json.dump(cfg, f, indent=2)\n","\n","print(\"Wrote new config.json\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1767011324358,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"kdYvvjSqFQZO","outputId":"057d7dc4-8379-480e-a355-4bd2f501c089"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'> gpt2 256 4 4\n"]}],"source":["from transformers import AutoConfig\n","\n","cfg = AutoConfig.from_pretrained(\"/content/tinyllm_wikitext2\")\n","print(type(cfg), cfg.model_type, cfg.n_embd, cfg.n_layer, cfg.n_head)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1356,"status":"ok","timestamp":1767011461999,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":480},"id":"uL3svkFrFxYm","outputId":"d29f5137-7dc4-4197-bf1b-3439fd0ea42d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wrote clean config.json\n"]}],"source":["import os, json\n","from transformers import GPT2Config, AutoTokenizer\n","\n","save_dir = \"/content/tinyllm_wikitext2\"\n","\n","# use the tokenizer you trained with to get bos/eos/pad\n","tok = AutoTokenizer.from_pretrained(\"gpt2\")\n","if tok.pad_token is None:\n","    tok.pad_token = tok.eos_token\n","\n","config = GPT2Config(\n","    vocab_size = tok.vocab_size,\n","    n_positions = 128,\n","    n_ctx       = 128,\n","    n_embd      = 256,\n","    n_layer     = 4,\n","    n_head      = 4,\n","    activation_function = \"gelu_new\",\n","    resid_pdrop = 0.1,\n","    embd_pdrop  = 0.1,\n","    attn_pdrop  = 0.1,\n","    bos_token_id = tok.bos_token_id or tok.eos_token_id,\n","    eos_token_id = tok.eos_token_id,\n","    pad_token_id = tok.pad_token_id,\n",")\n","\n","cfg = config.to_dict()\n","cfg[\"_name_or_path\"] = \"tinyllm-wikitext2\"\n","cfg[\"architectures\"] = [\"TinyLLMForCausalLM\"]  # your vLLM backend\n","cfg[\"id2label\"] = {\"0\": \"LABEL_0\"}            # if you really want this\n","\n","with open(os.path.join(save_dir, \"config.json\"), \"w\") as f:\n","    json.dump(cfg, f, indent=2)\n","\n","print(\"Wrote clean config.json\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1YvXYCiFxa3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_thtL5aBFxdO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elw0cq0gFxfw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oM9kV27zFxiL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gdus1AVrFxkl"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xyg0zCNNC5f5"},"outputs":[],"source":["!pip install \"vllm>=0.5.0\" \"transformers>=4.45.0\" torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KgNeysLCwT77"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUEClxdsC5if"},"outputs":[],"source":["import os\n","import json\n","from dataclasses import dataclass\n","from typing import Optional, Tuple, Union\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from transformers import (\n","    PretrainedConfig,\n","    PreTrainedModel,\n","    AutoTokenizer,\n",")\n","from transformers.modeling_outputs import CausalLMOutputWithPast\n","\n","# In recent HF, ALL_ATTENTION_FUNCTIONS is shared between backends.\n","# If this import fails, search in your transformers installation for ALL_ATTENTION_FUNCTIONS\n","from transformers.models.llama.modeling_llama import ALL_ATTENTION_FUNCTIONS\n","\n","from vllm import LLM\n","\n","\n","# -----------------------------\n","# 1. Config\n","# -----------------------------\n","class ToyConfig(PretrainedConfig):\n","    model_type = \"toy-transformer\"\n","\n","    def __init__(\n","        self,\n","        vocab_size: int = 50257,   # match GPT-2 tokenizer\n","        hidden_size: int = 128,\n","        num_hidden_layers: int = 2,\n","        num_attention_heads: int = 4,\n","        intermediate_size: int = 256,\n","        max_position_embeddings: int = 512,\n","        **kwargs,\n","    ):\n","        super().__init__(**kwargs)\n","        self.vocab_size = vocab_size\n","        self.hidden_size = hidden_size\n","        self.num_hidden_layers = num_hidden_layers\n","        self.num_attention_heads = num_attention_heads\n","        self.intermediate_size = intermediate_size\n","        self.max_position_embeddings = max_position_embeddings\n","\n","        # vLLM/Transformers backend stuff\n","        # This tells vLLM that the base model supports its attention backend.\n","        self._attn_implementation = \"vllm\"\n","        self.is_decoder = True\n","        self.is_encoder_decoder = False\n","\n","\n","# -----------------------------\n","# 2. Attention block compatible with vLLM backend\n","# -----------------------------\n","class ToyAttention(nn.Module):\n","    # decoder-only causal LM, so attention is causal\n","    is_causal = True\n","\n","    def __init__(self, config: ToyConfig):\n","        super().__init__()\n","        self.config = config\n","        self.num_heads = config.num_attention_heads\n","        self.head_dim = config.hidden_size // config.num_attention_heads\n","\n","        self.q_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","        self.k_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","        self.v_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","        self.o_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","\n","    def forward(\n","        self,\n","        hidden_states: torch.Tensor,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        **kwargs,\n","    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n","        bsz, seqlen, h = hidden_states.shape\n","        head_dim = self.head_dim\n","        num_heads = self.num_heads\n","\n","        # project to Q, K, V\n","        q = self.q_proj(hidden_states)\n","        k = self.k_proj(hidden_states)\n","        v = self.v_proj(hidden_states)\n","\n","        # (bsz, seqlen, num_heads, head_dim) -> (bsz, num_heads, seqlen, head_dim)\n","        def shape(x):\n","            return (\n","                x.view(bsz, seqlen, num_heads, head_dim)\n","                .transpose(1, 2)\n","                .contiguous()\n","            )\n","\n","        q = shape(q)\n","        k = shape(k)\n","        v = shape(v)\n","\n","        # This is the crucial hook: use vLLM attention backend\n","        attention_interface = ALL_ATTENTION_FUNCTIONS[self.config._attn_implementation]\n","        attn_output, attn_weights = attention_interface(\n","            self,\n","            query_states=q,\n","            key_states=k,\n","            value_states=v,\n","            attention_mask=attention_mask,\n","            is_causal=self.is_causal,\n","            **kwargs,\n","        )\n","\n","        # (bsz, num_heads, seqlen, head_dim) -> (bsz, seqlen, h)\n","        attn_output = (\n","            attn_output.transpose(1, 2)\n","            .reshape(bsz, seqlen, h)\n","            .contiguous()\n","        )\n","        attn_output = self.o_proj(attn_output)\n","        return attn_output, attn_weights\n","\n","\n","class ToyMLP(nn.Module):\n","    def __init__(self, config: ToyConfig):\n","        super().__init__()\n","        self.fc1 = nn.Linear(config.hidden_size, config.intermediate_size)\n","        self.fc2 = nn.Linear(config.intermediate_size, config.hidden_size)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        return self.fc2(F.gelu(self.fc1(x)))\n","\n","\n","class ToyBlock(nn.Module):\n","    def __init__(self, config: ToyConfig):\n","        super().__init__()\n","        self.self_attn = ToyAttention(config)\n","        self.mlp = ToyMLP(config)\n","        self.ln1 = nn.LayerNorm(config.hidden_size)\n","        self.ln2 = nn.LayerNorm(config.hidden_size)\n","\n","    def forward(\n","        self,\n","        hidden_states: torch.Tensor,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        **kwargs,\n","    ) -> torch.Tensor:\n","        # Self-attention\n","        residual = hidden_states\n","        hidden_states = self.ln1(hidden_states)\n","        attn_output, _ = self.self_attn(\n","            hidden_states,\n","            attention_mask=attention_mask,\n","            **kwargs,\n","        )\n","        hidden_states = residual + attn_output\n","\n","        # MLP\n","        residual = hidden_states\n","        hidden_states = self.ln2(hidden_states)\n","        hidden_states = residual + self.mlp(hidden_states)\n","        return hidden_states\n","\n","\n","# -----------------------------\n","# 3. Base model (decoder LM) + LM head\n","# -----------------------------\n","class ToyModel(PreTrainedModel):\n","    config_class = ToyConfig\n","    _supports_attention_backend = True  # required for vLLM backend\n","\n","    def __init__(self, config: ToyConfig):\n","        super().__init__(config)\n","        self.config = config\n","\n","        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size)\n","        self.embed_positions = nn.Embedding(\n","            config.max_position_embeddings, config.hidden_size\n","        )\n","\n","        self.layers = nn.ModuleList(\n","            [ToyBlock(config) for _ in range(config.num_hidden_layers)]\n","        )\n","        self.ln_f = nn.LayerNorm(config.hidden_size)\n","\n","        # Important for generation: LM head\n","        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n","\n","        self.post_init()\n","\n","    def get_input_embeddings(self):\n","        return self.embed_tokens\n","\n","    def set_input_embeddings(self, new_embeddings):\n","        self.embed_tokens = new_embeddings\n","\n","    def get_output_embeddings(self):\n","        return self.lm_head\n","\n","    def set_output_embeddings(self, new_embeddings):\n","        self.lm_head = new_embeddings\n","\n","    def forward(\n","        self,\n","        input_ids: torch.LongTensor,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        position_ids: Optional[torch.LongTensor] = None,\n","        labels: Optional[torch.LongTensor] = None,\n","        **kwargs,\n","    ) -> Union[Tuple, CausalLMOutputWithPast]:\n","        bsz, seqlen = input_ids.shape\n","\n","        if position_ids is None:\n","            position_ids = torch.arange(\n","                seqlen, dtype=torch.long, device=input_ids.device\n","            )\n","            position_ids = position_ids.unsqueeze(0).expand(bsz, seqlen)\n","\n","        inputs_embeds = self.embed_tokens(input_ids)\n","        pos_embeds = self.embed_positions(position_ids)\n","        hidden_states = inputs_embeds + pos_embeds\n","\n","        # (very simple): just apply full attention over all tokens\n","        for layer in self.layers:\n","            hidden_states = layer(\n","                hidden_states,\n","                attention_mask=attention_mask,\n","                **kwargs,\n","            )\n","\n","        hidden_states = self.ln_f(hidden_states)\n","        logits = self.lm_head(hidden_states)\n","\n","        loss = None\n","        if labels is not None:\n","            # standard LM shift\n","            shift_logits = logits[:, :-1, :].contiguous()\n","            shift_labels = labels[:, 1:].contiguous()\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(\n","                shift_logits.view(-1, self.config.vocab_size),\n","                shift_labels.view(-1),\n","            )\n","\n","        if not self.config.use_return_dict:\n","            output = (logits,)\n","            return (loss,) + output if loss is not None else output\n","\n","        return CausalLMOutputWithPast(\n","            loss=loss,\n","            logits=logits,\n","            past_key_values=None,\n","            hidden_states=None,\n","            attentions=None,\n","        )\n","\n","\n","# -----------------------------\n","# 4. Save as a HF-style model directory\n","# -----------------------------\n","def save_toy_model(model_dir: str = \"toy_vllm_model\"):\n","    os.makedirs(model_dir, exist_ok=True)\n","\n","    # use GPT-2 tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","    tokenizer.save_pretrained(model_dir)\n","\n","    config = ToyConfig(\n","        vocab_size=tokenizer.vocab_size,\n","        hidden_size=128,\n","        num_hidden_layers=2,\n","        num_attention_heads=4,\n","        intermediate_size=256,\n","        max_position_embeddings=512,\n","    )\n","\n","    # Add HF-style auto_map so Transformers/vLLM know how to import this class\n","    auto_map = {\n","        \"AutoConfig\": \"__main__.ToyConfig\",\n","        # For vLLM + Transformers backend, the base model should be the one in auto_map.\n","        # We treat ToyModel as the causal LM base.\n","        \"AutoModelForCausalLM\": \"__main__.ToyModel\",\n","    }\n","\n","    cfg_dict = config.to_dict()\n","    cfg_dict[\"auto_map\"] = auto_map\n","    cfg_dict[\"architectures\"] = [\"ToyModel\"]\n","\n","    with open(os.path.join(model_dir, \"config.json\"), \"w\") as f:\n","        json.dump(cfg_dict, f, indent=2)\n","\n","    model = ToyModel(config)\n","    model.save_pretrained(model_dir)\n","\n","    print(f\"Saved toy model + tokenizer to: {model_dir}\")\n","\n","\n","# -----------------------------\n","# 5. Load with vLLM and generate\n","# -----------------------------\n","def run_with_vllm(model_dir: str = \"toy_vllm_model\"):\n","    # Force Transformers backend; were using a Transformers-style custom model\n","    llm = LLM(model=model_dir, model_impl=\"transformers\", trust_remote_code=True)\n","\n","    prompts = [\"Hello world\", \"Once upon a time\"]\n","    outputs = llm.generate(prompts, max_tokens=20)\n","\n","    for i, out in enumerate(outputs):\n","        print(f\"\\nPrompt: {prompts[i]!r}\")\n","        print(\"Completion:\", out.outputs[0].text)\n","\n","\n","if __name__ == \"__main__\":\n","    save_toy_model()\n","    run_with_vllm()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"isosMWgC9p39"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yqI0TiHC5k1"},"outputs":[],"source":["# training toymodel\n","from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n","from toy_vllm_model import ToyModel, ToyConfig\n","from datasets import load_dataset\n","\n","# Load config + model\n","config = ToyConfig()\n","model = ToyModel(config)\n","\n","# Load a text dataset\n","dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","\n","def tokenize(example):\n","    return tokenizer(example[\"text\"], truncation=True, max_length=128)\n","tokenized = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n","\n","# Data collator for next-token prediction\n","collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=False,        # causal LM objective (autoregressive)\n",")\n","\n","args = TrainingArguments(\n","    output_dir=\"toy_trained\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    learning_rate=3e-4,\n","    warmup_steps=100,\n","    num_train_epochs=1,\n","    logging_steps=10,\n","    evaluation_strategy=\"steps\",\n","    save_strategy=\"epoch\",\n","    fp16=False,          # you can enable fp16 if you want\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    data_collator=collator,\n","    train_dataset=tokenized[\"train\"],\n","    eval_dataset=tokenized[\"validation\"]\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xw1ovQjk9sya"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U90qj6eTC5nc"},"outputs":[],"source":["# full example w training\n","\n","from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n","from toy_vllm_model import ToyModel, ToyConfig, save_toy_model\n","from datasets import load_dataset\n","\n","# Step 1: save base toy model\n","save_toy_model(\"toy_vllm_model\")\n","\n","# Step 2: load base model for training\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","config = ToyConfig(vocab_size=tokenizer.vocab_size)\n","model = ToyModel(config)\n","\n","# Step 3: load dataset\n","dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n","tokenized = dataset.map(\n","    lambda e: tokenizer(e[\"text\"], truncation=True, max_length=128),\n","    batched=True,\n","    remove_columns=[\"text\"],\n",")\n","\n","# Step 4: collator\n","collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=False,\n",")\n","\n","# Step 5: training args\n","args = TrainingArguments(\n","    output_dir=\"toy_vllm_trained\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    evaluation_strategy=\"steps\",\n","    learning_rate=3e-4,\n","    warmup_steps=50,\n","    num_train_epochs=1,\n","    save_strategy=\"epoch\",\n","    logging_steps=25,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=tokenized[\"train\"],\n","    eval_dataset=tokenized[\"validation\"],\n","    data_collator=collator,\n",")\n","\n","trainer.train()\n","\n","# Step 6: save trained model in HF format\n","trainer.save_model(\"toy_vllm_trained\")\n","\n","print(\"Training complete! Now you can serve it in vLLM:\")\n","print(\"vllm serve toy_vllm_trained --model-impl transformers --trust-remote-code\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLBdJ9jG_JVX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLBynEHwC5py"},"outputs":[],"source":["vllm serve toy_vllm_trained --model-impl transformers --trust-remote-code"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMQ1TpcAiDy1qjDI0vLDr5w"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"006ecbdf34b943dd937ffd2b6c566026":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8529e2577f7c43aeb639378bbedc2b8f","IPY_MODEL_f37253c8d7c84e82b85c7ed98ba0a829","IPY_MODEL_df59ed47ba9045af934227128095542d"],"layout":"IPY_MODEL_ab40cddd63c1433c954402a29292a9b7"}},"00bea1d79b5a4b3e911070c9c03fccf1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0165189d47894b23b07c64cfa824546d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_639701726b664ccca0966cea2678ba51","max":36718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_351f4330e8624ee2b10d8755be06dbc4","value":36718}},"056709ca73eb44d990b9990d9fdbe206":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08420f74b6c344dca941855325e3e3b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aa836e2827444bb8cb4929c045191a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0beffe9ebba64cad9f1bcca42a862e32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d0239e5c4244d70bd0bc30420acebe9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_377f69d9aa474004abf9d7337950cc4c","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f28532d8ab50429a98f9de52cf635633","value":26}},"0e682191fc0a4e0c9c3d3134c4115dcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ff0a7e275e84b84972aa9ad7e638e3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ff10dc18f0948cc934fda373b307ca6","placeholder":"","style":"IPY_MODEL_6b4e2e5b4b2e40188562e00fafe1d322","value":"Map:100%"}},"1087d1b2b0d74725b000bc9e07fba9c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"117aeb5d6841451394ca485f33ba2d9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11eac913eabc4694baf70f858e1d23ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18d5473a4b6340dc97c0561739614229":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d5c51917b4044bfa43ba4a5232f9397","placeholder":"","style":"IPY_MODEL_8bb22c223e4049f381525d10c99b9dd1","value":"vocab.json:100%"}},"1b25b411f2424456950ca33b87b932dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b4dacaa78d84b5982d01ece05d45be3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ba7974ddb3b4e4cbb54e1bc29b8edf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d5c51917b4044bfa43ba4a5232f9397":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e4d76c4ef234d1792839e692e1139ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"212d58f1ce5c49d5bfac0e5db83d6ea8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2decf45365ca4e0c8779ec1d093a848d","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55674e2fce3e47a08d51777749e51dd8","value":665}},"21471a7f56a247ab877262d81be19f52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84311cf3d05149129608f87b65e54368","placeholder":"","style":"IPY_MODEL_d2ddd61263bb44f2a0a5bd4a192b0055","value":"README.md:"}},"21f9a82b630d4746a2dd5e1be8b0d48a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2531f8d1511d4c15a0c0e6412f08d480":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"257388c3bf1246f88fa57b947c5ba291":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"275a41b39b374d349a1dc7d90d41be51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0aa836e2827444bb8cb4929c045191a5","placeholder":"","style":"IPY_MODEL_8e0693e2a0734d6ca5f20da4be958474","value":"Generatingvalidationsplit:100%"}},"29aa0a8aeef64b85b99667715a8e6b26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a38717f8cc746b88b6fea1d9891fee7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c278e9e826ae43beb2d4ac81fafe956a","placeholder":"","style":"IPY_MODEL_f62aae1c59394eb58fb9df01a3628764","value":"merges.txt:100%"}},"2adcfdf8db024b66b5573499221f4a08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b2a4cc3bc31477b852a32cd8121c990":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11eac913eabc4694baf70f858e1d23ba","placeholder":"","style":"IPY_MODEL_5e13a0fe01314588a0e256e83e63eaba","value":"wikitext-2-raw-v1/validation-00000-of-00():100%"}},"2bfb60b0107c4f6ebfe69d45856e7cd4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_962e8c170def419cb205cc756ee10c56","placeholder":"","style":"IPY_MODEL_87636f0c72c246acb4722743ea70d315","value":"tokenizer_config.json:100%"}},"2c56ad7431e945dca7c8866c3243101d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eae068103346425c8be3518d7a55ccaa","placeholder":"","style":"IPY_MODEL_3f6635d2cd624c96aea8427644475183","value":"10.5k/?[00:00&lt;00:00,1.07MB/s]"}},"2d613ef8370d40949c8bd3e94af59ea5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2decf45365ca4e0c8779ec1d093a848d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e6f11c2950541b3bd03f556d7a3860e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f2574f5a565412aba5ffa859dc324da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c2bb819e460425ca6e43e259068e7c6","placeholder":"","style":"IPY_MODEL_0beffe9ebba64cad9f1bcca42a862e32","value":"4358/4358[00:00&lt;00:00,17247.69examples/s]"}},"2f73f92bd88b4e2484c96180b90df78c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b4dacaa78d84b5982d01ece05d45be3","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ff8fba4592d42f099dd1bbc67aec8e8","value":456318}},"2ff8fba4592d42f099dd1bbc67aec8e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3008197fae974e41ac0d4c70ab84f95f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3101b484a78c4b3d9d28788e96534ff5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_947d93a8a6ad46c89ab56d551da738c3","max":6357543,"min":0,"orientation":"horizontal","style":"IPY_MODEL_804d3e730988497f8c4e2165b2ca68da","value":6357543}},"351f4330e8624ee2b10d8755be06dbc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"377f69d9aa474004abf9d7337950cc4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37b87ed888604d219f85f76f18fef166":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3817cb1b27004650b331336897c98cdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d03959dde4a04ab788922ccbe7e76099","placeholder":"","style":"IPY_MODEL_0e682191fc0a4e0c9c3d3134c4115dcf","value":"36718/36718[00:00&lt;00:00,671640.32examples/s]"}},"391ff001bdad4bf7acb5ca25926f4277":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bb54182021e4eba9b309b87de58abcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5762dcb4ce64419a8744a69805d27dd","IPY_MODEL_3101b484a78c4b3d9d28788e96534ff5","IPY_MODEL_513c072c084a460e88824e6284dc7a3f"],"layout":"IPY_MODEL_ecaa7e71967e4616be09071c68bbdc02"}},"3d30b4c8d53b4f94aac194815e5b37f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3f6635d2cd624c96aea8427644475183":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40b9d0c6a39a4630bb59cac6e556c811":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f4a6c096b984feb876b10c44c0aa396","IPY_MODEL_517c5619c91047b99115ccfbc2bc084d","IPY_MODEL_e9f94e49e88c4b069f776138652a1f3b"],"layout":"IPY_MODEL_932bafc45b72459b9ab4173f1950e9b1"}},"440b77549572402284a31356ee717870":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46e9a26adade4a8986731f61274a54b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46fe76bd8d7040b5a25476843ef4de42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21471a7f56a247ab877262d81be19f52","IPY_MODEL_5bab41a75dd94a25acf9eb1f5fb37c19","IPY_MODEL_2c56ad7431e945dca7c8866c3243101d"],"layout":"IPY_MODEL_e7aefaf8127b438aa54671eed68a8ded"}},"4fd2e3ebc30b43d69fd05b167a0cee7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"513071b094ab4d19825029c3542ae61b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"513c072c084a460e88824e6284dc7a3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_440b77549572402284a31356ee717870","placeholder":"","style":"IPY_MODEL_8149d962342c46daa5e030151b902bbe","value":"6.36M/6.36M[00:00&lt;00:00,310kB/s]"}},"517c5619c91047b99115ccfbc2bc084d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29aa0a8aeef64b85b99667715a8e6b26","max":36718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c95bed5026242d588ed06f64af74689","value":36718}},"52fa7880598a4028a0b6cd80ef9adbb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b49ff3104fce40d99f5f0aeab5cd16f4","max":732610,"min":0,"orientation":"horizontal","style":"IPY_MODEL_918b00ebf25344e79e5a6e48a164a1aa","value":732610}},"55674e2fce3e47a08d51777749e51dd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58a5a5ef93254a66bcafb96852199069":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bab41a75dd94a25acf9eb1f5fb37c19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d30b4c8d53b4f94aac194815e5b37f1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c611d818f104db0bb59591ad93735e3","value":1}},"5e13a0fe01314588a0e256e83e63eaba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5eda3f3072ce4128910a6e18caa9db32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7090e887268843dcb2f36046b59cd5e8","IPY_MODEL_212d58f1ce5c49d5bfac0e5db83d6ea8","IPY_MODEL_6dd9c73dcbbf4c16a3003f79a0e5f68b"],"layout":"IPY_MODEL_e7c4e9421801424a8f1e2a31aa578f96"}},"605d7827e679422ab8feb0719e5a2d96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b31e6ae61254202b670c2d4bec50ee6","max":4358,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5c7b1ca05a74b6399be504d0f91820a","value":4358}},"60ef08481eeb4c6486cc8c35b90d77d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"639701726b664ccca0966cea2678ba51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6509aa8d44914af99d534f4ba5c8af56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"673892063e354f66945d1280ac178a9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ff0a7e275e84b84972aa9ad7e638e3d","IPY_MODEL_605d7827e679422ab8feb0719e5a2d96","IPY_MODEL_2f2574f5a565412aba5ffa859dc324da"],"layout":"IPY_MODEL_08420f74b6c344dca941855325e3e3b6"}},"6a9966fb9f0c461f9d9c00cadfa9a1d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc684a44bccb4da2bb2d7ab4c87594de","placeholder":"","style":"IPY_MODEL_58a5a5ef93254a66bcafb96852199069","value":"3760/3760[00:00&lt;00:00,240485.88examples/s]"}},"6b4e2e5b4b2e40188562e00fafe1d322":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c95bed5026242d588ed06f64af74689":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6dd9c73dcbbf4c16a3003f79a0e5f68b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c83d6b6a0152482ca604340bc5bdf499","placeholder":"","style":"IPY_MODEL_2d613ef8370d40949c8bd3e94af59ea5","value":"665/665[00:00&lt;00:00,93.7kB/s]"}},"6fb373c8a0cb49beade6d71dec0fdf98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ff10dc18f0948cc934fda373b307ca6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7090e887268843dcb2f36046b59cd5e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_391ff001bdad4bf7acb5ca25926f4277","placeholder":"","style":"IPY_MODEL_ce32b1a7d633474d941839704230ce69","value":"config.json:100%"}},"7429e6efd6c24c56bde773e90a9b4596":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e238ac5e2c5a4045a9bf9693e6bd3503","IPY_MODEL_52fa7880598a4028a0b6cd80ef9adbb3","IPY_MODEL_cdc385cb69f546ee9e00f0975169c261"],"layout":"IPY_MODEL_86665449e97747af95b25eb2a7449801"}},"77f95bb65efe4fef868b745e249f71c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78707284241a439a965417eadc21e4e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f4a6c096b984feb876b10c44c0aa396":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a014743e6d4b4c9a9bea7da1287c900c","placeholder":"","style":"IPY_MODEL_4fd2e3ebc30b43d69fd05b167a0cee7d","value":"Map:100%"}},"804d3e730988497f8c4e2165b2ca68da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8149d962342c46daa5e030151b902bbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83cb4f1edfa442acaeb54e92a00dc55f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8424915efc404a5893987b0da06a986a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_056709ca73eb44d990b9990d9fdbe206","placeholder":"","style":"IPY_MODEL_2e6f11c2950541b3bd03f556d7a3860e","value":"1.04M/1.04M[00:00&lt;00:00,1.65MB/s]"}},"84311cf3d05149129608f87b65e54368":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8529e2577f7c43aeb639378bbedc2b8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff21f42febc340589b0dc73fdda83b26","placeholder":"","style":"IPY_MODEL_1ba7974ddb3b4e4cbb54e1bc29b8edf4","value":"Map:100%"}},"866019f8091341d180d2d2551e0520a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_117aeb5d6841451394ca485f33ba2d9a","placeholder":"","style":"IPY_MODEL_d80a000ce7a0444fba9df88739bc7d1c","value":"Generatingtestsplit:100%"}},"86665449e97747af95b25eb2a7449801":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86de03adccdc481cb1ca578059e06702":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87636f0c72c246acb4722743ea70d315":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bb22c223e4049f381525d10c99b9dd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c2bb819e460425ca6e43e259068e7c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c611d818f104db0bb59591ad93735e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ddff6ac16f04e078f6534604325ac8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18d5473a4b6340dc97c0561739614229","IPY_MODEL_d56c1a0557d745908edf897af8de60a4","IPY_MODEL_8424915efc404a5893987b0da06a986a"],"layout":"IPY_MODEL_1087d1b2b0d74725b000bc9e07fba9c3"}},"8e0693e2a0734d6ca5f20da4be958474":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"914278c3cae54264acb653a33f11c81f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"918b00ebf25344e79e5a6e48a164a1aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93123f4763b948c2b42a5e2f8210bc35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"932bafc45b72459b9ab4173f1950e9b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9459fc8d95a54619871679b6c7dbe9db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8d037babeac4c8ba4fe577cc37a0d8d","placeholder":"","style":"IPY_MODEL_dc24f059fab94ff5a0a611b3b0559a0b","value":"657k/657k[00:00&lt;00:00,89.6kB/s]"}},"947d93a8a6ad46c89ab56d551da738c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"962e8c170def419cb205cc756ee10c56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96e6a57de1004d8388b053edf4e88e79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78707284241a439a965417eadc21e4e1","max":657209,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2adcfdf8db024b66b5573499221f4a08","value":657209}},"99c92cd4aa13485ebdd9858a8a89cb9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b31e6ae61254202b670c2d4bec50ee6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f33629411fc4e7aac4a70a7bf84d867":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a014743e6d4b4c9a9bea7da1287c900c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a086340ff7b343a0bba2eb5cc2d62c27":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4afd685b6b24871920d7b2ef1d0482f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a38717f8cc746b88b6fea1d9891fee7","IPY_MODEL_2f73f92bd88b4e2484c96180b90df78c","IPY_MODEL_b89c86e5863843b6be5d0896c82c00af"],"layout":"IPY_MODEL_9f33629411fc4e7aac4a70a7bf84d867"}},"a5762dcb4ce64419a8744a69805d27dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da72cbbc603044fdb6a28c42b6b449e9","placeholder":"","style":"IPY_MODEL_60ef08481eeb4c6486cc8c35b90d77d6","value":"wikitext-2-raw-v1/train-00000-of-00001.p():100%"}},"a5c7b1ca05a74b6399be504d0f91820a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab40cddd63c1433c954402a29292a9b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad952cc41b5f45858d0b211ab5055397":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af9ed07f41cd43e4b38af457dd634c00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b07550e4af784fab9aa5c5d404decf25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b49ff3104fce40d99f5f0aeab5cd16f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6172b3042bf42f4ab1aca94e78e00b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b89c86e5863843b6be5d0896c82c00af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad952cc41b5f45858d0b211ab5055397","placeholder":"","style":"IPY_MODEL_6509aa8d44914af99d534f4ba5c8af56","value":"456k/456k[00:00&lt;00:00,56.1MB/s]"}},"baed747e0a2a4e2092ed9dfdfbedd14a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b2a4cc3bc31477b852a32cd8121c990","IPY_MODEL_96e6a57de1004d8388b053edf4e88e79","IPY_MODEL_9459fc8d95a54619871679b6c7dbe9db"],"layout":"IPY_MODEL_86de03adccdc481cb1ca578059e06702"}},"bbdcb080e62e43d78d99fa2d6229386e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9934be8e092499c8b53abf47f461c25","max":3760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5bd003854c7448bb781475fbe708032","value":3760}},"bd1d5cda8c824c19be315594e92508aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf070d07f4e8491a9e2f92143b3e0667":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c269fa3e7e1b4d67bae323c672923baf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb9b188c958c4b74ab2de1777a3625b5","placeholder":"","style":"IPY_MODEL_99c92cd4aa13485ebdd9858a8a89cb9f","value":"4358/4358[00:00&lt;00:00,87000.78examples/s]"}},"c278e9e826ae43beb2d4ac81fafe956a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2aa85673942457c9263940b6456ada2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5884b09520840858c458500df3435a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c83d6b6a0152482ca604340bc5bdf499":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8c1fb2221694d8298d2994d5453dbc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00bea1d79b5a4b3e911070c9c03fccf1","placeholder":"","style":"IPY_MODEL_513071b094ab4d19825029c3542ae61b","value":"tokenizer.json:100%"}},"c8d037babeac4c8ba4fe577cc37a0d8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca37bad47f7f42be84dfd13f72a5a989":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee0c40dadd434180bdc248753cfb3136","IPY_MODEL_0165189d47894b23b07c64cfa824546d","IPY_MODEL_3817cb1b27004650b331336897c98cdd"],"layout":"IPY_MODEL_bd1d5cda8c824c19be315594e92508aa"}},"cb9b188c958c4b74ab2de1777a3625b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdb1ffc07da84dd68f697c1be60b7638":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdc385cb69f546ee9e00f0975169c261":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5884b09520840858c458500df3435a7","placeholder":"","style":"IPY_MODEL_f6220a02b3cd4a0a951b1507fd7670b2","value":"733k/733k[00:01&lt;00:00,23.1kB/s]"}},"ce32b1a7d633474d941839704230ce69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d03959dde4a04ab788922ccbe7e76099":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2ddd61263bb44f2a0a5bd4a192b0055":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d56c1a0557d745908edf897af8de60a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b07550e4af784fab9aa5c5d404decf25","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2dc3ff0a2cd40428306cbe6c70dcf37","value":1042301}},"d5bd003854c7448bb781475fbe708032":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d691981d65a0493eb9f194a91d200560":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6c8f2fd80b34b64ba6da8f285b8c795":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_866019f8091341d180d2d2551e0520a8","IPY_MODEL_fc2ffebc17c94e8daf87c0471d8ce117","IPY_MODEL_c269fa3e7e1b4d67bae323c672923baf"],"layout":"IPY_MODEL_2531f8d1511d4c15a0c0e6412f08d480"}},"d80a000ce7a0444fba9df88739bc7d1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da72cbbc603044fdb6a28c42b6b449e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dba0ba4f3d494d10aa1c8965f463af5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8c1fb2221694d8298d2994d5453dbc1","IPY_MODEL_f09cc00186214845afa3770b92269e89","IPY_MODEL_eabbf4ff588e4f9e891d6217c1303e9f"],"layout":"IPY_MODEL_93123f4763b948c2b42a5e2f8210bc35"}},"dc1201e0b1854142ba525fb3b79141da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2aa85673942457c9263940b6456ada2","placeholder":"","style":"IPY_MODEL_e42b97798dc9426a9c2e40f32caba75a","value":"26.0/26.0[00:00&lt;00:00,2.56kB/s]"}},"dc24f059fab94ff5a0a611b3b0559a0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc684a44bccb4da2bb2d7ab4c87594de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df59ed47ba9045af934227128095542d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e4d76c4ef234d1792839e692e1139ce","placeholder":"","style":"IPY_MODEL_37b87ed888604d219f85f76f18fef166","value":"3760/3760[00:00&lt;00:00,16055.75examples/s]"}},"e238ac5e2c5a4045a9bf9693e6bd3503":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21f9a82b630d4746a2dd5e1be8b0d48a","placeholder":"","style":"IPY_MODEL_3008197fae974e41ac0d4c70ab84f95f","value":"wikitext-2-raw-v1/test-00000-of-00001.pa():100%"}},"e42b97798dc9426a9c2e40f32caba75a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7aefaf8127b438aa54671eed68a8ded":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7c4e9421801424a8f1e2a31aa578f96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9f94e49e88c4b069f776138652a1f3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fb373c8a0cb49beade6d71dec0fdf98","placeholder":"","style":"IPY_MODEL_1b25b411f2424456950ca33b87b932dc","value":"36718/36718[00:02&lt;00:00,15309.38examples/s]"}},"eabbf4ff588e4f9e891d6217c1303e9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d691981d65a0493eb9f194a91d200560","placeholder":"","style":"IPY_MODEL_914278c3cae54264acb653a33f11c81f","value":"1.36M/1.36M[00:00&lt;00:00,1.61MB/s]"}},"eae068103346425c8be3518d7a55ccaa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecaa7e71967e4616be09071c68bbdc02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee0c40dadd434180bdc248753cfb3136":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a086340ff7b343a0bba2eb5cc2d62c27","placeholder":"","style":"IPY_MODEL_46e9a26adade4a8986731f61274a54b3","value":"Generatingtrainsplit:100%"}},"f09cc00186214845afa3770b92269e89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbf7161ef02a4c8db1bb73aab1fa03fc","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cdb1ffc07da84dd68f697c1be60b7638","value":1355256}},"f28532d8ab50429a98f9de52cf635633":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f2dc3ff0a2cd40428306cbe6c70dcf37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f37253c8d7c84e82b85c7ed98ba0a829":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_257388c3bf1246f88fa57b947c5ba291","max":3760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83cb4f1edfa442acaeb54e92a00dc55f","value":3760}},"f511eb5abe4e4d12811e67c91264642b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_275a41b39b374d349a1dc7d90d41be51","IPY_MODEL_bbdcb080e62e43d78d99fa2d6229386e","IPY_MODEL_6a9966fb9f0c461f9d9c00cadfa9a1d6"],"layout":"IPY_MODEL_77f95bb65efe4fef868b745e249f71c6"}},"f6220a02b3cd4a0a951b1507fd7670b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f62aae1c59394eb58fb9df01a3628764":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9934be8e092499c8b53abf47f461c25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbf7161ef02a4c8db1bb73aab1fa03fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc2ffebc17c94e8daf87c0471d8ce117":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af9ed07f41cd43e4b38af457dd634c00","max":4358,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf070d07f4e8491a9e2f92143b3e0667","value":4358}},"ff21f42febc340589b0dc73fdda83b26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff38a1a388784c90aadfd1b4e2e73da6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2bfb60b0107c4f6ebfe69d45856e7cd4","IPY_MODEL_0d0239e5c4244d70bd0bc30420acebe9","IPY_MODEL_dc1201e0b1854142ba525fb3b79141da"],"layout":"IPY_MODEL_b6172b3042bf42f4ab1aca94e78e00b4"}}}}},"nbformat":4,"nbformat_minor":0}