{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOSUyyn9Wz6BCh7vK6qR5cx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7vzVFb8WI45j","executionInfo":{"status":"ok","timestamp":1755217920867,"user_tz":420,"elapsed":3,"user":{"displayName":"doug chang","userId":"06495228775351504429"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"WKi27FT1OSRf","executionInfo":{"status":"ok","timestamp":1755218027770,"user_tz":420,"elapsed":14858,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"3309cf1d-c417-45ff-acb4-5916241fe60f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/cuda\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ri_aNA3FJBb6","executionInfo":{"status":"ok","timestamp":1755218039064,"user_tz":420,"elapsed":5,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"b7b420e8-159f-4e84-f2a6-af70722f535d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/cuda\n"]}]},{"cell_type":"code","source":["%%writefile cuda_events.cu\n","\n","\n","/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.\n"," *\n"," * Redistribution and use in source and binary forms, with or without\n"," * modification, are permitted provided that the following conditions\n"," * are met:\n"," *  * Redistributions of source code must retain the above copyright\n"," *    notice, this list of conditions and the following disclaimer.\n"," *  * Redistributions in binary form must reproduce the above copyright\n"," *    notice, this list of conditions and the following disclaimer in the\n"," *    documentation and/or other materials provided with the distribution.\n"," *  * Neither the name of NVIDIA CORPORATION nor the names of its\n"," *    contributors may be used to endorse or promote products derived\n"," *    from this software without specific prior written permission.\n"," *\n"," * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY\n"," * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n"," * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n"," * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n"," * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n"," * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n"," * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n"," * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n"," * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n"," * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n"," * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"," */\n","\n","/*\n"," * This sample illustrates the usage of CUDA events for both GPU timing and\n"," * overlapping CPU and GPU execution.  Events are inserted into a stream\n"," * of CUDA calls.  Since CUDA stream calls are asynchronous, the CPU can\n"," * perform computations while GPU is executing (including DMA memcopies\n"," * between the host and device).  CPU can query CUDA events to determine\n"," * whether GPU has completed tasks.\n"," */\n","\n","// includes, system\n","#include <stdio.h>\n","\n","// includes CUDA Runtime\n","#include <cuda_profiler_api.h>\n","#include <cuda_runtime.h>\n","\n","// includes, project\n","#include <helper_cuda.h>\n","#include <helper_functions.h> // helper utility functions\n","\n","__global__ void increment_kernel(int *g_data, int inc_value)\n","{\n","    int idx     = blockIdx.x * blockDim.x + threadIdx.x;\n","    g_data[idx] = g_data[idx] + inc_value;\n","}\n","\n","bool correct_output(int *data, const int n, const int x)\n","{\n","    for (int i = 0; i < n; i++)\n","        if (data[i] != x) {\n","            printf(\"Error! data[%d] = %d, ref = %d\\n\", i, data[i], x);\n","            return false;\n","        }\n","\n","    return true;\n","}\n","\n","int main(int argc, char *argv[])\n","{\n","    int            devID;\n","    cudaDeviceProp deviceProps;\n","\n","    printf(\"[%s] - Starting...\\n\", argv[0]);\n","\n","    // This will pick the best possible CUDA capable device\n","    devID = findCudaDevice(argc, (const char **)argv);\n","\n","    // get device name\n","    checkCudaErrors(cudaGetDeviceProperties(&deviceProps, devID));\n","    printf(\"CUDA device [%s]\\n\", deviceProps.name);\n","\n","    int n      = 16 * 1024 * 1024;\n","    int nbytes = n * sizeof(int);\n","    int value  = 26;\n","\n","    // allocate host memory\n","    int *a = 0;\n","    checkCudaErrors(cudaMallocHost((void **)&a, nbytes));\n","    memset(a, 0, nbytes);\n","\n","    // allocate device memory\n","    int *d_a = 0;\n","    checkCudaErrors(cudaMalloc((void **)&d_a, nbytes));\n","    checkCudaErrors(cudaMemset(d_a, 255, nbytes));\n","\n","    // set kernel launch configuration\n","    dim3 threads = dim3(512, 1);\n","    dim3 blocks  = dim3(n / threads.x, 1);\n","\n","    // create cuda event handles\n","    cudaEvent_t start, stop;\n","    checkCudaErrors(cudaEventCreate(&start));\n","    checkCudaErrors(cudaEventCreate(&stop));\n","\n","    StopWatchInterface *timer = NULL;\n","    sdkCreateTimer(&timer);\n","    sdkResetTimer(&timer);\n","\n","    checkCudaErrors(cudaDeviceSynchronize());\n","    float gpu_time = 0.0f;\n","\n","    // asynchronously issue work to the GPU (all to stream 0)\n","    checkCudaErrors(cudaProfilerStart());\n","    sdkStartTimer(&timer);\n","    cudaEventRecord(start, 0);\n","    cudaMemcpyAsync(d_a, a, nbytes, cudaMemcpyHostToDevice, 0);\n","    increment_kernel<<<blocks, threads, 0, 0>>>(d_a, value);\n","    cudaMemcpyAsync(a, d_a, nbytes, cudaMemcpyDeviceToHost, 0);\n","    cudaEventRecord(stop, 0);\n","    sdkStopTimer(&timer);\n","    checkCudaErrors(cudaProfilerStop());\n","\n","    // have CPU do some work while waiting for stage 1 to finish\n","    unsigned long int counter = 0;\n","\n","    while (cudaEventQuery(stop) == cudaErrorNotReady) {\n","        counter++;\n","    }\n","\n","    checkCudaErrors(cudaEventElapsedTime(&gpu_time, start, stop));\n","\n","    // print the cpu and gpu times\n","    printf(\"time spent executing by the GPU: %.2f\\n\", gpu_time);\n","    printf(\"time spent by CPU in CUDA calls: %.2f\\n\", sdkGetTimerValue(&timer));\n","    printf(\"CPU executed %lu iterations while waiting for GPU to finish\\n\", counter);\n","\n","    // check the output for correctness\n","    bool bFinalResults = correct_output(a, n, value);\n","\n","    // release resources\n","    checkCudaErrors(cudaEventDestroy(start));\n","    checkCudaErrors(cudaEventDestroy(stop));\n","    checkCudaErrors(cudaFreeHost(a));\n","    checkCudaErrors(cudaFree(d_a));\n","\n","    exit(bFinalResults ? EXIT_SUCCESS : EXIT_FAILURE);\n","}\n","\n"],"metadata":{"id":"c9IZ9-DlJBeb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oD4d4_lqJBgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4Nax4udvJBjW"},"execution_count":null,"outputs":[]}]}