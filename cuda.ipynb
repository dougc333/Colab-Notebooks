{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1toSx57xVu685HIRWWtnKBiurYsHOOiQC","timestamp":1754587395414}],"gpuType":"T4","authorship_tag":"ABX9TyP/0sex63oneJVfkqhd+FoN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**CUDA**"],"metadata":{"id":"RvuSPzlGjeYs"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9opQobyeJ34","executionInfo":{"status":"ok","timestamp":1754587433248,"user_tz":420,"elapsed":16539,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"59c9c238-d52d-49d9-d1c9-ca9a5289fb45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/colab_notebooks/"],"metadata":{"id":"jCRZMuTUeONq","executionInfo":{"status":"ok","timestamp":1754587436618,"user_tz":420,"elapsed":359,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd630714-8009-49be-9f14-a9c1b76319d8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/colab_notebooks\n"]}]},{"cell_type":"code","source":["!pip install colab_dc333\n","import colab_dc333\n","colab_dc333.nvidia.update_12_4()"],"metadata":{"id":"VNWhPcVUMBIl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["cuda kernels\n","CUDA C++ extends C++ by allowing the programmer to define C++ functions,\n","called kernels, that, when called, are executed N times in parallel\n","by N different CUDA threads, as opposed to only once like regular C++ functions.\n","\n","A kernel is defined using the __global__ declaration specifier  \n","number threads =  <<<num threads/block, num blocks/grid>>>.\n","\n","there are no for loops in cuda code. each iteration i in a for loop is\n","assigned to a cuda thread. The code inside a for loop is moved to a cuda fn\n","and this fn is the cuda kernel. Debug printing requires data be moved to the cpu\n","\n","The jupyter nvcc addons dont work\n","<h4>%%writefile filename</h4>\n","<h4>nvcc filename.cu -o execname</h4>\n","<h4>./execname</h4>"],"metadata":{"id":"VsU5TR7w--ja"}},{"cell_type":"code","source":["#include <stdio.h>\n","#include <cuda_runtime.h>\n","\n","// CUDA kernel to add two integers\n","__global__ void add_kernel(int a, int b, int *result) {\n","    *result = a + b;\n","}\n","\n","int main() {\n","    int a = 3, b = 5;\n","    int result = 0;\n","\n","    // Allocate memory on the device (GPU)\n","    int *d_result;\n","    cudaMalloc((void**)&d_result, sizeof(int));\n","\n","    // Launch kernel with 1 block and 1 thread\n","    add_kernel<<<1, 1>>>(a, b, d_result);\n","\n","    // Wait for kernel to finish\n","    cudaDeviceSynchronize();\n","\n","    // Copy result back to host\n","    cudaMemcpy(&result, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n","\n","    // Print result on host\n","    printf(\"Result of %d + %d = %d\\n\", a, b, result);\n","\n","    // Free device memory\n","    cudaFree(d_result);\n","\n","    return 0;\n","}"],"metadata":{"id":"JvKFq5j_yN4s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile thread_one.cu\n","#include \"stdio.h\"\n","#include <cuda_runtime.h>\n","\n","\n","__global__ void k1(int *bid, int *bdim, int* bidx){\n","  //what does if stmt look like in gpu?\n","  if (blockIdx.x == 2 && threadIdx.x == 2) {\n","        *bid = blockIdx.x;\n","        *bdim = blockDim.x;\n","        *bidx = threadIdx.x;\n","    }\n","}\n","\n","\n","int main(int argc, char** argv){\n","  // the 2 args in <<>> determine the itertation in k1 blockIdx.x,\n","  // blockDim.x, threadIdx.x\n","  const int numBlocks = 3;\n","  const int threadsPerBlock = 3;\n","\n","  int cpuBlockId = 10;\n","  int cpuBlockDim = 10;\n","  int cpuThreadIdx = 10;\n","\n","\n","  int *bid, *bdim, *bidx;\n","  cudaMalloc((void**)&bid , sizeof(int));\n","  cudaMalloc((void**)&bdim , sizeof(int));\n","  cudaMalloc((void**)&bidx , sizeof(int ));\n","\n","\n","\n","  k1<<<numBlocks,threadsPerBlock>>>(bid, bdim, bidx);\n","  cudaDeviceSynchronize();\n","  cudaMemcpy(&cpuBlockId, bid, sizeof(int), cudaMemcpyDeviceToHost);\n","  cudaMemcpy(&cpuBlockDim, bdim, sizeof(int), cudaMemcpyDeviceToHost);\n","  cudaMemcpy(&cpuThreadIdx, bidx, sizeof(int),  cudaMemcpyDeviceToHost);\n","\n","  printf(\"cpuBlockId:%d \\n\",cpuBlockId);\n","  printf(\"cpuBlockDim:%d \\n\",cpuBlockDim);\n","  printf(\"cpuThreadIdx:%d \\n\",cpuThreadIdx);\n","\n","  cudaFree(bid);\n","  cudaFree(bdim);\n","  cudaFree(bidx);\n","}\n","\n","\n","\n","\n"],"metadata":{"id":"jpyqjyfzeOP-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile threads_array.cu\n","#include <stdio.h>\n","#include <cuda_runtime.h>\n","\n","__global__ void capture_info(int* block_ids, int* thread_ids, int* global_ids) {\n","    int globalThreadId = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    block_ids[globalThreadId] = blockIdx.x;\n","    thread_ids[globalThreadId] = threadIdx.x;\n","    global_ids[globalThreadId] = globalThreadId;\n","}\n","\n","int main() {\n","    const int numBlocks = 3;\n","    const int threadsPerBlock = 4;\n","    const int totalThreads = numBlocks * threadsPerBlock;\n","\n","    // Allocate host arrays\n","    int h_block_ids[totalThreads];\n","    int h_thread_ids[totalThreads];\n","    int h_global_ids[totalThreads];\n","\n","    // Allocate device arrays\n","    int *d_block_ids, *d_thread_ids, *d_global_ids;\n","\n","    cudaMalloc((void**)&d_block_ids,  sizeof(int) * totalThreads);\n","    cudaMalloc((void**)&d_thread_ids, sizeof(int) * totalThreads);\n","    cudaMalloc((void**)&d_global_ids, sizeof(int) * totalThreads);\n","\n","    // Launch kernel\n","    capture_info<<<numBlocks, threadsPerBlock>>>(d_block_ids, d_thread_ids, d_global_ids);\n","    cudaDeviceSynchronize();\n","\n","    // Copy back to host\n","    cudaMemcpy(h_block_ids,  d_block_ids,  sizeof(int) * totalThreads, cudaMemcpyDeviceToHost);\n","    cudaMemcpy(h_thread_ids, d_thread_ids, sizeof(int) * totalThreads, cudaMemcpyDeviceToHost);\n","    cudaMemcpy(h_global_ids, d_global_ids, sizeof(int) * totalThreads, cudaMemcpyDeviceToHost);\n","\n","    // Print info\n","    for (int i = 0; i < totalThreads; ++i) {\n","        printf(\"GlobalThreadID: %2d | BlockID: %d | ThreadID: %d\\n\",\n","               h_global_ids[i], h_block_ids[i], h_thread_ids[i]);\n","    }\n","\n","    // Cleanup\n","    cudaFree(d_block_ids);\n","    cudaFree(d_thread_ids);\n","    cudaFree(d_global_ids);\n","\n","    return 0;\n","}"],"metadata":{"id":"fG-nSUTMeOU6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile allv2.cu\n","#include <stdio.h>\n","#include <cuda_runtime.h>\n","\n","__global__ void capture_info(int* block_ids, int* thread_ids, int* global_ids) {\n","    int globalThreadId = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    block_ids[globalThreadId]  = blockIdx.x;\n","    thread_ids[globalThreadId] = threadIdx.x;\n","    global_ids[globalThreadId] = globalThreadId;\n","}\n","\n","int main() {\n","    const int numBlocks = 3;\n","    const int threadsPerBlock = 4;\n","    const int totalThreads = numBlocks * threadsPerBlock;\n","\n","    // Allocate host arrays\n","    int* h_block_ids  = (int*)malloc(sizeof(int) * totalThreads);\n","    int* h_thread_ids = (int*)malloc(sizeof(int) * totalThreads);\n","    int* h_global_ids = (int*)malloc(sizeof(int) * totalThreads);\n","\n","    // Allocate device arrays\n","    int *d_block_ids, *d_thread_ids, *d_global_ids;\n","    cudaMalloc((void**)&d_block_ids,  sizeof(int) * totalThreads);\n","    cudaMalloc((void**)&d_thread_ids, sizeof(int) * totalThreads);\n","    cudaMalloc((void**)&d_global_ids, sizeof(int) * totalThreads);\n","\n","    // Launch kernel\n","    capture_info<<<numBlocks, threadsPerBlock>>>(d_block_ids, d_thread_ids, d_global_ids);\n","\n","    // Wait for the kernel to finish\n","    cudaDeviceSynchronize();\n","\n","    // Copy back to host\n","    cudaMemcpy(h_block_ids,  d_block_ids,  sizeof(int) * totalThreads, cudaMemcpyDeviceToHost);\n","    cudaMemcpy(h_thread_ids, d_thread_ids, sizeof(int) * totalThreads, cudaMemcpyDeviceToHost);\n","    cudaMemcpy(h_global_ids, d_global_ids, sizeof(int) * totalThreads, cudaMemcpyDeviceToHost);\n","\n","    // Print results\n","    FILE* f = fopen(\"output.txt\", \"w\");\n","    for (int i = 0; i < totalThreads; ++i) {\n","        fprintf(f, \"GlobalThreadID: %2d | BlockID: %d | ThreadID: %d\\n\",\n","               h_global_ids[i], h_block_ids[i], h_thread_ids[i]);\n","    }\n","    fclose(f);\n","    // Cleanup\n","    free(h_block_ids);\n","    free(h_thread_ids);\n","    free(h_global_ids);\n","    cudaFree(d_block_ids);\n","    cudaFree(d_thread_ids);\n","    cudaFree(d_global_ids);\n","\n","    return 0;\n","}"],"metadata":{"id":"SNdhekSjeOXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","print(torch.backends.cudnn.version())\n","print(torch.backends.cudnn.is_available())"],"metadata":{"id":"UbH1ASkJK687"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile vector_add_1.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","\n","// Define a helper macro for checking CUDA errors\n","#define CUDA_CHECK(err) { \\\n","    if (err != cudaSuccess) { \\\n","        fprintf(stderr, \"Fatal CUDA Error at %s:%d: %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); \\\n","        exit(EXIT_FAILURE); \\\n","    } \\\n","}\n","\n","// CUDA Kernel to perform vector addition\n","__global__ void vectorAdd(const float *a, const float *b, float *c, int n) {\n","    int i = blockIdx.x * blockDim.x + threadIdx.x;\n","    if (i < n) {\n","        c[i] = a[i] + b[i];\n","    }\n","}\n","\n","int main() {\n","    const int N = 1024; // Number of elements in the vector\n","    const size_t size = N * sizeof(float);\n","\n","    // 1. Allocate host memory\n","    float *h_a = (float *)malloc(size);\n","    float *h_b = (float *)malloc(size);\n","    float *h_c = (float *)malloc(size);\n","\n","    if (h_a == NULL || h_b == NULL || h_c == NULL) {\n","        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n","        return 1;\n","    }\n","\n","    // 2. Initialize host vectors\n","    for (int i = 0; i < N; ++i) {\n","        h_a[i] = i * 1.0f;\n","        h_b[i] = i * 2.0f;\n","    }\n","\n","    // 3. Allocate device memory\n","    float *d_a, *d_b, *d_c;\n","    CUDA_CHECK(cudaMalloc(&d_a, size));\n","    CUDA_CHECK(cudaMalloc(&d_b, size));\n","    CUDA_CHECK(cudaMalloc(&d_c, size));\n","\n","    // 4. Copy data from host to device\n","    printf(\"Copying data from host to device...\\n\");\n","    CUDA_CHECK(cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice));\n","    CUDA_CHECK(cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice));\n","\n","    // 5. Define grid and block dimensions and launch the kernel\n","    int threadsPerBlock = 256;\n","    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n","    printf(\"Launching kernel with %d blocks and %d threads...\\n\", blocksPerGrid, threadsPerBlock);\n","\n","    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, N);\n","\n","    // Check for any errors during kernel launch\n","    CUDA_CHECK(cudaGetLastError());\n","\n","    // 6. Copy result back from device to host\n","    printf(\"Copying result from device to host...\\n\");\n","    CUDA_CHECK(cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost));\n","\n","    // Synchronize to make sure the copy is complete before we access h_c\n","    CUDA_CHECK(cudaDeviceSynchronize());\n","\n","    // 7. Verification\n","    printf(\"Verification:\\n\");\n","    printf(\"First element: %f (Expected: 0.0 + 0.0 = 0.0)\\n\", h_c[0]);\n","    printf(\"Second element: %f (Expected: 1.0 + 2.0 = 3.0)\\n\", h_c[1]);\n","    printf(\"Last element: %f (Expected: 1023.0 + 2046.0 = 3069.0)\\n\", h_c[N-1]);\n","\n","    // 8. Cleanup\n","    free(h_a);\n","    free(h_b);\n","    free(h_c);\n","    CUDA_CHECK(cudaFree(d_a));\n","    CUDA_CHECK(cudaFree(d_b));\n","    CUDA_CHECK(cudaFree(d_c));\n","\n","    printf(\"Done.\\n\");\n","    return 0;\n","}"],"metadata":{"id":"lKnieEDreOgY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile add_cg.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cooperative_groups.h>\n","#include <cooperative_groups/reduce.h>\n","namespace cg = cooperative_groups;\n","\n","__global__ void modern_sum_reduction_kernel(const float* input, float* output, int n) {\n","\n","    cg::thread_block block = cg::this_thread_block();\n","    float sum = 0.0f;\n","\n","    int i = blockIdx.x * blockDim.x + threadIdx.x;\n","    for (; i < n; i += gridDim.x * blockDim.x) {\n","        sum += input[i];\n","    }\n","\n","    // cg reduce the values from all threads in the block to sum\n","    float block_sum = cg::reduce(block, sum, cg::plus<float>());\n","\n","    // The first thread writes the block's total sum to the output\n","    if (block.thread_rank() == 0) {\n","        output[blockIdx.x] = block_sum;\n","    }\n","}\n","\n","\n","int main(){\n","  const int blocksPerGrid = 3;\n","  const int threadsPerBlock = 2;\n","  const int n = 100\n","\n","  //allocate host memory\n","  float *input = (float *)malloc(sizeof(float) * n);\n","\n","  //initialize host memory\n","  for (int i;0;i<n; i++){\n","    input[i] = 10.0 + i;\n","  }\n","  //allocate gpu\n","  float *output;\n","  cudaMalloc(&output, sizeof(float))\n","\n","  vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(&finput, &output, n);\n","  cudaDeviceSynchronize();\n","\n","  return 0\n","}"],"metadata":{"id":"leVPIMttS29h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["reduction.cu error:\n","\n","run compute-sanitizer --tool memcheck ./r\n","\n","=========\n","========= Program hit cudaErrorUnsupportedPtxVersion (error 222) due to \"the provided PTX was compiled with an unsupported toolchain.\" on CUDA API call to cudaGetLastError.\n","\n","FIXED after updating cuda to 12.4. nvcc --version and nvidia-smi have to match versions\n","\n","/content# ./r\n","Problem Size: 4194304 elements.\n","Block Size: 256 threads.\n","Stage 1 Grid Size: 16384 blocks.\n","Launching Stage 1 reduction...\n","Launching Stage 2 reduction...\n","\n","--- Results ---\n","GPU Sum:              131072.00\n","Expected Sum:         8388608.00\n","GPU Average:          0.0312\n","Expected Average:     2.0000"],"metadata":{"id":"oeyhsLUZDSbA"}},{"cell_type":"code","source":["%%writefile reduction.cu\n","\n","#include <iostream>\n","#include <vector>\n","#include <numeric>\n","\n","// --- Helper for checking CUDA errors ---\n","#define CUDA_CHECK(err) { \\\n","    if (err != cudaSuccess) { \\\n","        fprintf(stderr, \"Fatal CUDA Error at %s:%d: %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); \\\n","        exit(EXIT_FAILURE); \\\n","    } \\\n","}\n","\n","// --- The Reduction Kernel ---\n","// This kernel can be used for both Stage 1 and Stage 2.\n","// It uses shared memory for an efficient, intra-block reduction.\n","__global__ void sum_reduction_kernel(const float* input, float* output, int n) {\n","    // Statically allocate shared memory. Size is known at compile time.\n","    extern __shared__ float sdata[];\n","\n","    // Each thread loads an element from global memory to shared memory\n","    unsigned int tid = threadIdx.x;\n","    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    // Load data into shared memory. Boundary check for safety.\n","    if (i < n) {\n","        sdata[tid] = input[i];\n","    } else {\n","        sdata[tid] = 0.0f; // Neutral element for addition\n","    }\n","\n","    // Synchronize to make sure all data is loaded before starting the reduction\n","    __syncthreads();\n","\n","    // Perform the reduction in shared memory\n","    // The loop reduces the active number of threads by half in each iteration\n","    for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n","        // Only the first 's' threads are active and add values\n","        if (tid < s) {\n","            sdata[tid] += sdata[tid + s];\n","        }\n","        // Synchronize to make sure all additions in this step are complete\n","        __syncthreads();\n","    }\n","\n","    // The first thread in the block writes the final result (the block's partial sum)\n","    // to the output array in global memory.\n","    if (tid == 0) {\n","        output[blockIdx.x] = sdata[0];\n","    }\n","}\n","\n","\n","int main() {\n","    // 1. --- Host Setup ---\n","    const int N = 1 << 22; // ~4 million elements\n","    const int BLOCK_SIZE = 256; // Threads per block\n","    const size_t data_size = N * sizeof(float);\n","\n","    std::cout << \"Problem Size: \" << N << \" elements.\" << std::endl;\n","    std::cout << \"Block Size: \" << BLOCK_SIZE << \" threads.\" << std::endl;\n","\n","    // Allocate host memory and initialize data\n","    std::vector<float> h_input(N);\n","    for (int i = 0; i < N; ++i) {\n","        h_input[i] = 2.0f; // Use a simple value for easy verification\n","    }\n","\n","    // 2. --- Device Memory Allocation ---\n","    float *d_input, *d_intermediate, *d_output;\n","    CUDA_CHECK(cudaMalloc(&d_input, data_size));\n","\n","    // Calculate grid size for the first stage\n","    int num_blocks = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n","    std::cout << \"Stage 1 Grid Size: \" << num_blocks << \" blocks.\" << std::endl;\n","\n","    // Allocate memory for intermediate (partial) sums and the final result\n","    CUDA_CHECK(cudaMalloc(&d_intermediate, num_blocks * sizeof(float)));\n","    CUDA_CHECK(cudaMalloc(&d_output, sizeof(float)));\n","\n","    // 3. --- Copy Data to Device ---\n","    CUDA_CHECK(cudaMemcpy(d_input, h_input.data(), data_size, cudaMemcpyHostToDevice));\n","\n","    // 4. --- Kernel Launches ---\n","    // The size of shared memory is passed as the third kernel launch parameter.\n","    size_t shared_mem_size = BLOCK_SIZE * sizeof(float);\n","\n","    // >> STAGE 1: Reduce the large input array to an intermediate array of partial sums\n","    std::cout << \"Launching Stage 1 reduction...\" << std::endl;\n","    sum_reduction_kernel<<<num_blocks, BLOCK_SIZE, shared_mem_size>>>(d_input, d_intermediate, N);\n","    //CUDA_CHECK(cudaGetLastError());\n","\n","    // >> STAGE 2: Reduce the intermediate array of partial sums to a single final value\n","    std::cout << \"Launching Stage 2 reduction...\" << std::endl;\n","    sum_reduction_kernel<<<1, BLOCK_SIZE, shared_mem_size>>>(d_intermediate, d_output, num_blocks);\n","    CUDA_CHECK(cudaGetLastError());\n","\n","    // 5. --- Copy Final Result Back to Host ---\n","    float final_sum = 0.0f;\n","    CUDA_CHECK(cudaMemcpy(&final_sum, d_output, sizeof(float), cudaMemcpyDeviceToHost));\n","\n","    // 6. --- Calculate Average and Verify ---\n","    float average = final_sum / N;\n","    float expected_sum = N * 2.0f;\n","    float expected_average = 2.0f;\n","\n","    std::cout << \"\\n--- Results ---\" << std::endl;\n","    printf(\"GPU Sum:              %.2f\\n\", final_sum);\n","    printf(\"Expected Sum:         %.2f\\n\", expected_sum);\n","    printf(\"GPU Average:          %.4f\\n\", average);\n","    printf(\"Expected Average:     %.4f\\n\", expected_average);\n","\n","    // 7. --- Cleanup ---\n","    cudaFree(d_input);\n","    cudaFree(d_intermediate);\n","    cudaFree(d_output);\n","\n","    return 0;\n","}"],"metadata":{"id":"eu91vqxuFKCo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# recompile profile_gpt2cu for colab gpu\n","!make profile_gpt2cu NO_MULTI_GPU=1\n","# run profile\n","!ncu --set full --import-source yes -o profile -f ./profile_gpt2cu\n","\n"],"metadata":{"id":"inEDbF2riVwE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ncu --set full --import-source yes -o profile -f ./profile_gpt2cu\n","\n","Multi-GPU support is disabled. Using a single GPU.\n","\n","==PROF== Connected to process 52856 (/content/drive/MyDrive/colab_notebooks/llm.c/profile_gpt2cu)\n","\n","[System]\n","Device 0: Tesla T4\n","batch size: 24\n","sequence length: 1024\n","| Zero Optimization is disabled                                              |\n","allocating 237 MiB for parameter gradients\n","\n","allocating 3762 MiB for activations\n","\n","allocating 474 MiB for AdamW optimizer state m\n","\n","allocating 474 MiB for AdamW optimizer state v\n","\n","allocating 474 MiB for master copy of params\n","\n","device memory usage: 5828 MiB / 15095 MiB\n","\n","memory per sequence: 156 MiB\n"," -> estimated maximum batch size: 83\n","\n","==PROF== Profiling \"encoder_forward_kernel3\" - 0: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"layernorm_forward_kernel6\" - 1: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"magma_sgemmEx_kernel\" - 2: 0%.\n","\n","==WARNING== Launching the workload is taking more time than expected. If thisnallocating 474 MiB for AdamW optimizer state v\n","\n","allocating 474 MiB for master copy of params\n","\n","device memory usage: 5828 MiB / 15095 MiB\n","\n","memory per sequence: 156 MiB\n"," -> estimated maximum batch size: 83\n","\n","==PROF== Profiling \"encoder_forward_kernel3\" - 0: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"layernorm_forward_kernel6\" - 1: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"magma_sgemmEx_kernel\" - 2: 0%.\n","\n","==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.\n","...50%....100% - 30 passes\n","\n","==PROF== Profiling \"permute_kernel\" - 3: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"magma_sgemmEx_kernel\" - 4: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"softmax_forward_kernel5\" - 5: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"magma_sgemmEx_kernel\" - 6: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"unpermute_kernel\" - 7: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"magma_sgemmEx_kernel\" - 8: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"fused_residual_forward_kernel5\" - 9: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"magma_sgemmEx_kernel\" - 10: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"gelu_forward_kernel2\" - 11: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"magma_sgemmEx_kernel\" - 12: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"fused_residual_forward_kernel5\" - 13: 0%....50%....100% - 30 passes\n","\n","==PROF== Profiling \"magma_sgemmEx_kernel\" - 14: 0%.\n","\n","==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.\n"],"metadata":{"id":"AUVSQLtlu6LV"}},{"cell_type":"code","source":["# --- 1. SETUP THE PROJECT ---\n","# Clone the repository and move into the directory\n","!git clone https://github.com/karpathy/llm.c.git\n","%cd llm.c\n","\n","# --- 2. DOWNLOAD MODEL WEIGHTS ---\n","# The C code needs this file to run\n","!wget https://huggingface.co/karpathy/gpt2/resolve/main/gpt2_124M_bf16.bin\n","\n","# --- 3. PATCH THE MAKEFILE FOR COLAB ---\n","# Fixes the \"cuDNN not found\" error by pointing to correct system paths\n","!sed -i 's|/usr/local/cuda/lib64|/usr/lib/x86_64-linux-gnu|g' Makefile\n","!sed -i 's|/usr/local/cuda/include|/usr/include|g' Makefile\n","\n","# --- 4. COMPILE THE PROFILER ---\n","# This creates the './profile_gpt2cu' executable\n","!make profile_gpt2cu NO_MULTI_GPU=1\n","\n","# --- 5. RUN THE PROFILER ---\n","# This runs the executable under ncu and creates 'profile.ncu-rep'\n","# This step will take a few minutes.\n","print(\"Starting profiling with ncu. This will take a moment...\")\n","!sudo ncu --set full --import-source yes -o profile -f ./profile_gpt2cu\n","print(\"Profiling complete. Download 'profile.ncu-rep' from the file browser to view the results.\")"],"metadata":{"id":"Er7r_TgIv3ii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#https://www.youtube.com/watch?v=IDOB9lQrcyw\n","# process blocks instead of complete rows and columns. BxB submatrix should\n","# fit in cache"],"metadata":{"id":"OU7dJ-ULY_np"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["// 1. Allocate host memory\n","// 2. --- Device Memory Allocation ---\n","// 3. --- Copy Data to Device ---\n","// 4. --- Kernel Launches ---\n","// 5. --- Copy Final Result Back to Host ---\n","// 6. --- Calculate Average and Verify ---\n","// 7. --- Cleanup ---\n"],"metadata":{"id":"gIi6BcbPqFPR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["cuda has __constant__ symbol which is a read-only array stored in device memory."],"metadata":{"id":"c1c6tREwWCo6"}},{"cell_type":"code","source":["%%writefile const.cu\n","\n","#include <stdio.h>\n","\n","#define N 8\n","\n","// GPU constant memory symbol (read-only from device, set from host)\n","__constant__ int const_data[N];\n","\n","// Kernel reads from constant memory\n","__global__ void useConstantMemory(int* output) {\n","    int tid = threadIdx.x;\n","    if (tid < N) {\n","        output[tid] = const_data[tid] * 2;  // Read from constant symbol\n","    }\n","}\n","\n","int main() {\n","    int h_const_data[N] = {1, 2, 3, 4, 5, 6, 7, 8};\n","    int h_output[N];\n","\n","    int* d_output;\n","\n","    // Allocate output buffer on device\n","    cudaMalloc((void**)&d_output, sizeof(int) * N);\n","\n","    // Copy host data to __constant__ memory on device\n","    cudaMemcpyToSymbol(const_data, h_const_data, sizeof(int) * N);\n","\n","    // Launch kernel\n","    useConstantMemory<<<1, N>>>(d_output);\n","    cudaDeviceSynchronize();\n","\n","    // Copy result back\n","    cudaMemcpy(h_output, d_output, sizeof(int) * N, cudaMemcpyDeviceToHost);\n","\n","    // Print result\n","    printf(\"Output from kernel:\\n\");\n","    for (int i = 0; i < N; ++i) {\n","        printf(\"%d \", h_output[i]);  // Expect 2Ã— input\n","    }\n","    printf(\"\\n\");\n","\n","    // Clean up\n","    cudaFree(d_output);\n","    return 0;\n","}"],"metadata":{"id":"iO-HuD5AsBpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F6uGda4psBr3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DKgIOQSIsBuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WrFpcZpysBwz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JCLsse9AsBy4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["https://fengyao.notion.site/moe-posttraining\n","https://fengyao.notion.site/off-policy-rl"],"metadata":{"id":"QUhuo6u5sB1P"},"execution_count":null,"outputs":[]}]}