{"cells":[{"cell_type":"markdown","source":["<h1>There are 2 conventions for tensor vs array elements</h1>\n","\n","\n","We write [1,2,3] with each element in an array or list separated by an comma.\n","<br/>\n","When writing a matrix we use commas to separate rows like this:\n","\n","[[1 2 3],[4 5 6]].\n","\n","The problem is the commas. Sometimes they separate elements in a list sometimes they separate rows in a matrix.  "],"metadata":{"id":"3B3NB25LIEUB"},"id":"3B3NB25LIEUB"},{"cell_type":"raw","id":"7e07fdc0-23b3-4d1a-9103-2a4718a1a689","metadata":{"id":"7e07fdc0-23b3-4d1a-9103-2a4718a1a689"},"source":["<h1> Derive the column and row average</h1>\n","\n","\n","<ul>\n","<li>The simplest step is to assume a matrix operation between an $I$ matrix and vector of data, $X$</li>\n","<li>A dot product or a matrix multiply is a multiply and addition between elements in both args, $I@X$ or $X@I$</li>\n","<li>Under an interview situation we want to derive each one before proceeding to the various forms of attention. First compute the average. Then\n","progress to weighted sum and finally the full causal attention block</li>\n","<li>Start with test data for $X$. Do not use a symmetric matrix to reduce confusion $[[1 2 3],[4 5 6]]$</li>\n","<li>Match the shapes and work the examples. $X$ is $(2,3)$. An identity matrix $I@X$ has $I=(?,2)$ or $I=(3,?)$ if $X@I$</li>\n","<li>Fill in the question marks, how many ones are there? Even before doing any matching, we know I@X will have 3 elements left and X@I will have 2 elements left. We can guess the 3 elements mean column sum and 2 elements mean row sum. </li>\n","<li>Write out the elements and verify our above guess was correct. </li>\n","</ul>\n","\n","<ul>\n","<li>$I@X$ has $I=(?,2)$, what is the question mark? The (?,2) means 2 columns to match the matrix multiply rules. Write out the matrix with 2 cols to make sure we arent confusing rows vs cols.  [[col1, col2],...]*[[1 2 3],[4 5 6]]. The question becomes how many rows are there. Draw picture, can see 1 row is needed, [1+4=5,2+5=7,3+6=9 ], this is a column sum.   </li>\n","<li>$X@I$ has $I=(3,?)$ how many cols are there?  Write out the form of I with 3 rows to verify we aren't confusing rows vs. cols. The minimum is 1 col. Write out and see what happens. [[1 2 3],[4 5 6]]@[[1],[1],[1]] = [[1+2+3=7],[4+5+6=15]]. This is row sum</li>\n","</ul>\n","\n","<ul>\n","To modify to average, divide by num elements of X rows or cols.\n","</ul>\n","\n","<ul>\n","Important: practice on the matching numpy notation where [[1],[1],[1]] means 3 rows with shape(3,1) and [[1 1 1]] is 1 col of 3 ones, shape(1,3).\n","</ul>"]},{"cell_type":"code","source":["import torch\n","test = [[1,2,3 ],[4,5,6]]\n","\n","x = torch.tensor(test)\n","m = torch.mean(x.float())\n","print('mean:',m.shape)\n","m = m.unsqueeze(0)\n","m = m.squeeze(1)\n","print(\"m squeeze\", m.shape)\n","\n","#print(m.shape)\n","#[3]\n","#[1,3]\n","#[3,1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239},"id":"EP09hRlDOX2P","executionInfo":{"status":"error","timestamp":1764816573463,"user_tz":480,"elapsed":14,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"edc4ab89-af67-40ce-d964-6a93fd5d160a"},"id":"EP09hRlDOX2P","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mean: torch.Size([])\n"]},{"output_type":"error","ename":"IndexError","evalue":"Dimension out of range (expected to be in range of [-1, 0], but got 1)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1903732477.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"m squeeze\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"]}]},{"cell_type":"code","execution_count":null,"id":"d324cfba-a3d2-478a-9c8b-3953e83a38fa","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"id":"d324cfba-a3d2-478a-9c8b-3953e83a38fa","executionInfo":{"status":"error","timestamp":1764809097798,"user_tz":480,"elapsed":6473,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"3fc188cd-4d57-4c6a-d9ab-8cddc4ee62b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 1])\n","torch.Size([1, 1])\n","torch.Size([3, 1])\n"]},{"output_type":"error","ename":"TypeError","evalue":"mean() received an invalid combination of arguments - got (Tensor, keepdims=bool), but expected one of:\n * (Tensor input, *, torch.dtype dtype = None, Tensor out = None)\n * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)\n * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3611346253.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# do not fix. for demo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# if you use keepdims you need dim. dim=0 rows, dim=1 cols.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (Tensor, keepdims=bool), but expected one of:\n * (Tensor input, *, torch.dtype dtype = None, Tensor out = None)\n * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)\n * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)\n"]}],"source":["import torch\n","# error cell, leave error\n","a=torch.tensor([[1],[1],[1]]).float()\n","print(a.shape)\n","\n","\n","res = torch.mean(a, dim=0, keepdims=True) # if you use keepdims you need dim. dim=0 rows, dim=1 cols.\n","print(res.shape)\n","\n","res = torch.mean(a, dim=1, keepdims=True) # if you use keepdims you need dim. dim=0 rows, dim=1 cols.\n","print(res.shape)\n","\n","# do not fix. for demo\n","res = torch.mean(a, keepdims=True) # if you use keepdims you need dim. dim=0 rows, dim=1 cols.\n","print(res.shape)\n","\n"]},{"cell_type":"raw","id":"746ce7f8-5240-4b31-8adb-3a60723f2994","metadata":{"id":"746ce7f8-5240-4b31-8adb-3a60723f2994"},"source":["<h6>torch Size[3] and numpy (3,) means no rows or cols. Sometimes these are used interchangably. Always reshape these</h6>\n","<h6>How to use unsqueeze to produce (3,1) vs (3,) </h6>\n","<h6>Avoid slient dimensions, Size[3] has to be converted to (1,3) or (3,1)</h6>\n","\n","<ul>\n","<li>A shape =(3,) means there is no shape. torch.tensor([1, 2, 3,]) has shape (3,)</li>\n","<li>Sometimes numpy (3,) is used interchangbly with torch.Size([3]). Size[3] means there are no rows or cols.  </li>\n","<li>You have to test to verify depending on numpy and torch versions</li>\n","</ul>"]},{"cell_type":"code","execution_count":null,"id":"baf3f8dc-c86d-4852-8754-f70bf8563086","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"baf3f8dc-c86d-4852-8754-f70bf8563086","executionInfo":{"status":"ok","timestamp":1764809104803,"user_tz":480,"elapsed":48,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"bea35b95-93a5-4945-c5e7-aee8c06bdf7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","(3,)\n","(3,)\n","(3,)\n","(3,)\n"]}],"source":["print(torch.tensor([1,2,3]).shape)\n","print(torch.arange(3).shape)\n","print(torch.ones(3).shape)\n","print(torch.zeros(3).shape)\n","print(torch.randn(3).shape)\n","import numpy\n","print(numpy.ones(3).shape)\n","print(numpy.zeros(3).shape)\n","print(numpy.random.rand(3).shape)\n","print(numpy.arange(3).shape)\n"]},{"cell_type":"code","execution_count":null,"id":"63cace57-6060-47f2-afb7-db9b8b1ca71c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63cace57-6060-47f2-afb7-db9b8b1ca71c","executionInfo":{"status":"ok","timestamp":1764809130835,"user_tz":480,"elapsed":33,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"32ebddb6-104c-422a-bcc8-9a2419fd00f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["x:tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","torch.Size([3])\n","torch.Size([3, 1])\n","tensor([[1],\n","        [1],\n","        [1]])\n","tensor([[ 6],\n","        [15]])\n","I_b:tensor([1, 1])\n","I_b shape:torch.Size([2])\n","I_b shape:torch.Size([1, 2])\n","I_b*x:tensor([[5, 7, 9]])\n"]}],"source":["# derive the col and row sums.\n","\n","import torch\n","x = torch.tensor([[1,2,3], [4,5,6]])\n","print(f'x:{x}')\n","\n","\n","# x = (2x3)\n","# I=([1,1,1]x2) I@x or I=(3,[1,1]) for x@I\n","#\n","I_a = torch.tensor([1,1,1]) #\n","print(I_a.shape)\n","I_a = I_a.unsqueeze(1)\n","print(I_a.shape)\n","print(I_a)\n","print(x@I_a) # row or column sum?\n","I_b = torch.tensor([1,1])\n","print(f'I_b:{I_b}')\n","print(f'I_b shape:{I_b.shape}')\n","I_b = I_b.unsqueeze(0)\n","print(f'I_b shape:{I_b.shape}')\n","print(f'I_b*x:{I_b@x}')\n","\n","# do matrix multiply have keepdims? No. Why? Mean have keepdims because all the elements reduce to 1 number.\n","#"]},{"cell_type":"code","execution_count":null,"id":"6f71632d-40d6-42c9-ad8a-beab8bf5b480","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6f71632d-40d6-42c9-ad8a-beab8bf5b480","executionInfo":{"status":"ok","timestamp":1764809262519,"user_tz":480,"elapsed":52,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"9423c260-2934-41db-fa0f-ecf670dfbddc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.1808, -0.0700],\n","        [-0.3596, -0.9152],\n","        [ 0.6258,  0.0255],\n","        [ 0.9545,  0.0643],\n","        [ 0.3612,  1.1679],\n","        [-1.3499, -0.5102],\n","        [ 0.2360, -0.2398],\n","        [-0.9211,  1.5433]])"]},"metadata":{},"execution_count":5}],"source":["#lkarpathy lets build gpt from scratch 45:00\n","\n","torch.manual_seed(1337)\n","B,T,C = 4,8,2\n","\n","x = torch.randn(B,T,C)\n","x.shape\n","\n","#note randn creates float so we dont need conversion to float for torch.mean\n","x[0]"]},{"cell_type":"markdown","source":["<h1>Karpathy Prefix Average</h1>\n","\n","\n","\n","\n","<ul>\n","<li>X [1,2,3,4,5,6]</li>\n","<li>$\\frac{1}{t+1}\\sum_{t=0} x_t$</li>\n","<li>t=0 1/1(1)=1</li>\n","<li>t=1 1/2(1+2)=1.5</li>\n","<li>t=2 1/3(1+2+3)=2</li>\n","<li>t=3 1/4(1+2+3+4)=2.5</li>\n","</ul>"],"metadata":{"id":"sqOw8rKq1I9b"},"id":"sqOw8rKq1I9b"},{"cell_type":"code","execution_count":null,"id":"0a7473de-8b0a-4a9d-81a4-65f08efb1a43","metadata":{"id":"0a7473de-8b0a-4a9d-81a4-65f08efb1a43","outputId":"f30df7d8-6955-4223-87f0-f885bd5d38ce"},"outputs":[{"data":{"text/plain":["tensor([[[ 0.1808, -0.0700],\n","         [-0.0894, -0.4926],\n","         [ 0.1490, -0.3199],\n","         [ 0.3504, -0.2238],\n","         [ 0.3525,  0.0545],\n","         [ 0.0688, -0.0396],\n","         [ 0.0927, -0.0682],\n","         [-0.0341,  0.1332]],\n","\n","        [[ 1.3488, -0.1396],\n","         [ 0.8173,  0.4127],\n","         [-0.1342,  0.4395],\n","         [ 0.2711,  0.4774],\n","         [ 0.2421,  0.0694],\n","         [ 0.0084,  0.0020],\n","         [ 0.0712, -0.1128],\n","         [ 0.2527,  0.2149]],\n","\n","        [[-0.6631, -0.2513],\n","         [ 0.1735, -0.0649],\n","         [ 0.1685,  0.3348],\n","         [-0.1621,  0.1765],\n","         [-0.2312, -0.0436],\n","         [-0.1015, -0.2855],\n","         [-0.2593, -0.1630],\n","         [-0.3015, -0.2293]],\n","\n","        [[ 1.6455, -0.8030],\n","         [ 1.4985, -0.5395],\n","         [ 0.4954,  0.3420],\n","         [ 1.0623, -0.1802],\n","         [ 1.1401, -0.4462],\n","         [ 1.0870, -0.4071],\n","         [ 1.0430, -0.1299],\n","         [ 1.1138, -0.1641]]])"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["# we want x[b,t] = mean_{i<t} x[b,i]\n","# calculate sequence average, time t=1, avg=x[1]; t=2 avg=(x[1]+x[2])/2; t=3 avg=(x[1]+x[2]+x[3])/3\n","xbow = torch.zeros((B,T,C))\n","\n","for b in range(B):\n","    for t in range(T):\n","        xprev = x[b,:t+1] #(t,C)\n","        xbow[b,t] = torch.mean(xprev, 0) #calc mean on 0th dimension which is the firrst, t from (t,C) shold have keepdims=True\n","xbow"]},{"cell_type":"markdown","id":"916bec0f-80dd-416a-bcc7-d7da7132aed5","metadata":{"id":"916bec0f-80dd-416a-bcc7-d7da7132aed5"},"source":["<h1>Prefix average</h1>\n","\n","\n","Prefix average where all the positions in T have the same weight. $prefixavg = \\frac{1}{t+1}\\sum_0^t{x_s}$\n","\n","We are going to later modify the weights for each position to indicate the relative importance each position term contributes to current token."]},{"cell_type":"code","execution_count":null,"id":"404f8357-aa55-41b8-ae66-8fb1569126ce","metadata":{"id":"404f8357-aa55-41b8-ae66-8fb1569126ce","outputId":"3786da7c-6810-49d3-8ae6-9d97a75642d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 tensor([1])\n","1 tensor([1, 2])\n","2 tensor([1, 2, 3])\n","3 tensor([1, 2, 3, 4])\n","4 tensor([1, 2, 3, 4, 5])\n","5 tensor([1, 2, 3, 4, 5, 6])\n"]}],"source":["seq = torch.tensor([1,2,3,4,5,6])\n","for t in range(len(seq)):\n","    print(t,seq[:t+1])\n","\n","# 0 tensor([1])                1/(0+1) sum(1)\n","# 1 tensor([1, 2])             1/(1+1) sum(1+2)\n","# 2 tensor([1, 2, 3])          1/(1+1+1) sum(1+2+3)\n","# 3 tensor([1, 2, 3, 4])       1/(1+1+1+1) sum(1+2+3+4)\n","# 4 tensor([1, 2, 3, 4, 5])    ...\n","# 5 tensor([1, 2, 3, 4, 5, 6])  ..."]},{"cell_type":"markdown","source":["<h1>Mathematical trick using Matrix Multiply and lower triangular matrix to compute prefix average</h1>\n","\n","There are no weights here. Add them in next step."],"metadata":{"id":"ZroYU7zspX9o"},"id":"ZroYU7zspX9o"},{"cell_type":"code","execution_count":null,"id":"535e3406-60a6-4d46-b525-7b85796ee766","metadata":{"id":"535e3406-60a6-4d46-b525-7b85796ee766","outputId":"e685eafb-1b09-4831-8df2-d00e307906fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["a=\n","tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]])\n","-----\n","b=\n","tensor([[2., 7.],\n","        [6., 4.],\n","        [6., 5.]])\n","c=\n","tensor([[14., 16.],\n","        [14., 16.],\n","        [14., 16.]])\n","-----\n"]}],"source":["# karpathy mathematical trick w matric mul\n","# first part compute sum of rows and or columns with matrix multiply\n","# second part is using pytorch.tril a upper triagular matrix to act as a mask to compute prefix average\n","import torch\n","\n","torch.manual_seed(42)\n","a = torch.ones(3,3)\n","b = torch.randint(0,10,(3,2)).float()\n","c = a@b\n","print('a=')\n","print(a)\n","print('-----')\n","print('b=')\n","print(b)\n","print('c=')\n","print(c) # see the column sums replicated in all rows\n","print('-----')\n","\n"]},{"cell_type":"code","execution_count":null,"id":"1f97b671-2d25-4dcf-8ca9-765f4732a7e2","metadata":{"id":"1f97b671-2d25-4dcf-8ca9-765f4732a7e2","outputId":"02ff8106-da50-4b92-8ba6-7023d7f04205"},"outputs":[{"name":"stdout","output_type":"stream","text":["a=\n","tensor([[1., 0., 0.],\n","        [1., 1., 0.],\n","        [1., 1., 1.]])\n","-----\n","b=\n","tensor([[2., 7.],\n","        [6., 4.],\n","        [6., 5.]])\n","c=\n","tensor([[ 2.,  7.],\n","        [ 8., 11.],\n","        [14., 16.]])\n","-----\n"]}],"source":[" # to turn this into a progressive sum use triangular to mask out the future tokens\n","\n","torch.manual_seed(42)\n","a = torch.tril(torch.ones(3,3))\n","b = torch.randint(0,10,(3,2)).float()\n","c = a@b\n","print('a=')\n","print(a)\n","print('-----')\n","print('b=')\n","print(b)\n","print('c=')\n","print(c) # see the column sums replicated in all rows\n","print('-----')"]},{"cell_type":"code","execution_count":null,"id":"beef798f-c9d2-4b8b-8d36-5e87c7900a0c","metadata":{"id":"beef798f-c9d2-4b8b-8d36-5e87c7900a0c","outputId":"b38c61aa-586e-4326-ecbb-e39147547856"},"outputs":[{"name":"stdout","output_type":"stream","text":["s:tensor([[1.],\n","        [2.],\n","        [3.]])\n","torch.Size([3, 1])\n","y: tensor([[1.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000],\n","        [0.3333, 0.3333, 0.3333]])\n","tensor([[2.0000, 7.0000],\n","        [4.0000, 5.5000],\n","        [4.6667, 5.3333]])\n"]}],"source":["\n","import torch.nn.functional as F\n","\n","#x = torch.tensor([[1,2,3],[4,5,6],[7,8,9]]).float()\n","x = torch.tril(torch.ones(3,3)).float()\n","#print(f'x:{x}')\n","s = torch.sum(x, 1, keepdim=True)\n","print(f's:{s}')\n","print(s.shape)\n","y = x/s\n","print(\"y:\",y)\n","c=y@b\n","print(c) #match karpathy 51:20\n","#print(F.softmax(x, dim=0)) # with ones it doesnt matter which dims\n"]},{"cell_type":"code","execution_count":null,"id":"8f442e28-5427-41a9-9b98-db2e3cc9feee","metadata":{"id":"8f442e28-5427-41a9-9b98-db2e3cc9feee","outputId":"f0a9fb74-d3cb-4f00-dcd9-0a70a25eeaea"},"outputs":[{"name":"stdout","output_type":"stream","text":["x1:tensor([[[1., 2., 3.],\n","         [4., 5., 6.],\n","         [7., 8., 9.]]]),x1.shape:torch.Size([1, 3, 3])\n","cum_sum:{cum_sum}\n","counts:tensor([[[1.],\n","         [2.],\n","         [3.]]])\n","tensor([[[1.0000, 2.0000, 3.0000],\n","         [2.5000, 3.5000, 4.5000],\n","         [4.0000, 5.0000, 6.0000]]])\n"]}],"source":["# dont need tril do cumulative_sum\n","B,T,C = 1,3,3\n","#**tricky make sure the brackets are correct for B,T,C\n","x1 = torch.tensor([[\n","    [1,2,3],\n","    [4,5,6],\n","    [7,8,9]\n","]]).float()\n","print(f'x1:{x1},x1.shape:{x.shape}') #3,3 T,C dim_t=1, dim_c=2 we want dim=1\n","cum_sum = torch.cumsum(x1, dim=1)\n","print('cum_sum:{cum_sum}')\n","counts = torch.arange(1,T+1).view(1,T,1).float()\n","print(f'counts:{counts}')\n","\n","prefix_avg = cum_sum/counts\n","print(prefix_avg)\n","\n","\n","# 2.5 is avg of 1+4, 4.0 is avg of 1+4+7\n","\n","#tensor([[[1.0000, 2.0000, 3.0000],\n","#         [2.5000, 3.5000, 4.5000],\n","#         [4.0000, 5.0000, 6.0000]]])"]},{"cell_type":"code","execution_count":null,"id":"3450d220-ad0a-4cd6-823d-03f7ec7e58cc","metadata":{"id":"3450d220-ad0a-4cd6-823d-03f7ec7e58cc","outputId":"6ba641ba-7c5c-421a-a974-1c1baf7f00a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n","        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n","        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n","        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"]}],"source":["# a vectorized  weighted average\n","B,T,C = 4,8,2\n","wei = torch.tril(torch.ones(T,T))\n","wei = wei/wei.sum(1, keepdim=True)\n","print(wei)"]},{"cell_type":"code","execution_count":null,"id":"ca31ab73-94d8-435f-b945-93e326a4dd3b","metadata":{"id":"ca31ab73-94d8-435f-b945-93e326a4dd3b","outputId":"840b8d6a-e54a-4d66-8204-aa08eb054a0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.1808, -0.0700],\n","        [-0.0894, -0.4926],\n","        [ 0.1490, -0.3199],\n","        [ 0.3504, -0.2238],\n","        [ 0.3525,  0.0545],\n","        [ 0.0688, -0.0396],\n","        [ 0.0927, -0.0682],\n","        [-0.0341,  0.1332]])\n","tensor([[ 0.1808, -0.0700],\n","        [-0.0894, -0.4926],\n","        [ 0.1490, -0.3199],\n","        [ 0.3504, -0.2238],\n","        [ 0.3525,  0.0545],\n","        [ 0.0688, -0.0396],\n","        [ 0.0927, -0.0682],\n","        [-0.0341,  0.1332]])\n"]}],"source":["xbow2 = wei @ x #(T,T) @ (B,T,C) pytorch will create batched mm by 1) adding B to dim (T,T) to (B,T,T)\n","# (B,T,T) @ (B,T,C) becomes (B,T,C)\n","# xbow2 identical to xbow\n","\n","print(xbow2[0])\n","print(xbow[0])# verify same who proves teh vectorized version using batched matrix multiply is same as loop\n","# rthe prefix average uses 1s which is in tril."]},{"cell_type":"markdown","source":["<h6>Add weights for affinities between tokens</h6>"],"metadata":{"id":"OiRRCWeJpNmE"},"id":"OiRRCWeJpNmE"},{"cell_type":"code","execution_count":null,"id":"26c54d60-ba5d-4cef-baab-519d0fa9288c","metadata":{"id":"26c54d60-ba5d-4cef-baab-519d0fa9288c","outputId":"1564190a-05d2-41f8-eef9-dd3d469c5b85"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0.]])\n","tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n","        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n","        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n","        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"]},{"data":{"text/plain":["True"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["# third version uses softmax\n","# karpathy the wei starts at 0\n","tril = torch.tril(torch.ones(T,T))\n","wei = torch.zeros(T,T) #interaction between elements these are trained for now they are 0.\n","wei = wei.masked_fill(tril==0, float('-inf')) #tril is the mask to ignore future tokens\n","print(wei)\n","wei = F.softmax(wei, dim=1)\n","print(wei)\n","xbow3 = wei @ x\n","torch.allclose(xbow,xbow3)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"N87SKP5JlV46"},"id":"N87SKP5JlV46","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install triton"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eainuU4JM4E7","executionInfo":{"status":"ok","timestamp":1764815522682,"user_tz":480,"elapsed":4101,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"3ae547ce-9178-46f8-8187-582164020000"},"id":"eainuU4JM4E7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (3.5.0)\n"]}]},{"cell_type":"code","execution_count":null,"id":"c622bcd3-4439-4903-8bd4-f74e61f8fe6e","metadata":{"id":"c622bcd3-4439-4903-8bd4-f74e61f8fe6e"},"outputs":[],"source":["import triton\n","import triton.language as tl\n","\n","@triton.jit\n","def prefix_avg_kernel(\n","    x_ptr,        # *const float\n","    y_ptr,        # *float\n","    B, T, C,      # int32\n","    stride_b,     # int32 (distance in elements between consecutive batches)\n","    stride_t,     # int32 (distance in elements between consecutive time steps)\n","    stride_c,     # int32 (distance in elements between consecutive channels)\n","):\n","    # program ids: one program per (b, c)\n","    pid_b = tl.program_id(0)    # 0 .. B-1\n","    pid_c = tl.program_id(1)    # 0 .. C-1\n","\n","    # guard: in case grid is bigger than B or C\n","    if pid_b >= B or pid_c >= C:\n","        return\n","\n","    running_sum = tl.zeros((), dtype=tl.float32)\n","\n","    # IMPORTANT:\n","    # Triton wants static ranges; if T is small/fixed you can make it constexpr.\n","    # For many practical uses you specialize the kernel on T.\n","    #\n","    # For clarity we assume T is marked constexpr in the launcher;\n","    # if not, you can use tl.static_range with a compile-time upper bound.\n","    for t in tl.static_range(0, tl.constexpr(lambda: 1024)):  # 1024 = max_T you care about\n","        # break if weâ€™ve passed the real T\n","        if t >= T:\n","            break\n","\n","        # Compute index into flat memory:\n","        # idx = pid_b * stride_b + t * stride_t + pid_c * stride_c\n","        idx = pid_b * stride_b + t * stride_t + pid_c * stride_c\n","\n","        x_val = tl.load(x_ptr + idx)\n","        running_sum += x_val\n","\n","        count = t + 1\n","        avg = running_sum / count\n","\n","        tl.store(y_ptr + idx, avg)"]},{"cell_type":"code","execution_count":null,"id":"7657b937-630f-4ae3-9291-a1f31943e2ac","metadata":{"id":"7657b937-630f-4ae3-9291-a1f31943e2ac","outputId":"d2549a6d-4298-405a-f1dc-a4b6ba86ac92"},"outputs":[{"name":"stdout","output_type":"stream","text":["B:4 T:8 C:2\n","out:tensor([[[ 0.1808, -0.0700],\n","         [-0.0894, -0.4926],\n","         [ 0.1490, -0.3199],\n","         [ 0.3504, -0.2238],\n","         [ 0.3525,  0.0545],\n","         [ 0.0688, -0.0396],\n","         [ 0.0927, -0.0682],\n","         [-0.0341,  0.1332]],\n","\n","        [[ 1.3488, -0.1396],\n","         [ 0.8173,  0.4127],\n","         [-0.1342,  0.4395],\n","         [ 0.2711,  0.4774],\n","         [ 0.2421,  0.0694],\n","         [ 0.0084,  0.0020],\n","         [ 0.0712, -0.1128],\n","         [ 0.2527,  0.2149]],\n","\n","        [[-0.6631, -0.2513],\n","         [ 0.1735, -0.0649],\n","         [ 0.1685,  0.3348],\n","         [-0.1621,  0.1765],\n","         [-0.2312, -0.0436],\n","         [-0.1015, -0.2855],\n","         [-0.2593, -0.1630],\n","         [-0.3015, -0.2293]],\n","\n","        [[ 1.6455, -0.8030],\n","         [ 1.4985, -0.5395],\n","         [ 0.4954,  0.3420],\n","         [ 1.0623, -0.1802],\n","         [ 1.1401, -0.4462],\n","         [ 1.0870, -0.4071],\n","         [ 1.0430, -0.1299],\n","         [ 1.1138, -0.1641]]])\n"]}],"source":["# fourth version not in karpathy\n","\n","# x: (B,T,C)\n","B, T, C = x.shape\n","print(f'B:{B} T:{T} C:{C}')\n","out = torch.empty_like(x)\n","\n","for b in range(B):\n","    running_sum = torch.zeros(C)\n","    running_count = 0\n","    for t in range(T):\n","        running_sum += x[b, t]\n","        running_count += 1\n","        out[b, t] = running_sum / running_count  # prefix average\n","print(f'out:{out}')"]},{"cell_type":"code","source":["import triton\n","import triton.language as tl\n","import torch\n","\n","@triton.jit\n","def prefix_avg_kernel(\n","    x_ptr, out_ptr,\n","    B, C,\n","    stride_b, stride_t, stride_c,\n","    T: tl.constexpr,   # T is compile-time constant for this kernel specialization\n","):\n","    pid = tl.program_id(0)  # 0 .. B*C-1\n","    b = pid // C\n","    c = pid % C\n","\n","    if b >= B:\n","        return\n","\n","    # base offset for this (b,c) line through time\n","    base_offset = b * stride_b + c * stride_c\n","\n","    running_sum = tl.zeros((), dtype=tl.float32)\n","\n","    # loop over time dimension, 0..T-1\n","    for t in tl.static_range(0, T):\n","        idx = base_offset + t * stride_t\n","        x_val = tl.load(x_ptr + idx)\n","        running_sum += x_val\n","\n","        count = t + 1  # 1..T\n","        avg = running_sum / count\n","        tl.store(out_ptr + idx, avg)\n","\n","\n","def prefix_avg_triton(x: torch.Tensor) -> torch.Tensor:\n","    assert x.ndim == 3\n","    B, T, C = x.shape\n","    x = x.contiguous()\n","    out = torch.empty_like(x)\n","\n","    stride_b, stride_t, stride_c = x.stride()\n","\n","    grid = (B * C,)\n","\n","    prefix_avg_kernel[grid](\n","        x, out,\n","        B, C,\n","        stride_b, stride_t, stride_c,\n","        T=T,   # passed as meta argument (constexpr)\n","    )\n","    return out\n","\n","B, T, C = 1, 3, 3\n","x = torch.tensor([[[1., 2., 3.],\n","                   [4., 5., 6.],\n","                   [7., 8., 9.]]], device='cuda')\n","\n","y = prefix_avg_triton(x)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6obCQTRRNOom","executionInfo":{"status":"ok","timestamp":1764819055887,"user_tz":480,"elapsed":8,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"633eee4d-7e62-4bd0-e8c6-060e01318aed"},"id":"6obCQTRRNOom","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[1.0000, 2.0000, 3.0000],\n","         [2.5000, 3.5000, 4.5000],\n","         [4.0000, 5.0000, 6.0000]]], device='cuda:0')\n"]}]},{"cell_type":"code","execution_count":null,"id":"4b2e34b3-c496-4dbd-a70a-3c9eb11c734d","metadata":{"id":"4b2e34b3-c496-4dbd-a70a-3c9eb11c734d","outputId":"a0cc7aaf-5fb6-4a00-9f03-b41eb1ac270d"},"outputs":[{"name":"stdout","output_type":"stream","text":["funning_sum:tensor([[ 8.9105, -1.3124]])\n","running_count:8\n"]}],"source":["# break into blocks\n","\n","BLOCK_T = 128\n","for b in range(B):\n","    running_sum = torch.zeros(1, C, device=x.device)  # (1,C)\n","    running_count = 0\n","\n","    for start in range(0, T, BLOCK_T):\n","        end = min(start + BLOCK_T, T)\n","        x_blk = x[b, start:end]                      # (Tb, C)\n","        # cumulative sum within block\n","        blk_cumsum = torch.cumsum(x_blk, dim=0)      # (Tb, C)\n","\n","        # add previous running_sum\n","        blk_sum = blk_cumsum + running_sum           # (Tb, C)\n","\n","        # counts for each position in this block\n","        Tb = end - start\n","        counts = torch.arange(\n","            running_count + 1,\n","            running_count + Tb + 1,\n","            device=x.device\n","        ).view(Tb, 1)                                # (Tb,1)\n","\n","        out[b, start:end] = blk_sum / counts         # (Tb,C)\n","\n","        running_sum = blk_sum[-1:]                   # final prefix sum of block\n","        running_count += Tb\n","print(f'funning_sum:{running_sum}')\n","print(f'running_count:{running_count}')"]},{"cell_type":"code","execution_count":null,"id":"b885353d-a438-4ab8-85e2-899bb8741558","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b885353d-a438-4ab8-85e2-899bb8741558","executionInfo":{"status":"ok","timestamp":1764888641883,"user_tz":480,"elapsed":17531,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"f99527e6-e02c-4ed4-fb7f-b575c42548f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"d62f3239-1a2e-41c0-98b4-33eb187e83c6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d62f3239-1a2e-41c0-98b4-33eb187e83c6","executionInfo":{"status":"ok","timestamp":1764888641893,"user_tz":480,"elapsed":5,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"337b3a21-b7c2-4e26-97a5-4f267b0dd270"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}],"source":["cd /content/drive/MyDrive"]},{"cell_type":"code","execution_count":7,"id":"8fe6ad8a-f643-43ae-857f-5498ca9173f3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fe6ad8a-f643-43ae-857f-5498ca9173f3","executionInfo":{"status":"ok","timestamp":1764898835032,"user_tz":480,"elapsed":14156,"user":{"displayName":"doug chang","userId":"06495228775351504429"}},"outputId":"3946be5d-aa73-48dc-ed3a-e50cafc01e23"},"outputs":[{"output_type":"stream","name":"stdout","text":["step:0 train loss:4.3893, val loss:4.3725\n","step:300 train loss:2.5177, val loss:2.5493\n","step:600 train loss:2.4979, val loss:2.5241\n","step:900 train loss:2.5053, val loss:2.5147\n","step:1200 train loss:2.5039, val loss:2.5251\n","step:1500 train loss:2.4890, val loss:2.5107\n","step:1800 train loss:2.4895, val loss:2.5164\n","step:2100 train loss:2.4902, val loss:2.5157\n","step:2400 train loss:2.4787, val loss:2.5095\n","step:2700 train loss:2.4854, val loss:2.5160\n","\n","A:\n","Wit minirush IUnonthefove thacke nd thassepe unco my wat Isavouean ye.\n","\n","Cis vesis to ctha dry chi\n"]}],"source":["# karpathy bigram language model\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","batch_size = 32\n","block_size = 8\n","max_iters = 3000\n","eval_interval = 300\n","learning_rate = 1e-2\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 200\n","n_embd = 32\n","\n","\n","torch.manual_seed(1337)\n","with open('/content/drive/MyDrive/gpt/input.txt', 'r', encoding='utf-8') as f:\n","  text = f.read()\n","\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","stoi = {ch:i for i, ch in enumerate(chars)}\n","itos = {i:ch for i, ch in enumerate(chars)}\n","encode = lambda s:[stoi[c] for c in s]\n","decode = lambda l:\"\".join([itos[i] for i in l])\n","\n","data = torch.tensor(encode(text), dtype=torch.long)\n","n = int(0.9 * len(data) )\n","train_data=data[:n]\n","val_data = data[n:]\n","\n","\n","def get_batch(split):\n","  data = train_data if split == 'train' else val_data\n","  ix = torch.randint(len(data)-block_size,(batch_size,))\n","  x = torch.stack([data[i:i+block_size] for i in ix])\n","  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","  x, y = x.to(device), y.to(device)\n","  return x,y\n","\n","# for b in range(batch_size):\n","#   for t in range(block_size):\n","#     context = xb[b, :t+1]\n","#     target = yb[b,t]\n","#     #print(f'when input is {context.tolist()} target:{target}')\n","\n","@torch.no_grad()\n","def estimate_loss():\n","  out = {}\n","  model.eval()\n","  for split in ['train', 'val']:\n","    losses = torch.zeros(eval_iters)\n","    for k in range(eval_iters):\n","      X, Y = get_batch(split)\n","      logits, loss = model(X,Y)\n","      losses[k] = loss.item()\n","    out[split] = losses.mean()\n","  model.train()\n","  return out\n","\n","class BigramLanguageModel(nn.Module):\n","  def __init__(self,vocab_size):\n","    super().__init__()\n","\n","    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n","    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n","\n","    self.lm_head = nn.Linear(n_embd, vocab_size)\n","\n","  # one issue is CE wants B,C,T vs B T C\n","  def forward(self, idx, targets=None):\n","    B, T ,C = idx.shape\n","\n","    tok_emb = self.token_embedding_table(idx) #B T C\n","    logits = self.lm_head(tok_emb) # B T vocab_size\n","\n","    if targets is None:\n","      loss = None\n","    else:\n","      B,T,C = logits.shape\n","      logits = logits.view(B*T, C)\n","      targets = targets.view(B*T)\n","      loss = F.cross_entropy(logits, targets)\n","    return logits, loss\n","\n","  def generate(self, idx, max_new_tokens):\n","    for _ in range(max_new_tokens):\n","      logits, loss = self(idx)\n","      logits = logits[:, -1, :] #B,C\n","      probs = F.softmax(logits, dim=-1) #B,C\n","      idx_next = torch.multinomial(probs, num_samples = 1) #B,1\n","      idx = torch.cat((idx, idx_next), dim=1) # B, T+1\n","    return idx\n","\n","model = BigramLanguageModel(vocab_size)\n","m = model.to(device)\n","\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n","\n","for iter in range(max_iters):\n","  if iter % eval_interval == 0:\n","    losses = estimate_loss()\n","    print(f'step:{iter} train loss:{losses['train']:.4f}, val loss:{losses['val']:.4f}')\n","  xb, yb = get_batch('train')\n","  logits, loss = model(xb, yb)\n","  optimizer.zero_grad(set_to_none=True)\n","  loss.backward()\n","  optimizer.step()\n","\n","context = torch.zeros((1,1), dtype=torch.long, device=device)\n","print(decode(m.generate(context, max_new_tokens=100)[0].tolist()))\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}