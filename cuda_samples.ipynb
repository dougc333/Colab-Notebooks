{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dougc333/Colab-Notebooks/blob/main/cuda_samples.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2pBc7Aq2Qun"
   },
   "source": [
    "CUDA Samples\n",
    "https://github.com/NVIDIA/cuda-samples/blob/master/Samples/6_Performance/transpose/transpose.cu\n",
    "\n",
    "\n",
    "1.   https://developer.nvidia.com/blog/unified-memory-cuda-beginners/   \n",
    "2.   https://developer.nvidia.com/blog/maximizing-unified-memory-performance-cuda/\n",
    "3. https://www.nvidia.com/en-us/on-demand/session/gtcspring21-cwes1175/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3056,
     "status": "ok",
     "timestamp": 1756432346861,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "Qip6jkQPrAzs",
    "outputId": "1bc82b20-b61b-4095-effd-d4cd32e4d262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "emacs is already the newest version (1:27.1+1-3ubuntu5.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!apt-get install emacs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1756432350097,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "Q0K9U4mx2WMl",
    "outputId": "86378903-b5af-4662-8300-117ffecdb54c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/cuda\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1756432352666,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "Kjoui1a9UN0Y",
    "outputId": "d9499148-3c16-47dd-8065-24931d544b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. PyTorch can use your GPU.\n",
      "Number of GPUs available: 1\n",
      "GPU Name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. PyTorch can use your GPU.\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\") # Prints the name of the first GPU\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use your CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 271627,
     "status": "ok",
     "timestamp": 1756427658981,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "s6Owm2l3u5P-",
    "outputId": "5060c609-b39a-4b37-a65b-d4335bddfa6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  cuda-cccl-12-4 cuda-command-line-tools-12-4 cuda-compiler-12-4 cuda-crt-12-4\n",
      "  cuda-cudart-12-4 cuda-cudart-dev-12-4 cuda-cuobjdump-12-4 cuda-cupti-12-4\n",
      "  cuda-cupti-dev-12-4 cuda-cuxxfilt-12-4 cuda-documentation-12-4\n",
      "  cuda-driver-dev-12-4 cuda-gdb-12-4 cuda-libraries-12-4\n",
      "  cuda-libraries-dev-12-4 cuda-nsight-12-4 cuda-nsight-compute-12-4\n",
      "  cuda-nsight-systems-12-4 cuda-nvcc-12-4 cuda-nvdisasm-12-4\n",
      "  cuda-nvml-dev-12-4 cuda-nvprof-12-4 cuda-nvprune-12-4 cuda-nvrtc-12-4\n",
      "  cuda-nvrtc-dev-12-4 cuda-nvtx-12-4 cuda-nvvm-12-4 cuda-nvvp-12-4\n",
      "  cuda-opencl-12-4 cuda-opencl-dev-12-4 cuda-profiler-api-12-4\n",
      "  cuda-sanitizer-12-4 cuda-toolkit-12-4-config-common cuda-tools-12-4\n",
      "  cuda-visual-tools-12-4 default-jre default-jre-headless fonts-dejavu-core\n",
      "  fonts-dejavu-extra gds-tools-12-4 libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libcublas-12-4 libcublas-dev-12-4 libcufft-12-4\n",
      "  libcufft-dev-12-4 libcufile-12-4 libcufile-dev-12-4 libcurand-12-4\n",
      "  libcurand-dev-12-4 libcusolver-12-4 libcusolver-dev-12-4 libcusparse-12-4\n",
      "  libcusparse-dev-12-4 libnpp-12-4 libnpp-dev-12-4 libnvfatbin-12-4\n",
      "  libnvfatbin-dev-12-4 libnvjitlink-12-4 libnvjitlink-dev-12-4 libnvjpeg-12-4\n",
      "  libnvjpeg-dev-12-4 libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1\n",
      "  libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1\n",
      "  libxkbcommon-x11-0 libxtst6 libxxf86dga1 nsight-compute-2024.1.1\n",
      "  nsight-systems-2023.4.4 openjdk-11-jre x11-utils\n",
      "Suggested packages:\n",
      "  mesa-utils\n",
      "The following NEW packages will be installed:\n",
      "  cuda-cccl-12-4 cuda-command-line-tools-12-4 cuda-compiler-12-4 cuda-crt-12-4\n",
      "  cuda-cudart-12-4 cuda-cudart-dev-12-4 cuda-cuobjdump-12-4 cuda-cupti-12-4\n",
      "  cuda-cupti-dev-12-4 cuda-cuxxfilt-12-4 cuda-documentation-12-4\n",
      "  cuda-driver-dev-12-4 cuda-gdb-12-4 cuda-libraries-12-4\n",
      "  cuda-libraries-dev-12-4 cuda-nsight-12-4 cuda-nsight-compute-12-4\n",
      "  cuda-nsight-systems-12-4 cuda-nvcc-12-4 cuda-nvdisasm-12-4\n",
      "  cuda-nvml-dev-12-4 cuda-nvprof-12-4 cuda-nvprune-12-4 cuda-nvrtc-12-4\n",
      "  cuda-nvrtc-dev-12-4 cuda-nvtx-12-4 cuda-nvvm-12-4 cuda-nvvp-12-4\n",
      "  cuda-opencl-12-4 cuda-opencl-dev-12-4 cuda-profiler-api-12-4\n",
      "  cuda-sanitizer-12-4 cuda-toolkit-12-4 cuda-toolkit-12-4-config-common\n",
      "  cuda-tools-12-4 cuda-visual-tools-12-4 default-jre default-jre-headless\n",
      "  fonts-dejavu-core fonts-dejavu-extra gds-tools-12-4 libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libcublas-12-4 libcublas-dev-12-4 libcufft-12-4\n",
      "  libcufft-dev-12-4 libcufile-12-4 libcufile-dev-12-4 libcurand-12-4\n",
      "  libcurand-dev-12-4 libcusolver-12-4 libcusolver-dev-12-4 libcusparse-12-4\n",
      "  libcusparse-dev-12-4 libnpp-12-4 libnpp-dev-12-4 libnvfatbin-12-4\n",
      "  libnvfatbin-dev-12-4 libnvjitlink-12-4 libnvjitlink-dev-12-4 libnvjpeg-12-4\n",
      "  libnvjpeg-dev-12-4 libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1\n",
      "  libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1\n",
      "  libxkbcommon-x11-0 libxtst6 libxxf86dga1 nsight-compute-2024.1.1\n",
      "  nsight-systems-2023.4.4 openjdk-11-jre x11-utils\n",
      "0 upgraded, 79 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 3,026 MB of archives.\n",
      "After this operation, 6,605 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre-headless amd64 2:1.11-72build2 [3,042 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.28+6-1ubuntu1~22.04.1 [214 kB]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cccl-12-4 12.4.127-1 [1,200 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre amd64 2:1.11-72build2 [896 B]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libtinfo5 amd64 6.3-2ubuntu0.1 [100 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
      "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cupti-12-4 12.4.127-1 [16.8 MB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
      "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cupti-dev-12-4 12.4.127-1 [3,830 kB]\n",
      "Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvdisasm-12-4 12.4.127-1 [49.9 MB]\n",
      "Get:25 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cuobjdump-12-4 12.4.127-1 [225 kB]\n",
      "Get:26 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-gdb-12-4 12.4.127-1 [4,920 kB]\n",
      "Get:27 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvprof-12-4 12.4.127-1 [2,431 kB]\n",
      "Get:28 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvtx-12-4 12.4.127-1 [51.5 kB]\n",
      "Get:29 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-sanitizer-12-4 12.4.127-1 [9,148 kB]\n",
      "Get:30 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-command-line-tools-12-4 12.4.1-1 [2,538 B]\n",
      "Get:31 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cuxxfilt-12-4 12.4.127-1 [191 kB]\n",
      "Get:32 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-toolkit-12-4-config-common 12.4.127-1 [16.4 kB]\n",
      "Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cudart-12-4 12.4.127-1 [165 kB]\n",
      "Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-driver-dev-12-4 12.4.127-1 [28.6 kB]\n",
      "Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cudart-dev-12-4 12.4.127-1 [1,000 kB]\n",
      "Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvvm-12-4 12.4.131-1 [19.5 MB]\n",
      "Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-crt-12-4 12.4.131-1 [78.0 kB]\n",
      "Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvcc-12-4 12.4.131-1 [32.0 MB]\n",
      "Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvprune-12-4 12.4.127-1 [58.8 kB]\n",
      "Get:40 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-compiler-12-4 12.4.1-1 [2,510 B]\n",
      "Get:41 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-documentation-12-4 12.4.127-1 [50.0 kB]\n",
      "Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvrtc-12-4 12.4.127-1 [17.6 MB]\n",
      "Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-opencl-12-4 12.4.127-1 [24.0 kB]\n",
      "Get:44 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcublas-12-4 12.4.5.8-1 [231 MB]\n",
      "Get:45 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcufft-12-4 11.2.1.3-1 [171 MB]\n",
      "Get:46 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcufile-12-4 1.9.1.3-1 [850 kB]\n",
      "Get:47 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcurand-12-4 10.3.5.147-1 [41.4 MB]\n",
      "Get:48 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcusolver-12-4 11.6.1.9-1 [78.9 MB]\n",
      "Get:49 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcusparse-12-4 12.3.1.170-1 [115 MB]\n",
      "Get:50 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnpp-12-4 12.2.5.30-1 [95.5 MB]\n",
      "Get:51 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvjitlink-12-4 12.4.127-1 [15.5 MB]\n",
      "Get:52 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvfatbin-12-4 12.4.127-1 [721 kB]\n",
      "Get:53 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvjpeg-12-4 12.3.1.117-1 [2,327 kB]\n",
      "Get:54 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-libraries-12-4 12.4.1-1 [2,606 B]\n",
      "Get:55 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-profiler-api-12-4 12.4.127-1 [18.7 kB]\n",
      "Get:56 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvrtc-dev-12-4 12.4.127-1 [16.9 MB]\n",
      "Get:57 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-opencl-dev-12-4 12.4.127-1 [87.0 kB]\n",
      "Get:58 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcublas-dev-12-4 12.4.5.8-1 [249 MB]\n",
      "Get:59 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcufft-dev-12-4 11.2.1.3-1 [342 MB]\n",
      "Get:60 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcufile-dev-12-4 1.9.1.3-1 [2,435 kB]\n",
      "Get:61 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcurand-dev-12-4 10.3.5.147-1 [41.6 MB]\n",
      "Get:62 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcusolver-dev-12-4 11.6.1.9-1 [51.4 MB]\n",
      "Get:63 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcusparse-dev-12-4 12.3.1.170-1 [116 MB]\n",
      "Get:64 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnpp-dev-12-4 12.2.5.30-1 [92.0 MB]\n",
      "Get:65 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvjitlink-dev-12-4 12.4.127-1 [13.9 MB]\n",
      "Get:66 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvfatbin-dev-12-4 12.4.127-1 [591 kB]\n",
      "Get:67 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvjpeg-dev-12-4 12.3.1.117-1 [2,025 kB]\n",
      "Get:68 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-libraries-dev-12-4 12.4.1-1 [2,646 B]\n",
      "Get:69 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nsight-12-4 12.4.127-1 [119 MB]\n",
      "Get:70 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-compute-2024.1.1 2024.1.1.4-1 [594 MB]\n",
      "Get:71 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nsight-compute-12-4 12.4.1-1 [4,060 B]\n",
      "Get:72 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-systems-2023.4.4 2023.4.4.54-234433681190v0 [316 MB]\n",
      "Get:73 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nsight-systems-12-4 12.4.1-1 [3,348 B]\n",
      "Get:74 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvml-dev-12-4 12.4.127-1 [145 kB]\n",
      "Get:75 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvvp-12-4 12.4.127-1 [115 MB]\n",
      "Get:76 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-visual-tools-12-4 12.4.1-1 [2,942 B]\n",
      "Get:77 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  gds-tools-12-4 1.9.1.3-1 [39.0 MB]\n",
      "Get:78 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-tools-12-4 12.4.1-1 [2,462 B]\n",
      "Get:79 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-toolkit-12-4 12.4.1-1 [3,336 B]\n",
      "Fetched 3,026 MB in 59s (51.7 MB/s)\n",
      "Extracting templates from packages: 100%\n",
      "Selecting previously unselected package cuda-cccl-12-4.\n",
      "(Reading database ... 131051 files and directories currently installed.)\n",
      "Preparing to unpack .../00-cuda-cccl-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-cccl-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-cupti-12-4.\n",
      "Preparing to unpack .../01-cuda-cupti-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-cupti-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-cupti-dev-12-4.\n",
      "Preparing to unpack .../02-cuda-cupti-dev-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-cupti-dev-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-nvdisasm-12-4.\n",
      "Preparing to unpack .../03-cuda-nvdisasm-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-nvdisasm-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-cuobjdump-12-4.\n",
      "Preparing to unpack .../04-cuda-cuobjdump-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-cuobjdump-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-gdb-12-4.\n",
      "Preparing to unpack .../05-cuda-gdb-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-gdb-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-nvprof-12-4.\n",
      "Preparing to unpack .../06-cuda-nvprof-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-nvprof-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-nvtx-12-4.\n",
      "Preparing to unpack .../07-cuda-nvtx-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-nvtx-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-sanitizer-12-4.\n",
      "Preparing to unpack .../08-cuda-sanitizer-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-sanitizer-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-command-line-tools-12-4.\n",
      "Preparing to unpack .../09-cuda-command-line-tools-12-4_12.4.1-1_amd64.deb ...\n",
      "Unpacking cuda-command-line-tools-12-4 (12.4.1-1) ...\n",
      "Selecting previously unselected package cuda-cuxxfilt-12-4.\n",
      "Preparing to unpack .../10-cuda-cuxxfilt-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-cuxxfilt-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-toolkit-12-4-config-common.\n",
      "Preparing to unpack .../11-cuda-toolkit-12-4-config-common_12.4.127-1_all.deb ...\n",
      "Unpacking cuda-toolkit-12-4-config-common (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-cudart-12-4.\n",
      "Preparing to unpack .../12-cuda-cudart-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-cudart-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-driver-dev-12-4.\n",
      "Preparing to unpack .../13-cuda-driver-dev-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-driver-dev-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-cudart-dev-12-4.\n",
      "Preparing to unpack .../14-cuda-cudart-dev-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-cudart-dev-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-nvvm-12-4.\n",
      "Preparing to unpack .../15-cuda-nvvm-12-4_12.4.131-1_amd64.deb ...\n",
      "Unpacking cuda-nvvm-12-4 (12.4.131-1) ...\n",
      "Selecting previously unselected package cuda-crt-12-4.\n",
      "Preparing to unpack .../16-cuda-crt-12-4_12.4.131-1_amd64.deb ...\n",
      "Unpacking cuda-crt-12-4 (12.4.131-1) ...\n",
      "Selecting previously unselected package cuda-nvcc-12-4.\n",
      "Preparing to unpack .../17-cuda-nvcc-12-4_12.4.131-1_amd64.deb ...\n",
      "Unpacking cuda-nvcc-12-4 (12.4.131-1) ...\n",
      "Selecting previously unselected package cuda-nvprune-12-4.\n",
      "Preparing to unpack .../18-cuda-nvprune-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-nvprune-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-compiler-12-4.\n",
      "Preparing to unpack .../19-cuda-compiler-12-4_12.4.1-1_amd64.deb ...\n",
      "Unpacking cuda-compiler-12-4 (12.4.1-1) ...\n",
      "Selecting previously unselected package cuda-documentation-12-4.\n",
      "Preparing to unpack .../20-cuda-documentation-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-documentation-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-nvrtc-12-4.\n",
      "Preparing to unpack .../21-cuda-nvrtc-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-nvrtc-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-opencl-12-4.\n",
      "Preparing to unpack .../22-cuda-opencl-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-opencl-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package libcublas-12-4.\n",
      "Preparing to unpack .../23-libcublas-12-4_12.4.5.8-1_amd64.deb ...\n",
      "Unpacking libcublas-12-4 (12.4.5.8-1) ...\n",
      "Selecting previously unselected package libcufft-12-4.\n",
      "Preparing to unpack .../24-libcufft-12-4_11.2.1.3-1_amd64.deb ...\n",
      "Unpacking libcufft-12-4 (11.2.1.3-1) ...\n",
      "Selecting previously unselected package libcufile-12-4.\n",
      "Preparing to unpack .../25-libcufile-12-4_1.9.1.3-1_amd64.deb ...\n",
      "Unpacking libcufile-12-4 (1.9.1.3-1) ...\n",
      "Selecting previously unselected package libcurand-12-4.\n",
      "Preparing to unpack .../26-libcurand-12-4_10.3.5.147-1_amd64.deb ...\n",
      "Unpacking libcurand-12-4 (10.3.5.147-1) ...\n",
      "Selecting previously unselected package libcusolver-12-4.\n",
      "Preparing to unpack .../27-libcusolver-12-4_11.6.1.9-1_amd64.deb ...\n",
      "Unpacking libcusolver-12-4 (11.6.1.9-1) ...\n",
      "Selecting previously unselected package libcusparse-12-4.\n",
      "Preparing to unpack .../28-libcusparse-12-4_12.3.1.170-1_amd64.deb ...\n",
      "Unpacking libcusparse-12-4 (12.3.1.170-1) ...\n",
      "Selecting previously unselected package libnpp-12-4.\n",
      "Preparing to unpack .../29-libnpp-12-4_12.2.5.30-1_amd64.deb ...\n",
      "Unpacking libnpp-12-4 (12.2.5.30-1) ...\n",
      "Selecting previously unselected package libnvjitlink-12-4.\n",
      "Preparing to unpack .../30-libnvjitlink-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking libnvjitlink-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package libnvfatbin-12-4.\n",
      "Preparing to unpack .../31-libnvfatbin-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking libnvfatbin-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package libnvjpeg-12-4.\n",
      "Preparing to unpack .../32-libnvjpeg-12-4_12.3.1.117-1_amd64.deb ...\n",
      "Unpacking libnvjpeg-12-4 (12.3.1.117-1) ...\n",
      "Selecting previously unselected package cuda-libraries-12-4.\n",
      "Preparing to unpack .../33-cuda-libraries-12-4_12.4.1-1_amd64.deb ...\n",
      "Unpacking cuda-libraries-12-4 (12.4.1-1) ...\n",
      "Selecting previously unselected package cuda-profiler-api-12-4.\n",
      "Preparing to unpack .../34-cuda-profiler-api-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-profiler-api-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-nvrtc-dev-12-4.\n",
      "Preparing to unpack .../35-cuda-nvrtc-dev-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-nvrtc-dev-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-opencl-dev-12-4.\n",
      "Preparing to unpack .../36-cuda-opencl-dev-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-opencl-dev-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package libcublas-dev-12-4.\n",
      "Preparing to unpack .../37-libcublas-dev-12-4_12.4.5.8-1_amd64.deb ...\n",
      "Unpacking libcublas-dev-12-4 (12.4.5.8-1) ...\n",
      "Selecting previously unselected package libcufft-dev-12-4.\n",
      "Preparing to unpack .../38-libcufft-dev-12-4_11.2.1.3-1_amd64.deb ...\n",
      "Unpacking libcufft-dev-12-4 (11.2.1.3-1) ...\n",
      "Selecting previously unselected package libcufile-dev-12-4.\n",
      "Preparing to unpack .../39-libcufile-dev-12-4_1.9.1.3-1_amd64.deb ...\n",
      "Unpacking libcufile-dev-12-4 (1.9.1.3-1) ...\n",
      "Selecting previously unselected package libcurand-dev-12-4.\n",
      "Preparing to unpack .../40-libcurand-dev-12-4_10.3.5.147-1_amd64.deb ...\n",
      "Unpacking libcurand-dev-12-4 (10.3.5.147-1) ...\n",
      "Selecting previously unselected package libcusolver-dev-12-4.\n",
      "Preparing to unpack .../41-libcusolver-dev-12-4_11.6.1.9-1_amd64.deb ...\n",
      "Unpacking libcusolver-dev-12-4 (11.6.1.9-1) ...\n",
      "Selecting previously unselected package libcusparse-dev-12-4.\n",
      "Preparing to unpack .../42-libcusparse-dev-12-4_12.3.1.170-1_amd64.deb ...\n",
      "Unpacking libcusparse-dev-12-4 (12.3.1.170-1) ...\n",
      "Selecting previously unselected package libnpp-dev-12-4.\n",
      "Preparing to unpack .../43-libnpp-dev-12-4_12.2.5.30-1_amd64.deb ...\n",
      "Unpacking libnpp-dev-12-4 (12.2.5.30-1) ...\n",
      "Selecting previously unselected package libnvjitlink-dev-12-4.\n",
      "Preparing to unpack .../44-libnvjitlink-dev-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking libnvjitlink-dev-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package libnvfatbin-dev-12-4.\n",
      "Preparing to unpack .../45-libnvfatbin-dev-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking libnvfatbin-dev-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package libnvjpeg-dev-12-4.\n",
      "Preparing to unpack .../46-libnvjpeg-dev-12-4_12.3.1.117-1_amd64.deb ...\n",
      "Unpacking libnvjpeg-dev-12-4 (12.3.1.117-1) ...\n",
      "Selecting previously unselected package cuda-libraries-dev-12-4.\n",
      "Preparing to unpack .../47-cuda-libraries-dev-12-4_12.4.1-1_amd64.deb ...\n",
      "Unpacking cuda-libraries-dev-12-4 (12.4.1-1) ...\n",
      "Selecting previously unselected package default-jre-headless.\n",
      "Preparing to unpack .../48-default-jre-headless_2%3a1.11-72build2_amd64.deb ...\n",
      "Unpacking default-jre-headless (2:1.11-72build2) ...\n",
      "Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../49-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
      "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
      "Selecting previously unselected package openjdk-11-jre:amd64.\n",
      "Preparing to unpack .../50-openjdk-11-jre_11.0.28+6-1ubuntu1~22.04.1_amd64.deb ...\n",
      "Unpacking openjdk-11-jre:amd64 (11.0.28+6-1ubuntu1~22.04.1) ...\n",
      "Selecting previously unselected package default-jre.\n",
      "Preparing to unpack .../51-default-jre_2%3a1.11-72build2_amd64.deb ...\n",
      "Unpacking default-jre (2:1.11-72build2) ...\n",
      "Selecting previously unselected package cuda-nsight-12-4.\n",
      "Preparing to unpack .../52-cuda-nsight-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-nsight-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package nsight-compute-2024.1.1.\n",
      "Preparing to unpack .../53-nsight-compute-2024.1.1_2024.1.1.4-1_amd64.deb ...\n",
      "Unpacking nsight-compute-2024.1.1 (2024.1.1.4-1) ...\n",
      "Selecting previously unselected package cuda-nsight-compute-12-4.\n",
      "Preparing to unpack .../54-cuda-nsight-compute-12-4_12.4.1-1_amd64.deb ...\n",
      "Unpacking cuda-nsight-compute-12-4 (12.4.1-1) ...\n",
      "Selecting previously unselected package libtinfo5:amd64.\n",
      "Preparing to unpack .../55-libtinfo5_6.3-2ubuntu0.1_amd64.deb ...\n",
      "Unpacking libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
      "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
      "Preparing to unpack .../56-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-icccm4:amd64.\n",
      "Preparing to unpack .../57-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
      "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
      "Selecting previously unselected package libxcb-util1:amd64.\n",
      "Preparing to unpack .../58-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
      "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
      "Selecting previously unselected package libxcb-image0:amd64.\n",
      "Preparing to unpack .../59-libxcb-image0_0.4.0-2_amd64.deb ...\n",
      "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
      "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
      "Preparing to unpack .../60-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
      "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
      "Selecting previously unselected package libxcb-render-util0:amd64.\n",
      "Preparing to unpack .../61-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
      "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
      "Selecting previously unselected package libxcb-xkb1:amd64.\n",
      "Preparing to unpack .../62-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
      "Preparing to unpack .../63-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
      "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libxcb-xinput0:amd64.\n",
      "Preparing to unpack .../64-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package nsight-systems-2023.4.4.\n",
      "Preparing to unpack .../65-nsight-systems-2023.4.4_2023.4.4.54-234433681190v0_amd64.deb ...\n",
      "Unpacking nsight-systems-2023.4.4 (2023.4.4.54-234433681190v0) ...\n",
      "Selecting previously unselected package cuda-nsight-systems-12-4.\n",
      "Preparing to unpack .../66-cuda-nsight-systems-12-4_12.4.1-1_amd64.deb ...\n",
      "Unpacking cuda-nsight-systems-12-4 (12.4.1-1) ...\n",
      "Selecting previously unselected package cuda-nvml-dev-12-4.\n",
      "Preparing to unpack .../67-cuda-nvml-dev-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-nvml-dev-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-nvvp-12-4.\n",
      "Preparing to unpack .../68-cuda-nvvp-12-4_12.4.127-1_amd64.deb ...\n",
      "Unpacking cuda-nvvp-12-4 (12.4.127-1) ...\n",
      "Selecting previously unselected package cuda-visual-tools-12-4.\n",
      "Preparing to unpack .../69-cuda-visual-tools-12-4_12.4.1-1_amd64.deb ...\n",
      "Unpacking cuda-visual-tools-12-4 (12.4.1-1) ...\n",
      "Selecting previously unselected package gds-tools-12-4.\n",
      "Preparing to unpack .../70-gds-tools-12-4_1.9.1.3-1_amd64.deb ...\n",
      "Unpacking gds-tools-12-4 (1.9.1.3-1) ...\n",
      "Selecting previously unselected package cuda-tools-12-4.\n",
      "Preparing to unpack .../71-cuda-tools-12-4_12.4.1-1_amd64.deb ...\n",
      "Unpacking cuda-tools-12-4 (12.4.1-1) ...\n",
      "Selecting previously unselected package cuda-toolkit-12-4.\n",
      "Preparing to unpack .../72-cuda-toolkit-12-4_12.4.1-1_amd64.deb ...\n",
      "Unpacking cuda-toolkit-12-4 (12.4.1-1) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../73-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
      "Selecting previously unselected package fonts-dejavu-extra.\n",
      "Preparing to unpack .../74-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
      "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
      "Selecting previously unselected package libxxf86dga1:amd64.\n",
      "Preparing to unpack .../75-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
      "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
      "Selecting previously unselected package x11-utils.\n",
      "Preparing to unpack .../76-x11-utils_7.7+5build2_amd64.deb ...\n",
      "Unpacking x11-utils (7.7+5build2) ...\n",
      "Selecting previously unselected package libatk-wrapper-java.\n",
      "Preparing to unpack .../77-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
      "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
      "Preparing to unpack .../78-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
      "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
      "Setting up cuda-cupti-12-4 (12.4.127-1) ...\n",
      "Setting up cuda-nvml-dev-12-4 (12.4.127-1) ...\n",
      "Setting up default-jre-headless (2:1.11-72build2) ...\n",
      "Setting up cuda-cccl-12-4 (12.4.127-1) ...\n",
      "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up cuda-cupti-dev-12-4 (12.4.127-1) ...\n",
      "Setting up gds-tools-12-4 (1.9.1.3-1) ...\n",
      "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
      "Setting up cuda-documentation-12-4 (12.4.127-1) ...\n",
      "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
      "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
      "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
      "Setting up openjdk-11-jre:amd64 (11.0.28+6-1ubuntu1~22.04.1) ...\n",
      "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
      "Setting up default-jre (2:1.11-72build2) ...\n",
      "Setting up cuda-profiler-api-12-4 (12.4.127-1) ...\n",
      "Setting up cuda-nvdisasm-12-4 (12.4.127-1) ...\n",
      "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
      "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
      "Setting up cuda-nvvm-12-4 (12.4.131-1) ...\n",
      "Setting up cuda-nvprune-12-4 (12.4.127-1) ...\n",
      "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up cuda-nvtx-12-4 (12.4.127-1) ...\n",
      "Setting up cuda-cuxxfilt-12-4 (12.4.127-1) ...\n",
      "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
      "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
      "Setting up cuda-nsight-12-4 (12.4.127-1) ...\n",
      "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
      "Setting up nsight-compute-2024.1.1 (2024.1.1.4-1) ...\n",
      "Setting up cuda-driver-dev-12-4 (12.4.127-1) ...\n",
      "Setting up cuda-nvprof-12-4 (12.4.127-1) ...\n",
      "Setting up x11-utils (7.7+5build2) ...\n",
      "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
      "Setting up libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
      "Setting up cuda-cuobjdump-12-4 (12.4.127-1) ...\n",
      "Setting up cuda-toolkit-12-4-config-common (12.4.127-1) ...\n",
      "Setting alternatives\n",
      "Setting up libnvjitlink-12-4 (12.4.127-1) ...\n",
      "Setting up cuda-nvrtc-12-4 (12.4.127-1) ...\n",
      "Setting up cuda-sanitizer-12-4 (12.4.127-1) ...\n",
      "Setting up libcurand-12-4 (10.3.5.147-1) ...\n",
      "Setting up libnpp-12-4 (12.2.5.30-1) ...\n",
      "Setting up libcufft-12-4 (11.2.1.3-1) ...\n",
      "Setting up cuda-nvvp-12-4 (12.4.127-1) ...\n",
      "Setting up libnvjitlink-dev-12-4 (12.4.127-1) ...\n",
      "Setting up libcublas-12-4 (12.4.5.8-1) ...\n",
      "Setting up libcusparse-12-4 (12.3.1.170-1) ...\n",
      "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
      "Setting up libnvfatbin-12-4 (12.4.127-1) ...\n",
      "Setting up libcurand-dev-12-4 (10.3.5.147-1) ...\n",
      "Setting up libnvjpeg-12-4 (12.3.1.117-1) ...\n",
      "Setting up cuda-nsight-compute-12-4 (12.4.1-1) ...\n",
      "Setting up libcufile-12-4 (1.9.1.3-1) ...\n",
      "Setting alternatives\n",
      "Setting up nsight-systems-2023.4.4 (2023.4.4.54-234433681190v0) ...\n",
      "update-alternatives: using /opt/nvidia/nsight-systems/2023.4.4/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n",
      "update-alternatives: using /opt/nvidia/nsight-systems/2023.4.4/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\n",
      "Setting up libnpp-dev-12-4 (12.2.5.30-1) ...\n",
      "Setting up cuda-opencl-12-4 (12.4.127-1) ...\n",
      "Setting up libcusparse-dev-12-4 (12.3.1.170-1) ...\n",
      "Setting up cuda-nvrtc-dev-12-4 (12.4.127-1) ...\n",
      "Setting up libcublas-dev-12-4 (12.4.5.8-1) ...\n",
      "Setting up cuda-cudart-12-4 (12.4.127-1) ...\n",
      "Setting up cuda-gdb-12-4 (12.4.127-1) ...\n",
      "Setting up libcusolver-12-4 (11.6.1.9-1) ...\n",
      "Setting up cuda-libraries-12-4 (12.4.1-1) ...\n",
      "Setting up cuda-nsight-systems-12-4 (12.4.1-1) ...\n",
      "Setting up libcusolver-dev-12-4 (11.6.1.9-1) ...\n",
      "Setting up libcufft-dev-12-4 (11.2.1.3-1) ...\n",
      "Setting up cuda-command-line-tools-12-4 (12.4.1-1) ...\n",
      "Setting up cuda-opencl-dev-12-4 (12.4.127-1) ...\n",
      "Setting up libnvfatbin-dev-12-4 (12.4.127-1) ...\n",
      "Setting up cuda-cudart-dev-12-4 (12.4.127-1) ...\n",
      "Setting up cuda-crt-12-4 (12.4.131-1) ...\n",
      "Setting up libnvjpeg-dev-12-4 (12.3.1.117-1) ...\n",
      "Setting up libcufile-dev-12-4 (1.9.1.3-1) ...\n",
      "Setting up cuda-nvcc-12-4 (12.4.131-1) ...\n",
      "Setting up cuda-compiler-12-4 (12.4.1-1) ...\n",
      "Setting up cuda-libraries-dev-12-4 (12.4.1-1) ...\n",
      "Setting up cuda-visual-tools-12-4 (12.4.1-1) ...\n",
      "Setting up cuda-tools-12-4 (12.4.1-1) ...\n",
      "Setting up cuda-toolkit-12-4 (12.4.1-1) ...\n",
      "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "#faster\n",
    "!apt-get -y install cuda-toolkit-12-4\n",
    "!rm /etc/alternatives/cuda\n",
    "!ln -s  /usr/local/cuda-12.4 /etc/alternatives/cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1756432369074,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "BdqmFC7j1bC4",
    "outputId": "ac67090e-2036-487a-cb8f-57a78b1ab097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 29 01:52:49 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   43C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1756432373449,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "RWgX2utc1ddC",
    "outputId": "308df9c4-89d7-4ee6-97e9-0f07609717d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Mar_28_02:18:24_PDT_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.131\n",
      "Build cuda_12.4.r12.4/compiler.34097967_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1756135795073,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "DKxkPaC-zXj4",
    "outputId": "fcfad38f-e73a-4983-b37b-06637ccc1d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting check_unified.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile check_unified.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "int main() {\n",
    "    cudaDeviceProp prop;\n",
    "    int device = 0;  // pick device 0\n",
    "\n",
    "    cudaError_t err = cudaGetDeviceProperties(&prop, device);\n",
    "    if (err != cudaSuccess) {\n",
    "        printf(\"cudaGetDeviceProperties failed: %s\\n\", cudaGetErrorString(err));\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    printf(\"Device %d: %s\\n\", device, prop.name);\n",
    "    printf(\"Unified addressing: %d\\n\", prop.unifiedAddressing);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1756135797235,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "ji2vaMar1tc_",
    "outputId": "a1926f48-17fa-4697-8f3d-79192b78201d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /content/drive/MyDrive/cuda: Is a directory\n"
     ]
    }
   ],
   "source": [
    "!/content/drive/MyDrive/cuda nvcc -o check_unified check_unified.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6HkjfGV2goS"
   },
   "outputs": [],
   "source": [
    "!chmod 755 /content/drive/MyDrive/cuda/check_unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1756258049162,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "E33ro6PJ1ksE",
    "outputId": "357af35b-08aa-497f-ba85-245a3b7b2453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /content/drive/MyDrive/cuda/check_unified: Permission denied\n"
     ]
    }
   ],
   "source": [
    "!/content/drive/MyDrive/cuda/check_unified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9UcHp7l9eXX"
   },
   "source": [
    "** Unified Addressing **\n",
    "Unified addressing is a single address space accessible by any GPU/CPU\n",
    "It adds a page handling mechanism in the OS kernel on a page fault when mapping VM address to physical address.\n",
    "\n",
    "Reference: https://developer.nvidia.com/blog/maximizing-unified-memory-performance-in-cuda/\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1xrOgMck9tXkDHiHoKldqVkFRjYtXSDAH\">\n",
    "\n",
    "Unified memory\n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1FLrnkIgEPIBtrndQbdpSpegM2dxYYVCj\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1756327730941,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "v1DBOqyjluom",
    "outputId": "ee48992f-4bf8-43a9-e065-d395068fed0e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/cuda'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eN2hbmF-026"
   },
   "source": [
    "First cuda program\n",
    "\n",
    "Called saxpy. Copied verbatim from blog. Structure of cuda program\n",
    "\n",
    "\n",
    "1.   ```__global__ void fn``` is a kernel. This code runs on the gpu\n",
    "2. there are 2 models, a hardware model of the chip and a logical model of grids, blocks and threads.\n",
    "\n",
    "**Hardware model**\n",
    "*   The GPU consists of SMs. Each block is run in a SM. One SM can run multiple blocks.\n",
    "*   Blocks contain threads. Each group of 32 threads is a warp. Blocks are interleaved in SMs\n",
    "```\n",
    " ---------------\n",
    "| SM0: B0, B3\n",
    "|---------------\n",
    "| SM1: B1, B4\n",
    "|---------------\n",
    "| SM2: B2, B5\n",
    "|---------------\n",
    "```\n",
    "The gpu scheduler runs blocks in SMs dynamically. The above figure can be deceptive in guaranteeing an order of execution.\n",
    "\n",
    "**Logical model **\n",
    "\n",
    "*   The logical model starts with a 1D, 2D or 3D assumption.\n",
    "*   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3.  Thread indexing:  i = blockIdx.x * blockDim.x + threadIdx.x. This is global thread indexing. Global thread indexing has implications on how <<gridDim, blockDim, sharedMem, stream>> are computed.\n",
    "\n",
    "*   gridDim=num blocks to launch\n",
    "*   blockDim=num threads per block\n",
    "*   sharedmem:allocate sm per block\n",
    "*   stream:used to overlap kernels and memcopies\n",
    "\n",
    "How to set <<gridDim, blockDim>>? numBlocks is calculated from gridDim. numBlocks isn't a reserved keyword it is our abbreviation for number of blocks\n",
    "\n",
    "\n",
    "*  For 1D, numBlocks=gridDim.x,\n",
    "*  2D, numBlocks=gridDim.x * gridDim.y.\n",
    "*  3d numBlocks = gridDim.x * gridDim.y * gridDimg.z\n",
    "\n",
    "How is N divided? One way is to divide each single N into a separate thread.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://developer.nvidia.com/blog/easy-introduction-cuda-c-and-c/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1756437420843,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "H8AdJ-B1hl-g",
    "outputId": "e5ed27f3-b20b-41be-a1cb-12c154847634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stall.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile stall.cu\n",
    "\n",
    "#include <nvtx3/nvToolsExt.h>\n",
    "\n",
    "__global__ void kernel(float *a, int N ) {\n",
    "    int gid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (gid < N) {\n",
    "        a[gid] = a[gid] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int N = 1<<20;\n",
    "    float *a, *d_a;\n",
    "    a = (float *)malloc(N*sizeof(float));\n",
    "\n",
    "    cudaMalloc(&d_a, N*sizeof(float));\n",
    "\n",
    "    //initialize data before memcpy\n",
    "    for(int i=0;i<N; i++){\n",
    "      a[i] = float(i);\n",
    "    }\n",
    "    cudaMemcpy(d_a, a, N*sizeof(float), cudaMemcpyHostToDevice);\n",
    "    nvtxRangePushA(\"Kernel Launch\");\n",
    "    kernel<<<(N+255)/256, 256>>>(d_a, N);\n",
    "    cudaMemcpy(a, d_a, N*sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "    nvtxRangePop();\n",
    "    for(int j=0;j<N;j++){\n",
    "      printf(\"a:%f\",a[j]);\n",
    "    }\n",
    "    cudaFree(d_a);\n",
    "    free(a);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 1403,
     "status": "ok",
     "timestamp": 1756437424288,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "dm_L4DHFh4dl"
   },
   "outputs": [],
   "source": [
    "!nvcc -o stall stall.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1756437457174,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "5L9EQiBUh4kF"
   },
   "outputs": [],
   "source": [
    "!chmod +x /content/drive/MyDrive/cuda/stall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1UXsrO6aBVXPQsSjdRbYZOB8tESIf95Tq"
    },
    "id": "6__QcILG1LGb",
    "outputId": "dc78b12a-9f0f-4cfb-9cf8-2adc038518ce"
   },
   "outputs": [],
   "source": [
    "!/content/drive/MyDrive/cuda/stall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpaRAEfp-dso"
   },
   "outputs": [],
   "source": [
    "%%writefile saxpy.cu\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__\n",
    "void saxpy(int n, float a, float *x, float *y)\n",
    "{\n",
    "  int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "  if (i < n) y[i] = a*x[i] + y[i];\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  int N = 1<<20;\n",
    "\n",
    "  float *x, *y, *d_x, *d_y;\n",
    "\n",
    "  x = (float*)malloc(N*sizeof(float));\n",
    "  y = (float*)malloc(N*sizeof(float));\n",
    "\n",
    "  cudaMalloc(&d_x, N*sizeof(float));\n",
    "  cudaMalloc(&d_y, N*sizeof(float));\n",
    "\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  cudaMemcpy(d_x, x, N*sizeof(float), cudaMemcpyHostToDevice);\n",
    "  cudaMemcpy(d_y, y, N*sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "  // Perform SAXPY on 1M elements\n",
    "  saxpy<<<(N+255)/256, 256>>>(N, 2.0f, d_x, d_y);\n",
    "\n",
    "  cudaMemcpy(y, d_y, N*sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = max(maxError, abs(y[i]-4.0f));\n",
    "  printf(\"Max error: %f\\n\", maxError);\n",
    "\n",
    "  cudaFree(d_x);\n",
    "  cudaFree(d_y);\n",
    "  free(x);\n",
    "  free(y);\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QU2FP4QmP4FU"
   },
   "source": [
    "  ```\n",
    "  int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "  if (i < n) y[i] = a*x[i] + y[i];\n",
    "```\n",
    "i corresponds to each thread. We have to test i<n because\n",
    "```\n",
    " (1024*1024+255)/256\n",
    "4096.99609375\n",
    "```\n",
    "we get 4097 but want 4096 so test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4yfhDZE-oqZ"
   },
   "outputs": [],
   "source": [
    "!/content/drive/MyDrive/cuda nvcc -o saxpy saxpy.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwpAwGQp-ow7"
   },
   "outputs": [],
   "source": [
    "!chmod 755 /content/drive/MyDrive/cuda/saxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1zmzsGl_B7o"
   },
   "outputs": [],
   "source": [
    "!/content/drive/MyDrive/cuda/saxpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvSaZYSy_XKx"
   },
   "source": [
    "https://developer.nvidia.com/blog/how-implement-performance-metrics-cuda-cc/\n",
    "Second saxpy post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1756324895464,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "niccjDxQ_ZLG",
    "outputId": "405a714c-709e-4e6e-e910-99ac34de90b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting saxpy_2nd_blog_post.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile saxpy_2nd_blog_post.cu\n",
    "\n",
    "//https://developer.nvidia.com/blog/how-implement-performance-metrics-cuda-cc/\n",
    "//confusing first part of post uses cpu timers; incomplete\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <chrono>\n",
    "\n",
    "__global__\n",
    "void saxpy(int n, float a, float *x, float *y)\n",
    "{\n",
    "  int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "  if (i < n) y[i] = a*x[i] + y[i];\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  cudaEvent_t start, stop;\n",
    "  cudaEventCreate(&start);\n",
    "  cudaEventCreate(&stop);\n",
    "\n",
    "\n",
    "  int N = 20*(1<<20);\n",
    "  float *x, *y, *d_x, *d_y;\n",
    "  x = (float*)malloc(N*sizeof(float));\n",
    "  y = (float*)malloc(N*sizeof(float));\n",
    "\n",
    "  cudaMalloc(&d_x, N*sizeof(float));\n",
    "  cudaMalloc(&d_y, N*sizeof(float));\n",
    "\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  cudaMemcpy(d_x, x, N*sizeof(float), cudaMemcpyHostToDevice);\n",
    "  cudaMemcpy(d_y, y, N*sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "\n",
    "  cudaEventRecord(start);\n",
    "  saxpy<<<(N+255)/256, 256>>>(N, 2.0, d_x, d_y);\n",
    "  cudaEventRecord(stop);\n",
    "\n",
    "  // Perform SAXPY on 1M elements\n",
    "  cudaMemcpy(y, d_y, N*sizeof(float), cudaMemcpyDeviceToHost);\n",
    "  cudaEventSynchronize(stop);\n",
    "  float milliseconds = 0;\n",
    "  cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = max(maxError, abs(y[i]-4.0f));\n",
    "  printf(\"Max error: %f milliseconds t2-t1: %f\\n\", maxError,milliseconds );\n",
    "  printf(\"Effective Bandwidth (GB/s): %f \\n\", N*4*3/milliseconds/1e6);\n",
    "  cudaFree(d_x);\n",
    "  cudaFree(d_y);\n",
    "  free(x);\n",
    "  free(y);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M03r2KqFCTAc"
   },
   "outputs": [],
   "source": [
    "!nvcc -o saxpy_2nd_blog_post saxpy_2nd_blog_post.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsNCLnsICTC_"
   },
   "outputs": [],
   "source": [
    "!chmod 755 /content/drive/MyDrive/cuda/saxpy_2nd_blog_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1756324904199,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "zrbNklOFCTFl",
    "outputId": "f827d9f8-2629-4230-91e6-323dab4012cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Max error: 0.000000 milliseconds t2-t1: 1.081248',\n",
       " 'Effective Bandwidth (GB/s): 232.747920 ']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!/content/drive/MyDrive/cuda/saxpy_2nd_blog_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1756330606706,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "SYQR7lb9ciVl",
    "outputId": "c3a55684-b9ef-47c4-ce4e-6d4bc2909738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing saxpy_unified.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile saxpy_unified.cu\n",
    "#include <stdio.h>\n",
    "#include <chrono>\n",
    "\n",
    "__global__\n",
    "void saxpy(int n, float a, float *x, float *y)\n",
    "{\n",
    "  int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "  if (i < n) y[i] = a*x[i] + y[i];\n",
    "}\n",
    "\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  cudaEvent_t start, stop;\n",
    "  cudaEventCreate(&start);\n",
    "  cudaEventCreate(&stop);\n",
    "\n",
    "\n",
    "  int N = 20*(1<<20);\n",
    "  float *x, *y, *d_x, *d_y;\n",
    "  //shouldnt need a malloc either?\n",
    "  x = (float*)malloc(N*sizeof(float));\n",
    "  y = (float*)malloc(N*sizeof(float));\n",
    "\n",
    "  cudaMallocManaged(&d_x, N*sizeof(float));\n",
    "  cudaMallocManaged(&d_y, N*sizeof(float));\n",
    "\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  //this is wrong, shouldnt need memcpy w unified\n",
    "  /*cudaMemcpy(d_x, x, N*sizeof(float), cudaMemcpyHostToDevice);*/\n",
    "  /*cudaMemcpy(d_y, y, N*sizeof(float), cudaMemcpyHostToDevice);*/\n",
    "\n",
    "  cudaEventRecord(start);\n",
    "  saxpy<<<(N+255)/256, 256>>>(N, 2.0, d_x, d_y);\n",
    "  cudaEventRecord(stop);\n",
    "\n",
    "  // Perform SAXPY on 1M elements\n",
    "  cudaMemcpy(y, d_y, N*sizeof(float), cudaMemcpyDeviceToHost);\n",
    "  cudaEventSynchronize(stop);\n",
    "  float milliseconds = 0;\n",
    "  cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "\n",
    "\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = max(maxError, abs(y[i]-4.0f));\n",
    "  printf(\"Max error: %f milliseconds t2-t1: %f\\n\", maxError,milliseconds );\n",
    "  printf(\"Effective Bandwidth (GB/s): %f \\n\", N*4*3/milliseconds/1e6);\n",
    "  cudaFree(d_x);\n",
    "  cudaFree(d_y);\n",
    "  free(x);\n",
    "  free(y);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1756330640404,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "HxsFuuUjdI2M",
    "outputId": "4fc0a996-c2c8-41b9-f1b7-0ea24b6dea9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/cuda\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/cuda\n",
    "!nvcc -o saxpy_unified saxpy_unified.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBUpgdkmdI6o"
   },
   "outputs": [],
   "source": [
    "!chmod 755 /content/drive/MyDrive/cuda/saxpy_unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1754,
     "status": "ok",
     "timestamp": 1756330707911,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "SD5l5Qsbdv9D",
    "outputId": "9280940d-8afd-4e4f-af91-a288aa0d7395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error: 0.000000 milliseconds t2-t1: 1.229472\n",
      "Effective Bandwidth (GB/s): 204.688048 \n"
     ]
    }
   ],
   "source": [
    "!/content/drive/MyDrive/cuda/saxpy_unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1756330722762,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "m7FbHBCHdI-g",
    "outputId": "ed967f90-5c03-444e-be9d-9d3c850bf01c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==38747== NVPROF is profiling process 38747, command: /content/drive/MyDrive/cuda/saxpy_unified\n",
      "Max error: 0.000000 milliseconds t2-t1: 1.286400\n",
      "Effective Bandwidth (GB/s): 195.629856 \n",
      "==38747== Profiling application: /content/drive/MyDrive/cuda/saxpy_unified\n",
      "==38747== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   69.42%  42.531ms         2  21.266ms  21.122ms  21.409ms  [CUDA memcpy HtoD]\n",
      "                   29.00%  17.771ms         1  17.771ms  17.771ms  17.771ms  [CUDA memcpy DtoH]\n",
      "                    1.58%  965.64us         1  965.64us  965.64us  965.64us  saxpy(int, float, float*, float*)\n",
      "      API calls:   51.15%  95.186ms         2  47.593ms  8.3260us  95.178ms  cudaEventCreate\n",
      "                   33.42%  62.194ms         3  20.731ms  19.058ms  21.754ms  cudaMemcpy\n",
      "                   10.98%  20.424ms         2  10.212ms  63.777us  20.360ms  cudaMallocManaged\n",
      "                    4.18%  7.7761ms         2  3.8881ms  3.8747ms  3.9015ms  cudaFree\n",
      "                    0.17%  317.76us         1  317.76us  317.76us  317.76us  cudaLaunchKernel\n",
      "                    0.08%  139.89us       114  1.2270us     104ns  56.987us  cuDeviceGetAttribute\n",
      "                    0.01%  15.895us         2  7.9470us  5.7740us  10.121us  cudaEventRecord\n",
      "                    0.01%  12.253us         1  12.253us  12.253us  12.253us  cuDeviceGetName\n",
      "                    0.00%  8.0200us         1  8.0200us  8.0200us  8.0200us  cuDeviceGetPCIBusId\n",
      "                    0.00%  5.7490us         1  5.7490us  5.7490us  5.7490us  cudaEventSynchronize\n",
      "                    0.00%  2.9370us         1  2.9370us  2.9370us  2.9370us  cudaEventElapsedTime\n",
      "                    0.00%  1.1800us         3     393ns     121ns     829ns  cuDeviceGetCount\n",
      "                    0.00%     796ns         2     398ns     141ns     655ns  cuDeviceGet\n",
      "                    0.00%     558ns         1     558ns     558ns     558ns  cuModuleGetLoadingMode\n",
      "                    0.00%     332ns         1     332ns     332ns     332ns  cuDeviceTotalMem\n",
      "                    0.00%     269ns         1     269ns     269ns     269ns  cuDeviceGetUuid\n",
      "\n",
      "==38747== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "     301         -         -         -           -  33.30321ms  Gpu page fault groups\n"
     ]
    }
   ],
   "source": [
    "!nvprof /content/drive/MyDrive/cuda/saxpy_unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJQrVkD9dJCI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WF00BNuwbpsL"
   },
   "source": [
    "** Pinned Memory **\n",
    "\n",
    "Pinned memory cannot be paged by the CPU. Use cudaHostAlloc instead of cudaMalloc. This allocates a fixed area in the CPU address space which is directly DMAed into GPU address space over interconnect, PCIe or nvlink. cudaMemcpyAsync requires pinned memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "419-9Z23cxhD"
   },
   "outputs": [],
   "source": [
    "%%writefile cuda_memcpy_async\n",
    "\n",
    "#include <iostream>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// A simple kernel that doubles each element\n",
    "__global__ void doubleElements(int *d_data, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        d_data[idx] *= 2;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int N = 1 << 16;  // 65536 ints\n",
    "    const int SIZE = N * sizeof(int);\n",
    "\n",
    "    int *h_data;            // host pointer\n",
    "    int *d_data;            // device pointer\n",
    "    cudaStream_t stream;    // CUDA stream for async ops\n",
    "\n",
    "    // Allocate pinned (page-locked) memory on host (needed for async copies)\n",
    "    cudaMallocHost((void**)&h_data, SIZE);\n",
    "    // Allocate memory on device\n",
    "    cudaMalloc((void**)&d_data, SIZE);\n",
    "\n",
    "    // Initialize host data\n",
    "    for (int i = 0; i < N; i++) h_data[i] = i;\n",
    "\n",
    "    // Create a stream\n",
    "    cudaStreamCreate(&stream);\n",
    "\n",
    "    // Async copy host->device\n",
    "    cudaMemcpyAsync(d_data, h_data, SIZE, cudaMemcpyHostToDevice, stream);\n",
    "\n",
    "    // Launch kernel in same stream\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    doubleElements<<<blocks, threads, 0, stream>>>(d_data, N);\n",
    "\n",
    "    // Async copy device->host\n",
    "    cudaMemcpyAsync(h_data, d_data, SIZE, cudaMemcpyDeviceToHost, stream);\n",
    "\n",
    "    // Wait for stream to complete\n",
    "    cudaStreamSynchronize(stream);\n",
    "\n",
    "    // Check results\n",
    "    std::cout << \"h_data[0] = \" << h_data[0] << \"\\n\";\n",
    "    std::cout << \"h_data[N-1] = \" << h_data[N-1] << \"\\n\";\n",
    "\n",
    "    // Cleanup\n",
    "    cudaStreamDestroy(stream);\n",
    "    cudaFree(d_data);\n",
    "    cudaFreeHost(h_data);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29427,
     "status": "ok",
     "timestamp": 1756325380651,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "zl9i-bjX_ZNK",
    "outputId": "470c128e-48d4-4a8a-a08f-d5bcb8ea5d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cuda-samples'...\n",
      "remote: Enumerating objects: 30412, done.\u001b[K\n",
      "remote: Counting objects: 100% (14672/14672), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1471/1471), done.\u001b[K\n",
      "remote: Total 30412 (delta 13818), reused 13201 (delta 13201), pack-reused 15740 (from 2)\u001b[K\n",
      "Receiving objects: 100% (30412/30412), 135.80 MiB | 17.20 MiB/s, done.\n",
      "Resolving deltas: 100% (26469/26469), done.\n",
      "Updating files: 100% (2052/2052), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/cuda-samples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2409,
     "status": "ok",
     "timestamp": 1756327700139,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "psK0EyWT_ZPi",
    "outputId": "5d04d430-fced-4159-c407-0bdd4789dbc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1756328888046,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "cXC-V1Ct_ZRn",
    "outputId": "afd2a66d-b495-4a8f-ab7c-d7e32fbb3cf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/cuda/cuda-samples\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/cuda/cuda-samples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1756328890280,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "aeZ132yK_ZUN",
    "outputId": "fc04a31d-cf75-443e-eeaf-072d60d4fa9e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/cuda/cuda-samples'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cEseO_Z_ZWS"
   },
   "outputs": [],
   "source": [
    "!mkdir build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1756328895566,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "pDZfP6aPS3tm",
    "outputId": "ef9bf5e8-f5bb-43cb-b852-b37814b36c21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/cuda/cuda-samples/build\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/cuda/cuda-samples/build/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52773,
     "status": "ok",
     "timestamp": 1756329566737,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "veklWjeIS94X",
    "outputId": "3ae44543-0044-415a-cf60-535749ade6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 11.4.0\n",
      "-- The CXX compiler identification is GNU 11.4.0\n",
      "-- The CUDA compiler identification is NVIDIA 12.4.131 with host compiler GNU 11.4.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Detecting CUDA compiler ABI info\n",
      "-- Detecting CUDA compiler ABI info - done\n",
      "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
      "-- Detecting CUDA compile features\n",
      "-- Detecting CUDA compile features - done\n",
      "-- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include (found version \"12.4.131\")\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE\n",
      "-- OpenMP not found - will not build sample 'UnifiedMemoryStreams'\n",
      "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
      "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
      "-- Could NOT find OpenMP_CUDA (missing: OpenMP_CUDA_FLAGS OpenMP_CUDA_LIB_NAMES) \n",
      "-- Could NOT find OpenMP (missing: OpenMP_CUDA_FOUND) (found version \"4.5\")\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'simpleCUDA2GL'\n",
      "-- Found MPI_C: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so (found version \"3.1\")\n",
      "-- Found MPI_CXX: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so (found version \"3.1\")\n",
      "-- Found MPI: TRUE (found version \"3.1\")\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'simpleTexture3D'\n",
      "-- Could NOT find EGL (missing: EGL_LIBRARY EGL_INCLUDE_DIR) \n",
      "-- EGL not found - will not build sample 'EGLStream_CUDA_CrossGPU'\n",
      "-- Could NOT find EGL (missing: EGL_LIBRARY EGL_INCLUDE_DIR) \n",
      "-- EGL not found - will not build sample 'EGLStream_CUDA_Interop'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'FunctionPointers'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'boxFilter'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'imageDenoising'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'particles'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'bindlessTexture'\n",
      "-- Could NOT find FreeImage (missing: FreeImage_LIBRARY FreeImage_INCLUDE_DIR) \n",
      "-- FreeImage not found - will not build sample 'FilterBorderControlNPP'\n",
      "-- Could NOT find FreeImage (missing: FreeImage_LIBRARY FreeImage_INCLUDE_DIR) \n",
      "-- FreeImage not found - will not build sample 'boxFilterNPP'\n",
      "-- Could NOT find FreeImage (missing: FreeImage_LIBRARY FreeImage_INCLUDE_DIR) \n",
      "-- FreeImage not found - will not build sample 'cannyEdgeDetectorNPP'\n",
      "-- Could NOT find NVSCI (missing: NVSCIBUF_LIBRARY NVSCISYNC_LIBRARY NVSCIBUF_INCLUDE_DIR NVSCISYNC_INCLUDE_DIR) \n",
      "-- NvSCI not found - will not build sample 'cudaNvSci'\n",
      "-- Could NOT find FreeImage (missing: FreeImage_LIBRARY FreeImage_INCLUDE_DIR) \n",
      "-- FreeImage not found - will not build sample 'freeImageInteropNPP'\n",
      "-- Could NOT find FreeImage (missing: FreeImage_LIBRARY FreeImage_INCLUDE_DIR) \n",
      "-- FreeImage not found - will not build sample 'histEqualizationNPP'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'oceanFFT'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'randomFog'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'Mandelbrot'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'SobelFilter'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'bicubicTexture'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'bilateralFilter'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'fluidsGL'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'marchingCubes'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'nbody'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'postProcessGL'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'recursiveGaussian'\n",
      "-- Sample 'simpleD3D11' is Windows-only - skipping\n",
      "-- Sample 'simpleD3D11Texture' is Windows-only - skipping\n",
      "-- Sample 'simpleD3D12' is Windows-only - skipping\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'simpleGL'\n",
      "-- Could NOT find Vulkan (missing: Vulkan_LIBRARY Vulkan_INCLUDE_DIR) (found version \"\")\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Looking for GLFW/glfw3.h\n",
      "-- Looking for GLFW/glfw3.h - not found\n",
      "-- Vulkan not found - will not build sample 'simpleVulkan'\n",
      "-- Could NOT find Vulkan (missing: Vulkan_LIBRARY Vulkan_INCLUDE_DIR) (found version \"\")\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Vulkan not found - will not build sample 'simpleVulkanMMAP'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'smokeParticles'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'volumeFiltering'\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR) \n",
      "-- OpenGL not found - will not build sample 'volumeRender'\n",
      "-- Could NOT find Vulkan (missing: Vulkan_LIBRARY Vulkan_INCLUDE_DIR) (found version \"\")\n",
      "-- Could NOT find OpenGL (missing: OPENGL_opengl_LIBRARY OPENGL_glx_LIBRARY OPENGL_INCLUDE_DIR) \n",
      "-- Vulkan not found - will not build sample 'vulkanImageCUDA'\n",
      "-- Using CUDA_HOME: /usr/local/cuda\n",
      "-- Using CUDA_LIB:  /usr/local/cuda/targets/x86_64-linux/lib/stubs/libcuda.so\n",
      "-- Using LIBNVVM_HOME: /usr/local/cuda/nvvm\n",
      "-- Using libnvvm header:      /usr/local/cuda/nvvm/include/nvvm.h\n",
      "-- Using libnvvm header path: /usr/local/cuda/nvvm/include\n",
      "-- Using libnvvm library:     /usr/local/cuda/nvvm/lib64/libnvvm.so\n",
      "-- Using rpath: /usr/local/cuda/nvvm/lib64\n",
      "-- Skipping the build of the cuda-c-linking sample.\n",
      "-- Configuring done (19.0s)\n",
      "-- Generating done (33.2s)\n",
      "-- Build files have been written to: /content/drive/MyDrive/cuda/cuda-samples/build\n"
     ]
    }
   ],
   "source": [
    "!cmake .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1756329379082,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "xNbuELvmYwzP",
    "outputId": "43c6ae6a-aae7-4bba-95f0-751982f66c6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: *** No rule to make target 'all'.  Stop.\n"
     ]
    }
   ],
   "source": [
    "!cd build/build\n",
    "! make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo_UJohBJ9YI"
   },
   "source": [
    "https://developer.nvidia.com/blog/maximizing-unified-memory-performance-cuda/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDitu9W4J-8W"
   },
   "outputs": [],
   "source": [
    "%%writefile um1.cu\n",
    "template <typename data_type, op_type op>\n",
    "__global__ void stream_thread(data_type *ptr, const size_t size,\n",
    "                              data_type *output, const data_type val)\n",
    "{\n",
    "  size_t tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "  size_t n = size / sizeof(data_type);\n",
    "  data_type accum = 0;\n",
    "\n",
    "  for(; tid < n; tid += blockDim.x * gridDim.x)\n",
    "    if (op == READ) accum += ptr[tid];\n",
    "      else ptr[tid] = val;\n",
    "\n",
    "  if (op == READ)\n",
    "    output[threadIdx.x + blockIdx.x * blockDim.x] = accum;\n",
    "}\n",
    "void main(){\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqWW53hFlAZA"
   },
   "outputs": [],
   "source": [
    "%%writefile add_grid.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "// CUDA kernel to add elements of two arrays\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "    y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  int N = 1<<20;\n",
    "  float *x, *y;\n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "  cudaMallocManaged(&x, N*sizeof(float));\n",
    "  cudaMallocManaged(&y, N*sizeof(float));\n",
    "\n",
    "  // initialize x and y arrays on the host\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  // Launch kernel on 1M elements on the GPU\n",
    "  int blockSize = 256;\n",
    "  int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "  add<<<numBlocks, blockSize>>>(N, x, y);\n",
    "\n",
    "  // Wait for GPU to finish before accessing on host\n",
    "  cudaDeviceSynchronize();\n",
    "\n",
    "  // Check for errors (all values should be 3.0f)\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
    "  std::cout << \"Max error: \" << maxError << std::endl;\n",
    "\n",
    "  // Free memory\n",
    "  cudaFree(x);\n",
    "  cudaFree(y);\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1755312394954,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "FRetWlT12WPB",
    "outputId": "91491a31-1a27-45bb-b218-cd9b77fcfb7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async_api.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile async_api.cu\n",
    "\n",
    "\n",
    "/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.\n",
    " *\n",
    " * Redistribution and use in source and binary forms, with or without\n",
    " * modification, are permitted provided that the following conditions\n",
    " * are met:\n",
    " *  * Redistributions of source code must retain the above copyright\n",
    " *    notice, this list of conditions and the following disclaimer.\n",
    " *  * Redistributions in binary form must reproduce the above copyright\n",
    " *    notice, this list of conditions and the following disclaimer in the\n",
    " *    documentation and/or other materials provided with the distribution.\n",
    " *  * Neither the name of NVIDIA CORPORATION nor the names of its\n",
    " *    contributors may be used to endorse or promote products derived\n",
    " *    from this software without specific prior written permission.\n",
    " *\n",
    " * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY\n",
    " * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    " * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n",
    " * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n",
    " * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n",
    " * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n",
    " * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n",
    " * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n",
    " * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
    " * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    " * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    " */\n",
    "\n",
    "/*\n",
    " * This sample illustrates the usage of CUDA events for both GPU timing and\n",
    " * overlapping CPU and GPU execution.  Events are inserted into a stream\n",
    " * of CUDA calls.  Since CUDA stream calls are asynchronous, the CPU can\n",
    " * perform computations while GPU is executing (including DMA memcopies\n",
    " * between the host and device).  CPU can query CUDA events to determine\n",
    " * whether GPU has completed tasks.\n",
    " */\n",
    "\n",
    "// includes, system\n",
    "#include <stdio.h>\n",
    "\n",
    "// includes CUDA Runtime\n",
    "#include <cuda_profiler_api.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// includes, project\n",
    "#include \"helper_cuda.h\"\n",
    "#include \"helper_functions.h\" // helper utility functions\n",
    "\n",
    "__global__ void increment_kernel(int *g_data, int inc_value)\n",
    "{\n",
    "    int idx     = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    g_data[idx] = g_data[idx] + inc_value;\n",
    "}\n",
    "\n",
    "bool correct_output(int *data, const int n, const int x)\n",
    "{\n",
    "    for (int i = 0; i < n; i++)\n",
    "        if (data[i] != x) {\n",
    "            printf(\"Error! data[%d] = %d, ref = %d\\n\", i, data[i], x);\n",
    "            return false;\n",
    "        }\n",
    "\n",
    "    return true;\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    "    int            devID;\n",
    "    cudaDeviceProp deviceProps;\n",
    "\n",
    "    printf(\"[%s] - Starting...\\n\", argv[0]);\n",
    "\n",
    "    // This will pick the best possible CUDA capable device\n",
    "    devID = findCudaDevice(argc, (const char **)argv);\n",
    "\n",
    "    // get device name\n",
    "    checkCudaErrors(cudaGetDeviceProperties(&deviceProps, devID));\n",
    "    printf(\"CUDA device [%s]\\n\", deviceProps.name);\n",
    "\n",
    "    int n      = 16 * 1024 * 1024;\n",
    "    int nbytes = n * sizeof(int);\n",
    "    int value  = 26;\n",
    "\n",
    "    // allocate host memory\n",
    "    int *a = 0;\n",
    "    checkCudaErrors(cudaMallocHost((void **)&a, nbytes));\n",
    "    memset(a, 0, nbytes);\n",
    "\n",
    "    // allocate device memory\n",
    "    int *d_a = 0;\n",
    "    checkCudaErrors(cudaMalloc((void **)&d_a, nbytes));\n",
    "    checkCudaErrors(cudaMemset(d_a, 255, nbytes));\n",
    "\n",
    "    // set kernel launch configuration\n",
    "    dim3 threads = dim3(512, 1);\n",
    "    dim3 blocks  = dim3(n / threads.x, 1);\n",
    "\n",
    "    // create cuda event handles\n",
    "    cudaEvent_t start, stop;\n",
    "    checkCudaErrors(cudaEventCreate(&start));\n",
    "    checkCudaErrors(cudaEventCreate(&stop));\n",
    "\n",
    "    StopWatchInterface *timer = NULL;\n",
    "    sdkCreateTimer(&timer);\n",
    "    sdkResetTimer(&timer);\n",
    "\n",
    "    checkCudaErrors(cudaDeviceSynchronize());\n",
    "    float gpu_time = 0.0f;\n",
    "\n",
    "    // asynchronously issue work to the GPU (all to stream 0)\n",
    "    checkCudaErrors(cudaProfilerStart());\n",
    "    sdkStartTimer(&timer);\n",
    "    cudaEventRecord(start, 0);\n",
    "    cudaMemcpyAsync(d_a, a, nbytes, cudaMemcpyHostToDevice, 0);\n",
    "    increment_kernel<<<blocks, threads, 0, 0>>>(d_a, value);\n",
    "    cudaMemcpyAsync(a, d_a, nbytes, cudaMemcpyDeviceToHost, 0);\n",
    "    cudaEventRecord(stop, 0);\n",
    "    sdkStopTimer(&timer);\n",
    "    checkCudaErrors(cudaProfilerStop());\n",
    "\n",
    "    // have CPU do some work while waiting for stage 1 to finish\n",
    "    unsigned long int counter = 0;\n",
    "\n",
    "    while (cudaEventQuery(stop) == cudaErrorNotReady) {\n",
    "        counter++;\n",
    "    }\n",
    "\n",
    "    checkCudaErrors(cudaEventElapsedTime(&gpu_time, start, stop));\n",
    "\n",
    "    // print the cpu and gpu times\n",
    "    printf(\"time spent executing by the GPU: %.2f\\n\", gpu_time);\n",
    "    printf(\"time spent by CPU in CUDA calls: %.2f\\n\", sdkGetTimerValue(&timer));\n",
    "    printf(\"CPU executed %lu iterations while waiting for GPU to finish\\n\", counter);\n",
    "\n",
    "    // check the output for correctness\n",
    "    bool bFinalResults = correct_output(a, n, value);\n",
    "\n",
    "    // release resources\n",
    "    checkCudaErrors(cudaEventDestroy(start));\n",
    "    checkCudaErrors(cudaEventDestroy(stop));\n",
    "    checkCudaErrors(cudaFreeHost(a));\n",
    "    checkCudaErrors(cudaFree(d_a));\n",
    "\n",
    "    exit(bFinalResults ? EXIT_SUCCESS : EXIT_FAILURE);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1755313768303,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "jkmQ-OY22WRh",
    "outputId": "17b7ee5b-ba4c-44a6-e9a9-81fc848395be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting clock.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile clock.cu\n",
    "/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.\n",
    " *\n",
    " * Redistribution and use in source and binary forms, with or without\n",
    " * modification, are permitted provided that the following conditions\n",
    " * are met:\n",
    " *  * Redistributions of source code must retain the above copyright\n",
    " *    notice, this list of conditions and the following disclaimer.\n",
    " *  * Redistributions in binary form must reproduce the above copyright\n",
    " *    notice, this list of conditions and the following disclaimer in the\n",
    " *    documentation and/or other materials provided with the distribution.\n",
    " *  * Neither the name of NVIDIA CORPORATION nor the names of its\n",
    " *    contributors may be used to endorse or promote products derived\n",
    " *    from this software without specific prior written permission.\n",
    " *\n",
    " * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY\n",
    " * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    " * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n",
    " * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n",
    " * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n",
    " * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n",
    " * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n",
    " * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n",
    " * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
    " * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    " * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    " */\n",
    "\n",
    "/*\n",
    " * This example shows how to use the clock function to measure the performance\n",
    " * of block of threads of a kernel accurately. Blocks are executed in parallel\n",
    " * and out of order. Since there's no synchronization mechanism between blocks,\n",
    " * we measure the clock once for each block. The clock samples are written to\n",
    " * device memory.\n",
    " */\n",
    "\n",
    "// System includes\n",
    "#include <assert.h>\n",
    "#include <stdint.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "// CUDA runtime\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// helper functions and utilities to work with CUDA\n",
    "#include \"helper_cuda.h\"\n",
    "#include \"helper_functions.h\"\n",
    "\n",
    "// This kernel computes a standard parallel reduction and evaluates the\n",
    "// time it takes to do that for each block. The timing results are stored\n",
    "// in device memory.\n",
    "__global__ static void timedReduction(const float *input, float *output, clock_t *timer)\n",
    "{\n",
    "    // __shared__ float shared[2 * blockDim.x];\n",
    "    extern __shared__ float shared[];\n",
    "\n",
    "    const int tid = threadIdx.x;\n",
    "    const int bid = blockIdx.x;\n",
    "\n",
    "    if (tid == 0)\n",
    "        timer[bid] = clock();\n",
    "\n",
    "    // Copy input.\n",
    "    shared[tid]              = input[tid];\n",
    "    shared[tid + blockDim.x] = input[tid + blockDim.x];\n",
    "\n",
    "    // Perform reduction to find minimum.\n",
    "    for (int d = blockDim.x; d > 0; d /= 2) {\n",
    "        __syncthreads();\n",
    "\n",
    "        if (tid < d) {\n",
    "            float f0 = shared[tid];\n",
    "            float f1 = shared[tid + d];\n",
    "\n",
    "            if (f1 < f0) {\n",
    "                shared[tid] = f1;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Write result.\n",
    "    if (tid == 0)\n",
    "        output[bid] = shared[0];\n",
    "\n",
    "    __syncthreads();\n",
    "\n",
    "    if (tid == 0)\n",
    "        timer[bid + gridDim.x] = clock();\n",
    "}\n",
    "\n",
    "#define NUM_BLOCKS  64\n",
    "#define NUM_THREADS 256\n",
    "\n",
    "// It's interesting to change the number of blocks and the number of threads to\n",
    "// understand how to keep the hardware busy.\n",
    "//\n",
    "// Here are some numbers I get on my G80:\n",
    "//    blocks - clocks\n",
    "//    1 - 3096\n",
    "//    8 - 3232\n",
    "//    16 - 3364\n",
    "//    32 - 4615\n",
    "//    64 - 9981\n",
    "//\n",
    "// With less than 16 blocks some of the multiprocessors of the device are idle.\n",
    "// With more than 16 you are using all the multiprocessors, but there's only one\n",
    "// block per multiprocessor and that doesn't allow you to hide the latency of\n",
    "// the memory. With more than 32 the speed scales linearly.\n",
    "\n",
    "// Start the main CUDA Sample here\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "    printf(\"CUDA Clock sample\\n\");\n",
    "\n",
    "    // This will pick the best possible CUDA capable device\n",
    "    int dev = findCudaDevice(argc, (const char **)argv);\n",
    "\n",
    "    float   *dinput  = NULL;\n",
    "    float   *doutput = NULL;\n",
    "    clock_t *dtimer  = NULL;\n",
    "\n",
    "    clock_t timer[NUM_BLOCKS * 2];\n",
    "    float   input[NUM_THREADS * 2];\n",
    "\n",
    "    for (int i = 0; i < NUM_THREADS * 2; i++) {\n",
    "        input[i] = (float)i;\n",
    "    }\n",
    "\n",
    "    checkCudaErrors(cudaMalloc((void **)&dinput, sizeof(float) * NUM_THREADS * 2));\n",
    "    checkCudaErrors(cudaMalloc((void **)&doutput, sizeof(float) * NUM_BLOCKS));\n",
    "    checkCudaErrors(cudaMalloc((void **)&dtimer, sizeof(clock_t) * NUM_BLOCKS * 2));\n",
    "\n",
    "    checkCudaErrors(cudaMemcpy(dinput, input, sizeof(float) * NUM_THREADS * 2, cudaMemcpyHostToDevice));\n",
    "\n",
    "    timedReduction<<<NUM_BLOCKS, NUM_THREADS, sizeof(float) * 2 * NUM_THREADS>>>(dinput, doutput, dtimer);\n",
    "\n",
    "    checkCudaErrors(cudaMemcpy(timer, dtimer, sizeof(clock_t) * NUM_BLOCKS * 2, cudaMemcpyDeviceToHost));\n",
    "\n",
    "    checkCudaErrors(cudaFree(dinput));\n",
    "    checkCudaErrors(cudaFree(doutput));\n",
    "    checkCudaErrors(cudaFree(dtimer));\n",
    "\n",
    "    long double avgElapsedClocks = 0;\n",
    "\n",
    "    for (int i = 0; i < NUM_BLOCKS; i++) {\n",
    "        avgElapsedClocks += (long double)(timer[i + NUM_BLOCKS] - timer[i]);\n",
    "    }\n",
    "\n",
    "    avgElapsedClocks = avgElapsedClocks / NUM_BLOCKS;\n",
    "    printf(\"Average clocks/block = %Lf\\n\", avgElapsedClocks);\n",
    "\n",
    "    return EXIT_SUCCESS;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OkDITGs2WTu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BU91LP0q2WV9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "of21gNbi2WYS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4xx4bxR2WaY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLhoF72U2Wcc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrcPJof82We3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IC5niflsI-5"
   },
   "source": [
    "<h1>Triton kernels</h1>\n",
    "vLLM offline mode\n",
    "\n",
    "<href=https://www.youtube.com/watch?v=E8Mju53VB00&list=PLoROMvodv4rOY23Y0BoGoBGgQ1zmU_MT_&index=6\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750193793680,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "m1JgypxLrZ4i",
    "outputId": "75eab6c2-425a-48c8-9a54-097c749ede5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7595,
     "status": "ok",
     "timestamp": 1750193813467,
     "user": {
      "displayName": "doug chang",
      "userId": "06495228775351504429"
     },
     "user_tz": 420
    },
    "id": "f9wBLwburCcX",
    "outputId": "a65c0119-c609-4cdb-cc40-835a669c42ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BRcqo_Mq_sy"
   },
   "outputs": [],
   "source": [
    "# \ud83d\udce6 Triton kernel for PagedAttention (simplified illustration)\n",
    "# NOTE: This is not production vLLM code, but illustrates the idea\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import torch\n",
    "\n",
    "@triton.jit\n",
    "def paged_attention_kernel(\n",
    "    Q_ptr, K_ptr, V_ptr, Out_ptr,\n",
    "    B, H, L_Q, L_KV, D,\n",
    "    stride_qb, stride_qh, stride_qd,\n",
    "    stride_kb, stride_kh, stride_kd,\n",
    "    stride_vb, stride_vh, stride_vd,\n",
    "    stride_ob, stride_oh, stride_od,\n",
    "    BLOCK_D: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    b = pid // H  # batch\n",
    "    h = pid % H   # head\n",
    "\n",
    "    offs_d = tl.arange(0, BLOCK_D)\n",
    "\n",
    "    q_ptrs = Q_ptr + b * stride_qb + h * stride_qh + offs_d * stride_qd\n",
    "    k_ptrs = K_ptr + b * stride_kb + h * stride_kh + offs_d * stride_kd\n",
    "    v_ptrs = V_ptr + b * stride_vb + h * stride_vh + offs_d * stride_vd\n",
    "    o_ptrs = Out_ptr + b * stride_ob + h * stride_oh + offs_d * stride_od\n",
    "\n",
    "    q = tl.load(q_ptrs)\n",
    "    k = tl.load(k_ptrs)\n",
    "    v = tl.load(v_ptrs)\n",
    "\n",
    "    score = tl.dot(q, k)\n",
    "    weight = tl.softmax(score)\n",
    "    out = tl.dot(weight, v)\n",
    "\n",
    "    tl.store(o_ptrs, out)\n",
    "\n",
    "# Example usage\n",
    "B, H, L, D = 1, 1, 32, 64\n",
    "Q = torch.randn((B, H, L, D), device=\"cuda\")\n",
    "K = torch.randn((B, H, L, D), device=\"cuda\")\n",
    "V = torch.randn((B, H, L, D), device=\"cuda\")\n",
    "Out = torch.empty_like(Q)\n",
    "\n",
    "paged_attention_kernel[(B * H,)](\n",
    "    Q, K, V, Out,\n",
    "    B, H, L, L, D,\n",
    "    Q.stride(0), Q.stride(1), Q.stride(3),\n",
    "    K.stride(0), K.stride(1), K.stride(3),\n",
    "    V.stride(0), V.stride(1), V.stride(3),\n",
    "    Out.stride(0), Out.stride(1), Out.stride(3),\n",
    "    BLOCK_D=D,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ns7iNYgrrA2K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6Jus4IHrA4f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE_veaZosxZu"
   },
   "source": [
    "<h1>LLM Implementation</h1>\n",
    "<h4>lecture 3</h4>\n",
    "<href=\"https://www.youtube.com/watch?v=ptFiH_bHnJw&list=PLoROMvodv4rOY23Y0BoGoBGgQ1zmU_MT_&index=3\"/>\n",
    "\n",
    "<p>Notes from lecture: What has changed in the last year? The new models are CommandA LLM, 2 Olmo Furious, SmolLM2, Phi-3, Phi-4, most of these are in their 2-4x iteration reflecting changes in industry. 19 dense model releases in last year. Not going to recreate foundation model training but can create vllm offline mode for these models. \u00a0</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nSPAthLs8K-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83bUOp3Us8NN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "II6b5P82s8P0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOxx56eIPgtQLiyiZyx9Hbg",
   "gpuType": "T4",
   "name": "",
   "provenance": [
    {
     "file_id": "1QnXCuy1mFDS0NwN_-7Y1tk-ToZ9upvFg",
     "timestamp": 1755364038651
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}