{"cells":[{"cell_type":"markdown","metadata":{"id":"Wo1mATQBR_Qz"},"source":["\u003ch1\u003emakemore part2\u003c/h1\u003e\n","/content/drive/MyDrive/Colab Notebooks/makemore_part3_part2.ipynb\n","\n","\u003cp\u003e1:05:08 REsnet review of layers weight, linear, batch, nonlinear. Deep NN example of different layers. Conv layers depth and bias=False bc after batch normalization adds bias and removes the need for additional bias. \u003c/p\u003e\n","\n","\u003cp\u003e1:13:12 a momentum of 0.1 seems too big. If big the batch wont converge to the true mean and std of the training data. Will thrash around the true mean/std. \u003c/p\u003e\n","\n","\u003cp\u003e\u003c/p\u003e"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":890,"status":"ok","timestamp":1753711331499,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":420},"id":"iRgNy-ZuR2Ce"},"outputs":[{"ename":"ValueError","evalue":"mount failed","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2258033288.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--\u003e 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1753711541947,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":420},"id":"WkgV-jHnTRC4"},"outputs":[],"source":["%cd /content/drive/MyDrive/makemore"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RCkBDFlKTRFN"},"outputs":[],"source":["#pytorch resnet"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":106,"status":"ok","timestamp":1753727370922,"user":{"displayName":"doug chang","userId":"06495228775351504429"},"user_tz":420},"id":"B6_cmIO8TRHl","outputId":"65fb462b-8c0b-4f26-ebe9-1e57f0d9aad4"},"outputs":[{"name":"stdout","output_type":"stream","text":["vocab_size:27\n","46497\n"]}],"source":["import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","\n","class Linear:\n","    def __init__(self, fan_in, fan_out, bias=True):\n","        self.weight = torch.randn( (fan_in, fan_out), generator = g) / fan_in ** 0.5\n","        self.bias = torch.randn(fan_out)\n","\n","    def __call__(self, x):\n","        self.out = x @ self.weight\n","        if self.bias is not None:\n","            self.out += self.bias\n","        return self.out\n","\n","    def parameters(self):\n","        return [self.weight] + ([] if self.bias is None else [self.bias])\n","\n","class BatchNorm1d:\n","    def __init__(self, dim, eps=1e-5, momentum = 0.1):\n","        self.eps = eps\n","        self.momentum = momentum\n","        self.training = True\n","        self.gamma = torch.ones(dim)\n","        self.beta = torch.zeros(dim)\n","        self.running_mean = torch.zeros(dim)\n","        self.running_var = torch.ones(dim)\n","\n","    def __call__(self, x):\n","      # forward\n","      if self.training:\n","        xmean = x.mean(0, keepdim=True) # batch mean\n","        xvar = x.var(0, keepdim=True, unbiased=True)\n","      else:\n","        xmean = self.running_mean\n","        xvar = self.running_var\n","\n","      xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n","      self.out = self.gamma * xhat + self.beta\n","\n","      if self.training:\n","        with torch.no_grad():\n","          self.running_mean =  (1 - self.momentumn) * self.running_mean + self.momentum * xmean\n","          self.running_var = (1 - self.momentumn) * self.running_var + self.momentum * xvar\n","      return self.out\n","\n","class Tanh:\n","    def __call__(self,x):\n","        self.out = torch.tanh(x)\n","        return self.out\n","    def parameters(self):\n","        return []\n","\n","\n","# read in all the words\n","words = open('names.txt', 'r').read().splitlines()\n","chars = sorted(list(set(''.join(words))))\n","stoi = {s:i+1 for i,s in enumerate(chars)}\n","stoi['.'] = 0\n","itos = {i:s for s,i in stoi.items()}\n","vocab_size = len(itos)\n","\n","print(f\"vocab_size:{vocab_size}\")\n","\n","block_size = 3\n","n_embed = 10\n","n_hidden = 100\n","g = torch.Generator().manual_seed(2147483647)\n","C = torch.randn((vocab_size, n_embed), generator = g)\n","\n","layers = [\n","  Linear( n_embed*block_size, n_hidden), Tanh(),\n","  Linear( n_hidden, n_hidden), Tanh(),\n","  Linear( n_hidden, n_hidden), Tanh(),\n","  Linear( n_hidden, n_hidden), Tanh(),\n","  Linear( n_hidden, n_hidden), Tanh(),\n","  Linear( n_hidden, vocab_size),\n","]\n","\n","\n","with torch.no_grad():\n","    # last layer make less confident??????\n","    layers[-1].weight *= 0.1\n","    # all other layers apply gain\n","    for layer in layers[:-1]:\n","        if isinstance(layer, Linear):\n","            layer.weight *= 5/3\n","\n","\n","parameters = [C] + [p for layer in layers for p in layer.parameters()]\n","print(sum( p.nelement() for p in parameters))\n","for p in parameters:\n","    p.requires_grad = True\n","\n","\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OsIVtOnsTRJn"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWZ6lKcSTRMQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOESn2pFTROV"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41NEhHdJTRQs"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBpxsKO-TRSh"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOQdG/HMfbu1lfNKxEBCzWU","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}